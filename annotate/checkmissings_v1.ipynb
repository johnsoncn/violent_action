{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missings:  images, videos and annotations\n",
    "version: 1\n",
    "\n",
    "info: \n",
    "\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"TAO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir_dsets='D:/external_datasets/' #WARNING: DATASETS ROOT is OK?\n",
    "rdir='D:/external_datasets/'+ dataset\n",
    "if str(platform.platform()).find('linux')>-1:\n",
    "    dirdir_dsets=rdir_dsets.replace('D:/','/mnt/d/')\n",
    "    rdir=rdir.replace('D:/','/mnt/d/')\n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root datasets dir: {}'.format(rdir_dsets))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jsonfile\n",
    "injsonfile_rdir=\"TAO_DIR/annotations/train\" #\"split_mola_fix_equal/test\"\n",
    "molajson =  json.load(open(rdir+injsonfile_rdir+'.json'))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Verify using dataset toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAO\n",
    "if (dataset==\"TAO\"):\n",
    "    #https://github.com/TAO-Dataset/tao\n",
    "    #https://github.com/TAO-Dataset/tao/blob/master/docs/download.md\n",
    "    TAO_ROOT=rdir+\"/TAO_DIR\")\n",
    "    !\"path/violent_action/python\" \"tao/scripts/download/verify.py\" $TAO_ROOT --split train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Verify using MOLA annotation tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets name and id\n",
    "dset_l=[]\n",
    "dset_l_id=[]\n",
    "try:\n",
    "    for d in molajson['datasets']:\n",
    "        dset_l.append(d['name'])\n",
    "        dset_l_id.append(d['id'])\n",
    "except: #manually add for example for only COCO\n",
    "    dset_l=['COCO']\n",
    "    dset_l_id=[1]\n",
    "print(dset_l, dset_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "cat_l_id=[]\n",
    "cat_l_dset=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "    cat_l_id.append(c['id'])\n",
    "    try:\n",
    "        cat_l_dset.append(dset_l[c['dataset']-1]) # dset_l index is same as id-1\n",
    "    except:\n",
    "        cat_l_dset.append(dset_l[0])\n",
    "#print(cat_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "img_l=[]\n",
    "img_l_id=[]\n",
    "for c in molajson['images']:\n",
    "    img_l.append(c['file_name'])\n",
    "    img_l_id.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos filepath and id\n",
    "try:\n",
    "    vid_l=[]\n",
    "    vid_l_id=[]\n",
    "    for c in molajson['videos']:\n",
    "        vid_l.append(c['name'])\n",
    "        vid_l_id.append(c['id'])\n",
    "except:\n",
    "    print(\"No video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks \n",
    "try:\n",
    "    track_l_id=[]\n",
    "    track_l_vidid=[]\n",
    "    for c in molajson['videos']:\n",
    "        track_l_id.append(c['id'])\n",
    "        track_l_vidid.append(c['video_id'])\n",
    "except:\n",
    "    print(\"No video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "ann_dset=[]\n",
    "ann_trackid=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "    try: ann_trackid.append(an['track_id']) \n",
    "    try:\n",
    "        ann_dset.append(an['dataset'])\n",
    "    except:\n",
    "        ann_dset.append(dset_l_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHECK IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_missing_l=[]\n",
    "for img in img_l:\n",
    "    src = os.path.join(rdir_dsets, img)\n",
    "    if not os.path.exists(src): \n",
    "        img_missing_l.append(img)\n",
    "print(rdir_dsets)\n",
    "print(len(img_missing_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 CHECK ANNOTATIONS (with missing images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image dict {id: image}\n",
    "images = {'%g' % x['id']: x for x in molajson['images']}\n",
    "\n",
    "# annotations category_id\n",
    "new_annotations=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    try:\n",
    "        if an['iscrowd']: continue\n",
    "    except:\n",
    "        print('missing \"iscrowd\" key')\n",
    "    img = images['%g' % an['image_id']]\n",
    "    h, w, f = img['height'], img['width'], img['file_name']\n",
    "\n",
    "\n",
    "    # The Labelbox bounding box format is [top left x, top left y, width, height]\n",
    "    box = np.array(an['bbox'], dtype=np.float64)\n",
    "    box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "    box[[0, 2]] /= w  # normalize x\n",
    "    box[[1, 3]] /= h  # normalize y\n",
    "\n",
    "    if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "        src = os.path.join(rdir_dsets, f)\n",
    "        if os.path.exists(src): new_annotations.append(an)\n",
    "        else: print(\">> missing : \", src )\n",
    "\n",
    "print(len(molajson['annotations']))\n",
    "print(len(new_annotations))\n",
    "print(len(molajson['annotations'])-len(new_annotations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CHECK Classes|categories (annotations and images for each class w/ EXCEL report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks #TODO: SORT alphabetically\n",
    "checks_l=[]\n",
    "checks_l_catid=[]\n",
    "checks_l_catdset=[]\n",
    "check_method=\"all_cats\"\n",
    "if check_method==\"all_cats\": #Do for all category names, even with equal \n",
    "    checks_l=cat_l\n",
    "    checks_l_catid=[[id] for id in cat_l_id]\n",
    "    checks_l_catdset=[[dset] for dset in cat_l_dset]\n",
    "    \n",
    "\n",
    "print(checks_l[0:5])\n",
    "print(checks_l_catid[0:5])\n",
    "print(checks_l_catdset[0:5])\n",
    "print(len(checks_l))\n",
    "print(len(checks_l_catid))\n",
    "print(len(checks_l_catdset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotations checks\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "ann_imgid_np=np.array(ann_imgid)\n",
    "ann_bbox_np=np.array(ann_bbox)\n",
    "ann_dset_np=np.array(ann_dset)\n",
    "checks_l_imgid=[]\n",
    "checks_l_bbox=[]\n",
    "checks_l_dset=[]\n",
    "for catids in tqdm(checks_l_catid):\n",
    "    l_imgid=[]\n",
    "    l_bbox=[]\n",
    "    l_dset=[]\n",
    "    for catid in catids:\n",
    "        ann_idx = np.where(ann_catid_np==catid)[0].tolist() #annotation index of ids\n",
    "        l_imgid.append(ann_imgid_np[ann_idx].tolist())\n",
    "        l_bbox.append(ann_bbox_np[ann_idx].tolist())\n",
    "        l_dset.append(ann_dset_np[ann_idx].tolist())\n",
    "    checks_l_imgid.append(l_imgid)\n",
    "    checks_l_bbox.append(l_bbox)\n",
    "    checks_l_dset.append(l_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INIT VARS\n",
    "method=\"save_images\" #\"save_images\": to save new images and excel for manual inspection; \"\": already saved don't need to repeat and the excel are\n",
    "datadir=\"checks/\"+injsonfile_rdir+\"/\" #root folder to save check method . #WARNING checks/original json that was used to save images and excel\n",
    "folder=check_method+'/' #folder to save images and exel \n",
    "showimage=False #show images\n",
    "startidx=0 # start index of image to save from each dataset\n",
    "imgnr=3 # total number of images to save from each dataset\n",
    "imgstep='random' # step between images: int | 'random' - int steps between images; 'rand' gets random list\n",
    "#paths\n",
    "path=os.path.join(rdir,datadir,folder) #path to folder\n",
    "assure_path_exists(path)\n",
    "excelpath=path+check_method+\"_report_v1.xlsx\"#path+check_method+\"_report.xlsx\"#path to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHODS\n",
    "if method==\"save_images\": # save images and excel to folder for manual edit\n",
    "    df=pd.DataFrame({'checks_l': checks_l,'checks_l_catid': checks_l_catid, 'checks_l_catdset': checks_l_catdset })\n",
    "    df['annotations_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    df['images_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    #save image for each check\n",
    "    for i, check in enumerate(tqdm(checks_l)): #run for each check category\n",
    "        firstclass=check\n",
    "        if isinstance(firstclass, list): firstclass=firstclass[0] #first class\n",
    "        print('\\n>> '+firstclass+'...') #class\n",
    "        classpath=os.path.join(path, firstclass) # path to folder for images of  firstclass\n",
    "        classpath=parse_path(classpath)+'/' #make it a folder\n",
    "        assure_path_exists(classpath)\n",
    "        df=save_imgs(df, rdir_dsets, classpath, i, dset_l, checks_l, checks_l_catid, checks_l_bbox, checks_l_dset,\n",
    "              checks_l_imgid, img_l, img_l_id, startidx=startidx, imgnr=imgnr, imgstep=imgstep, showimage=showimage)    \n",
    "    df.to_excel(excelpath, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT EXCEL MANUAL EDIT #WARNING: CHECK EXCEL FIRST (#NOTE: donte use classes with missing annotations and images)\n",
    "df=pd.read_excel(excelpath)\n",
    "display(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CHECK VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_missing_l=[]\n",
    "for vid in vid_l:\n",
    "    src = os.path.join(rdir_dsets, vid)\n",
    "    if not os.path.exists(src): \n",
    "        vid_missing_l.append(vid)\n",
    "print(rdir_dsets)\n",
    "print(len(vid_missing_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 CHECK ANNOTATIONS (with missing ivideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image dict {id: image}\n",
    "videos = {'%g' % x['id']: x for x in molajson['videos']}\n",
    "tracks = {'%g' % x['id']: x for x in molajson['tracks']}\n",
    "# annotations category_id\n",
    "new_annotations=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    try:\n",
    "        if an['iscrowd']: continue\n",
    "    except:\n",
    "        print('missing \"iscrowd\" key')\n",
    "    \n",
    "    vid = videos['%g' % tracks['%g' % an['track_id']]]\n",
    "    h, w, f = vid['height'], vid['width'], vid['name']\n",
    "\n",
    "\n",
    "    # The Labelbox bounding box format is [top left x, top left y, width, height]\n",
    "    box = np.array(an['bbox'], dtype=np.float64)\n",
    "    box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "    box[[0, 2]] /= w  # normalize x\n",
    "    box[[1, 3]] /= h  # normalize y\n",
    "\n",
    "    if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "        src = os.path.join(rdir_dsets, f)\n",
    "        if os.path.exists(src): new_annotations.append(an)\n",
    "        else: print(\">> missing : \", src )\n",
    "            \n",
    "print(len(molajson['annotations']))\n",
    "print(len(new_annotations))\n",
    "print(len(molajson['annotations'])-len(new_annotations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
