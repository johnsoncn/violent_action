{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missings:  images, videos and annotations\n",
    "version: 1\n",
    "\n",
    "info: \n",
    "\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root=\"TAO/new_TAO_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux-5.4.0-65-generic-x86_64-with-glibc2.10\n",
      "root datasets dir: /home/administrator/Z/Datasets/External Datasets/\n",
      "root dir: /home/administrator/Z/Datasets/External Datasets/TAO/new_TAO_DIR/\n"
     ]
    }
   ],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir_dsets='/home/administrator/Z/Datasets/External Datasets/' #WARNING: DATASETS ROOT is OK?\n",
    "rdir='/home/administrator/Z/Datasets/External Datasets/'+ dataset_root +'/'\n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root datasets dir: {}'.format(rdir_dsets))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videos 500\n",
      "annotations 54639\n",
      "tracks 2647\n",
      "images 18274\n",
      "info 6\n",
      "categories 1230\n",
      "licenses 1\n"
     ]
    }
   ],
   "source": [
    "#jsonfile\n",
    "injsonfile_rdir=\"annotations/train\" #\"split_mola_fix_equal/test\"\n",
    "molajson =  json.load(open(rdir+injsonfile_rdir+'.json'))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Verify using dataset toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for administrator:   File \"/home/administrator/Z/Datasets/External Datasets/TAO/tao/scripts/download/verify.py\", line 28\n",
      "    ann_path = args.root / f'annotations/{args.split}.json'\n",
      "                                                          ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TAO\n",
    "if (dataset_root.upper().find(\"TAO\")>-1):\n",
    "    #https://github.com/TAO-Dataset/tao\n",
    "    #https://github.com/TAO-Dataset/tao/blob/master/docs/download.md\n",
    "    TAO_ROOT='\"'+rdir+'\"'#'\"'+rdir+'\"'\n",
    "    TAO_SCRIPT='\"/home/administrator/Z/Datasets/External Datasets/TAO/tao/scripts/download/verify.py\"'\n",
    "    PASSFILE=\"/home/administrator/Desktop/remote.txt\"\n",
    "    !sudo -S python $TAO_SCRIPT $TAO_ROOT --split train <$PASSFILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAO'] [1]\n"
     ]
    }
   ],
   "source": [
    "# datasets name and id\n",
    "dset_l=[]\n",
    "dset_l_id=[]\n",
    "try:\n",
    "    for d in molajson['datasets']:\n",
    "        dset_l.append(d['name'])\n",
    "        dset_l_id.append(d['id'])\n",
    "except: #manually add for example for only COCO\n",
    "    dset_l=['TAO']\n",
    "    dset_l_id=[1]\n",
    "print(dset_l, dset_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "cat_l_id=[]\n",
    "cat_l_dset=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "    cat_l_id.append(c['id'])\n",
    "    try:\n",
    "        cat_l_dset.append(dset_l[c['dataset']-1]) # dset_l index is same as id-1\n",
    "    except:\n",
    "        cat_l_dset.append(dset_l[0])\n",
    "#print(cat_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "img_l=[]\n",
    "img_l_id=[]\n",
    "for c in molajson['images']:\n",
    "    img_l.append(c['file_name'])\n",
    "    img_l_id.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos filepath and id\n",
    "try:\n",
    "    vid_l=[]\n",
    "    vid_l_id=[]\n",
    "    for c in molajson['videos']:\n",
    "        vid_l.append(c['name'])\n",
    "        vid_l_id.append(c['id'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"No video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks \n",
    "try:\n",
    "    track_l_id=[]\n",
    "    track_l_vidid=[]\n",
    "    for c in molajson['tracks']:\n",
    "        track_l_id.append(c['id'])\n",
    "        track_l_vidid.append(c['video_id'])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"No video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54639/54639 [00:00<00:00, 480695.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "ann_dset=[]\n",
    "ann_trackid=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "    try: \n",
    "        ann_trackid.append(an['track_id'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ann_dset.append(an['dataset'])\n",
    "    except:\n",
    "        ann_dset.append(dset_l_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHECK IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18274/18274 [00:03<00:00, 5789.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/administrator/Z/Datasets/External Datasets/TAO/new_TAO_DIR/frames/train/Charades/8Q0EY/frame0931.jpg\n",
      "6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_missing_l=[]\n",
    "for img in tqdm(img_l):\n",
    "    src = os.path.join(rdir, img)\n",
    "    if (dataset_root.upper().find(\"TAO\")>-1): src = os.path.join(rdir,\"frames\", img)\n",
    "    if not os.path.exists(src): \n",
    "        img_missing_l.append(img)\n",
    "print(src)\n",
    "print(len(img_missing_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 CHECK ANNOTATIONS (with missing images, that have good bounding box and are are not \"iscrowd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54639/54639 [00:03<00:00, 13884.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54639\n",
      "32008\n",
      "22631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create image dict {id: image}\n",
    "images = {'%g' % x['id']: x for x in molajson['images']}\n",
    "\n",
    "# annotations category_id\n",
    "new_annotations=[]\n",
    "img_missing_l=[]\n",
    "ann_missing_l=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    try:\n",
    "        if an['iscrowd']: continue\n",
    "    except:\n",
    "        print('missing \"iscrowd\" key')\n",
    "    img = images['%g' % an['image_id']]\n",
    "    h, w, f = img['height'], img['width'], img['file_name']\n",
    "\n",
    "\n",
    "    # The Labelbox bounding box format is [top left x, top left y, width, height]\n",
    "    box = np.array(an['bbox'], dtype=np.float64)\n",
    "    box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "    box[[0, 2]] /= w  # normalize x\n",
    "    box[[1, 3]] /= h  # normalize y\n",
    "\n",
    "    if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "        src = os.path.join(rdir, f)\n",
    "        if (dataset_root.upper().find(\"TAO\")>-1): src = os.path.join(rdir,\"frames\", f)\n",
    "        if os.path.exists(src): new_annotations.append(an)\n",
    "        else: \n",
    "            img_missing_l.append(img)\n",
    "            ann_missing_l.append(an)\n",
    "            \n",
    "\n",
    "print(len(molajson['annotations']))\n",
    "print(len(new_annotations))\n",
    "print(len(img_missing_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CHECK Classes|categories (annotations and images for each class w/ EXCEL report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acorn', 'aerosol_can', 'air_conditioner', 'airplane', 'alarm_clock']\n",
      "[[1], [2], [3], [4], [5]]\n",
      "[['TAO'], ['TAO'], ['TAO'], ['TAO'], ['TAO']]\n",
      "1230\n",
      "1230\n",
      "1230\n"
     ]
    }
   ],
   "source": [
    "#checks #TODO: SORT alphabetically\n",
    "checks_l=[]\n",
    "checks_l_catid=[]\n",
    "checks_l_catdset=[]\n",
    "check_method=\"all_cats\"\n",
    "if check_method==\"all_cats\": #Do for all category names, even with equal \n",
    "    checks_l=cat_l\n",
    "    checks_l_catid=[[id] for id in cat_l_id]\n",
    "    checks_l_catdset=[[dset] for dset in cat_l_dset]\n",
    "    \n",
    "\n",
    "print(checks_l[0:5])\n",
    "print(checks_l_catid[0:5])\n",
    "print(checks_l_catdset[0:5])\n",
    "print(len(checks_l))\n",
    "print(len(checks_l_catid))\n",
    "print(len(checks_l_catdset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1230/1230 [00:00<00:00, 17485.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# get annotations checks\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "ann_imgid_np=np.array(ann_imgid)\n",
    "ann_bbox_np=np.array(ann_bbox)\n",
    "ann_dset_np=np.array(ann_dset)\n",
    "checks_l_imgid=[]\n",
    "checks_l_bbox=[]\n",
    "checks_l_dset=[]\n",
    "for catids in tqdm(checks_l_catid):\n",
    "    l_imgid=[]\n",
    "    l_bbox=[]\n",
    "    l_dset=[]\n",
    "    for catid in catids:\n",
    "        ann_idx = np.where(ann_catid_np==catid)[0].tolist() #annotation index of ids\n",
    "        l_imgid.append(ann_imgid_np[ann_idx].tolist())\n",
    "        l_bbox.append(ann_bbox_np[ann_idx].tolist())\n",
    "        l_dset.append(ann_dset_np[ann_idx].tolist())\n",
    "    checks_l_imgid.append(l_imgid)\n",
    "    checks_l_bbox.append(l_bbox)\n",
    "    checks_l_dset.append(l_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INIT VARS\n",
    "method=\"save_images\" #\"save_images\": to save new images and excel for manual inspection; \"\": already saved don't need to repeat and the excel are\n",
    "datadir=\"checks/\"+injsonfile_rdir+\"/\" #root folder to save check method . #WARNING checks/original json that was used to save images and excel\n",
    "folder=check_method+'/' #folder to save images and exel \n",
    "showimage=False #show images\n",
    "startidx=0 # start index of image to save from each dataset\n",
    "imgnr=3 # total number of images to save from each dataset\n",
    "imgstep='random' # step between images: int | 'random' - int steps between images; 'rand' gets random list\n",
    "#paths\n",
    "path=os.path.join(rdir,datadir,folder) #path to folder\n",
    "assure_path_exists(path)\n",
    "excelpath=path+check_method+\"_report_v1.xlsx\"#path+check_method+\"_report.xlsx\"#path to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#METHODS\n",
    "if method==\"save_images\": # save images and excel to folder for manual edit\n",
    "    df=pd.DataFrame({'checks_l': checks_l,'checks_l_catid': checks_l_catid, 'checks_l_catdset': checks_l_catdset })\n",
    "    df['annotations_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    df['images_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    #save image for each check\n",
    "    for i, check in enumerate(tqdm(checks_l)): #run for each check category\n",
    "        firstclass=check\n",
    "        if isinstance(firstclass, list): firstclass=firstclass[0] #first class\n",
    "        print('\\n>> '+firstclass+'...') #class\n",
    "        classpath=os.path.join(path, firstclass) # path to folder for images of  firstclass\n",
    "        classpath=parse_path(classpath)+'/' #make it a folder\n",
    "        assure_path_exists(classpath)\n",
    "        rdir_path=rdir_dsets\n",
    "        if (dataset_root.upper().find(\"TAO\")>-1): rdir_path = os.path.join(rdir,\"frames/\")\n",
    "        df=save_imgs(df, rdir_path, classpath, i, dset_l, checks_l, checks_l_catid, checks_l_bbox, checks_l_dset,\n",
    "              checks_l_imgid, img_l, img_l_id, startidx=startidx, imgnr=imgnr, imgstep=imgstep, showimage=showimage)    \n",
    "    df.to_excel(excelpath, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checks_l</th>\n",
       "      <th>checks_l_catid</th>\n",
       "      <th>checks_l_catdset</th>\n",
       "      <th>annotations_missing</th>\n",
       "      <th>images_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acorn</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aerosol_can</td>\n",
       "      <td>[2]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[4]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alarm_clock</td>\n",
       "      <td>[5]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>yak</td>\n",
       "      <td>[1226]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>yogurt</td>\n",
       "      <td>[1227]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>yoke_(animal_equipment)</td>\n",
       "      <td>[1228]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[1229]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>[1230]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     checks_l checks_l_catid checks_l_catdset  \\\n",
       "0                       acorn            [1]          ['TAO']   \n",
       "1                 aerosol_can            [2]          ['TAO']   \n",
       "2             air_conditioner            [3]          ['TAO']   \n",
       "3                    airplane            [4]          ['TAO']   \n",
       "4                 alarm_clock            [5]          ['TAO']   \n",
       "...                       ...            ...              ...   \n",
       "1225                      yak         [1226]          ['TAO']   \n",
       "1226                   yogurt         [1227]          ['TAO']   \n",
       "1227  yoke_(animal_equipment)         [1228]          ['TAO']   \n",
       "1228                    zebra         [1229]          ['TAO']   \n",
       "1229                 zucchini         [1230]          ['TAO']   \n",
       "\n",
       "     annotations_missing images_missing  \n",
       "0                    [1]            [0]  \n",
       "1                    [0]            [1]  \n",
       "2                    [1]            [0]  \n",
       "3                    [0]            [0]  \n",
       "4                    [1]            [0]  \n",
       "...                  ...            ...  \n",
       "1225                 [1]            [0]  \n",
       "1226                 [1]            [0]  \n",
       "1227                 [1]            [0]  \n",
       "1228                 [0]            [0]  \n",
       "1229                 [1]            [0]  \n",
       "\n",
       "[1230 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IMPORT EXCEL MANUAL EDIT #WARNING: CHECK EXCEL FIRST (#NOTE: donte use classes with missing annotations and images)\n",
    "df=pd.read_excel(excelpath)\n",
    "display(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CHECK VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/administrator/Z/Datasets/External Datasets/TAO/new_TAO_DIR/videos/train/Charades/8Q0EY\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "vid_missing_l=[]\n",
    "for vid in vid_l:\n",
    "    src = os.path.join(rdir, vid)\n",
    "    if (dataset_root.upper().find(\"TAO\")>-1): src = os.path.join(rdir,\"videos\", vid)\n",
    "    if not os.path.exists(src): \n",
    "        vid_missing_l.append(vid)\n",
    "print(src)\n",
    "print(len(vid_missing_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 CHECK ANNOTATIONS (with missing ivideos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image dict {id: image}\n",
    "videos = {'%g' % x['id']: x for x in molajson['videos']}\n",
    "tracks = {'%g' % x['id']: x for x in molajson['tracks']}\n",
    "# annotations category_id\n",
    "new_annotations=[]\n",
    "vid_missing_l=[]\n",
    "ann_missing_l=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    try:\n",
    "        if an['iscrowd']: continue\n",
    "    except:\n",
    "        print('missing \"iscrowd\" key')\n",
    "    \n",
    "    vid = videos['%g' % tracks['%g' % an['track_id']]]\n",
    "    h, w, f = vid['height'], vid['width'], vid['name']\n",
    "\n",
    "\n",
    "    # The Labelbox bounding box format is [top left x, top left y, width, height]\n",
    "    box = np.array(an['bbox'], dtype=np.float64)\n",
    "    box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "    box[[0, 2]] /= w  # normalize x\n",
    "    box[[1, 3]] /= h  # normalize y\n",
    "\n",
    "    if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "        src = os.path.join(rdir, f)\n",
    "        if (dataset_root.upper().find(\"TAO\")>-1): src = os.path.join(rdir,\"videos\", f)\n",
    "        if os.path.exists(src): new_annotations.append(an)\n",
    "        else: \n",
    "            vid_missing_l.append(img)\n",
    "            ann_missing_l.append(an)\n",
    "            \n",
    "\n",
    "print(len(molajson['annotations']))\n",
    "print(len(new_annotations))\n",
    "print(len(vid_missing_l))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
