{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix/Fusion of Classes=Categories\n",
    "version: 1\n",
    "\n",
    "info: \n",
    "- mix/fusion: of classes into other classes\n",
    "    0. If not mola.json : Manually add dataset descriptors when importing id, e.g. COCO(see below)\n",
    "- reorder_ids: It also reorders category id\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.21332-SP0\n",
      "root datasets dir: D:/external_datasets/\n",
      "root dir: D:/external_datasets/MOLA/\n"
     ]
    }
   ],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir_dsets='D:/external_datasets/' #WARNING: DATASETS ROOT is OK?\n",
    "rdir='D:/external_datasets/MOLA/' \n",
    "if str(platform.platform()).find('linux')>-1:\n",
    "    dirdir_dsets=rdir_dsets.replace('D:/','/mnt/d/')\n",
    "    rdir=rdir.replace('D:/','/mnt/d/')\n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root datasets dir: {}'.format(rdir_dsets))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 6\n",
      "images 54649\n",
      "annotations 83875\n",
      "categories 1230\n",
      "licenses 1\n",
      "videos 1488\n",
      "tracks 8132\n"
     ]
    }
   ],
   "source": [
    "#jsonfile\n",
    "injsonfile=\"split_tao_original/train\" #\"split_mola_fix_equal/test\"\n",
    "molajson =  json.load(open(rdir+'annotations/'+injsonfile+'.json'))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import ids\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAO'] [1]\n"
     ]
    }
   ],
   "source": [
    "# datasets name and id\n",
    "dset_l=[]\n",
    "dset_l_id=[]\n",
    "try:\n",
    "    for d in molajson['datasets']:\n",
    "        dset_l.append(d['name'])\n",
    "        dset_l_id.append(d['id'])\n",
    "except: #manually add for example for only COCO\n",
    "    dset_l=['TAO']\n",
    "    dset_l_id=[1]\n",
    "print(dset_l, dset_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "cat_l_id=[]\n",
    "cat_l_dset=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "    cat_l_id.append(c['id'])\n",
    "    try:\n",
    "        cat_l_dset.append(dset_l[c['dataset']-1]) # dset_l index is same as id-1\n",
    "    except:\n",
    "        cat_l_dset.append(dset_l[0])\n",
    "#print(cat_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "img_l=[]\n",
    "img_l_id=[]\n",
    "for c in molajson['images']:\n",
    "    img_l.append(c['file_name'])\n",
    "    img_l_id.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 83875/83875 [00:00<00:00, 670763.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "ann_dset=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "    try:\n",
    "        ann_dset.append(an['dataset'])\n",
    "    except:\n",
    "        ann_dset.append(dset_l_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find mixers cat_ids\n",
    "mixers example\n",
    "categories= [{name:cow, id:1, dataset:1},...,{name:cow, id:200, dataset:2},...,{name:cow, id:101, dataset:3}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acorn', 'aerosol_can', 'air_conditioner', 'airplane', 'alarm_clock']\n",
      "[[1], [2], [3], [4], [5]]\n",
      "[['TAO'], ['TAO'], ['TAO'], ['TAO'], ['TAO']]\n",
      "1230\n",
      "1230\n",
      "1230\n"
     ]
    }
   ],
   "source": [
    "#mixers #TODO: SORT alphabetically\n",
    "mixers_l=[]\n",
    "mixers_l_catid=[]\n",
    "mixers_l_catdset=[]\n",
    "mixer_method=\"all_cats\"\n",
    "if mixer_method==\"all_cats\": #Do for all category names, even with equal \n",
    "    mixers_l=cat_l\n",
    "    mixers_l_catid=[[id] for id in cat_l_id]\n",
    "    mixers_l_catdset=[[dset] for dset in cat_l_dset]\n",
    "    \n",
    "\n",
    "print(mixers_l[0:5])\n",
    "print(mixers_l_catid[0:5])\n",
    "print(mixers_l_catdset[0:5])\n",
    "print(len(mixers_l))\n",
    "print(len(mixers_l_catid))\n",
    "print(len(mixers_l_catdset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1230/1230 [00:00<00:00, 6440.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# get annotations mixers\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "ann_imgid_np=np.array(ann_imgid)\n",
    "ann_bbox_np=np.array(ann_bbox)\n",
    "ann_dset_np=np.array(ann_dset)\n",
    "mixers_l_imgid=[]\n",
    "mixers_l_bbox=[]\n",
    "mixers_l_dset=[]\n",
    "for catids in tqdm(mixers_l_catid):\n",
    "    l_imgid=[]\n",
    "    l_bbox=[]\n",
    "    l_dset=[]\n",
    "    for catid in catids:\n",
    "        ann_idx = np.where(ann_catid_np==catid)[0].tolist() #annotation index of ids\n",
    "        l_imgid.append(ann_imgid_np[ann_idx].tolist())\n",
    "        l_bbox.append(ann_bbox_np[ann_idx].tolist())\n",
    "        l_dset.append(ann_dset_np[ann_idx].tolist())\n",
    "    mixers_l_imgid.append(l_imgid)\n",
    "    mixers_l_bbox.append(l_bbox)\n",
    "    mixers_l_dset.append(l_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classes|categories to mix w/ EXCEL report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INIT VARS\n",
    "classtomix_l=[]\n",
    "classtomix_l_catid=[]\n",
    "method=\"\" #\"save_images\": to save new images and excel for manual inspection; \"\": already saved don't need to repeat and the excel are\n",
    "datadir=\"mixers/\"+injsonfile+\"/\" #root folder to save mixer method . #WARNING mixers/original json that was used to save images and excel\n",
    "folder=mixer_method+'/' #folder to save images and exel \n",
    "showimage=False #show images\n",
    "startidx=0 # start index of image to save from each dataset\n",
    "imgnr=1 # total number of images to save from each dataset\n",
    "imgstep='random' # step between images: int | 'random' - int steps between images; 'rand' gets random list\n",
    "#paths\n",
    "path=os.path.join(rdir,datadir,folder) #path to folder\n",
    "assure_path_exists(path)\n",
    "excelpath=path+mixer_method+\"_v1.xlsx\"#path+mixer_method+\"_classtomix_report.xlsx\"#path to excel\n",
    "#fixed path - uncomment and change to method=\"\"\n",
    "excelpath=\"D:/external_datasets/MOLA/mixers/split_tao_original/tao_cats_aggressive_v1.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#METHODS\n",
    "if method==\"save_images\": # save images and excel to folder for manual edit\n",
    "    df=pd.DataFrame({'mixers_l': mixers_l,'mixers_l_catid': mixers_l_catid, 'mixers_l_catdset': mixers_l_catdset, 'classtomix_l': np.nan, 'classtomix_l_catid':np.nan, 'rules':np.nan })\n",
    "    df.loc[0, 'rules']=\"To fix classes: 1) You need to fill the column classtomix_l and/or classtomix_l_catid with the information from the respective mixer columns; 2) When copy/pasting or changing, make sure the same structure maintains:  ['car', 'carrot'], [3, 52], beware of the spaces ['car', '  and always maintain the first class in the list;  3) You have 3 possibilities of filling the columns : 1-the 2 columns empty, meaning the row will not be used for classtomix; 2-only one column empty, e.g. fill the classtotix_l row with the class labels from mixers_l, then during the importing the classtomix_l_catid is filled, and vice-versa; 3-If you want to change the name of the first class in the list,e.g ['car', 'carrot'] for ['automobile', 'carrot'] you need to provide the ids to classtomix_l_catid.\"\n",
    "    df['annotations_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    df['images_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    #save image for each mixer\n",
    "    for i, mixer in enumerate(tqdm(mixers_l)): #run for each mixer category\n",
    "        firstclass=mixer\n",
    "        if isinstance(firstclass, list): firstclass=firstclass[0] #first class\n",
    "        print('\\n>> '+firstclass+'...') #class\n",
    "        classpath=os.path.join(path, firstclass) # path to folder for images of  firstclass\n",
    "        classpath=parse_path(classpath)+'/' #make it a folder\n",
    "        assure_path_exists(classpath)\n",
    "        df=save_imgs(df, rdir_dsets, classpath, i, dset_l, mixers_l, mixers_l_catid, mixers_l_bbox, mixers_l_dset,\n",
    "              mixers_l_imgid, img_l, img_l_id, startidx=startidx, imgnr=imgnr, imgstep=imgstep, showimage=showimage)    \n",
    "    df.to_excel(excelpath, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mixers_l</th>\n",
       "      <th>mixers_l_catid</th>\n",
       "      <th>mixers_l_catdset</th>\n",
       "      <th>classtomix_l</th>\n",
       "      <th>classtomix_l_catid</th>\n",
       "      <th>rules</th>\n",
       "      <th>annotations_missing</th>\n",
       "      <th>images_missing</th>\n",
       "      <th>aggressive_keywords</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acorn</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>[59, 137, 177, 263, 312, 360, 407, 460, 476, 5...</td>\n",
       "      <td>To fix classes: 1) You need to fill the column...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>knife</td>\n",
       "      <td>knife(626), butcher_knife(177), pocketknife(83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aerosol_can</td>\n",
       "      <td>[2]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>group_remain_classes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>weapon</td>\n",
       "      <td>bow_(weapon)(137), projectile_(weapon)(861)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>gun</td>\n",
       "      <td>gun(534),machine_gun(672),water_gun(1191)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[4]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>bat</td>\n",
       "      <td>baseball bat(59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alarm_clock</td>\n",
       "      <td>[5]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>fork</td>\n",
       "      <td>fork(476),pitchfork(829)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>yak</td>\n",
       "      <td>[1226]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>yogurt</td>\n",
       "      <td>[1227]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>yoke_(animal_equipment)</td>\n",
       "      <td>[1228]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>zebra</td>\n",
       "      <td>[1229]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>[1230]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1230 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mixers_l mixers_l_catid mixers_l_catdset  \\\n",
       "0                       acorn            [1]          ['TAO']   \n",
       "1                 aerosol_can            [2]          ['TAO']   \n",
       "2             air_conditioner            [3]          ['TAO']   \n",
       "3                    airplane            [4]          ['TAO']   \n",
       "4                 alarm_clock            [5]          ['TAO']   \n",
       "...                       ...            ...              ...   \n",
       "1225                      yak         [1226]          ['TAO']   \n",
       "1226                   yogurt         [1227]          ['TAO']   \n",
       "1227  yoke_(animal_equipment)         [1228]          ['TAO']   \n",
       "1228                    zebra         [1229]          ['TAO']   \n",
       "1229                 zucchini         [1230]          ['TAO']   \n",
       "\n",
       "              classtomix_l                                 classtomix_l_catid  \\\n",
       "0               aggressive  [59, 137, 177, 263, 312, 360, 407, 460, 476, 5...   \n",
       "1     group_remain_classes                                                NaN   \n",
       "2                      NaN                                                NaN   \n",
       "3                      NaN                                                NaN   \n",
       "4                      NaN                                                NaN   \n",
       "...                    ...                                                ...   \n",
       "1225                   NaN                                                NaN   \n",
       "1226                   NaN                                                NaN   \n",
       "1227                   NaN                                                NaN   \n",
       "1228                   NaN                                                NaN   \n",
       "1229                   NaN                                                NaN   \n",
       "\n",
       "                                                  rules annotations_missing  \\\n",
       "0     To fix classes: 1) You need to fill the column...                 [1]   \n",
       "1                                                   NaN                 [1]   \n",
       "2                                                   NaN                 [1]   \n",
       "3                                                   NaN                 [0]   \n",
       "4                                                   NaN                 [1]   \n",
       "...                                                 ...                 ...   \n",
       "1225                                                NaN                 [1]   \n",
       "1226                                                NaN                 [1]   \n",
       "1227                                                NaN                 [1]   \n",
       "1228                                                NaN                 [0]   \n",
       "1229                                                NaN                 [1]   \n",
       "\n",
       "     images_missing aggressive_keywords  \\\n",
       "0               [0]               knife   \n",
       "1               [0]              weapon   \n",
       "2               [0]                 gun   \n",
       "3               [0]                 bat   \n",
       "4               [0]                fork   \n",
       "...             ...                 ...   \n",
       "1225            [0]                 NaN   \n",
       "1226            [0]                 NaN   \n",
       "1227            [0]                 NaN   \n",
       "1228            [0]                 NaN   \n",
       "1229            [0]                 NaN   \n",
       "\n",
       "                                                  class  \n",
       "0     knife(626), butcher_knife(177), pocketknife(83...  \n",
       "1           bow_(weapon)(137), projectile_(weapon)(861)  \n",
       "2             gun(534),machine_gun(672),water_gun(1191)  \n",
       "3                                      baseball bat(59)  \n",
       "4                              fork(476),pitchfork(829)  \n",
       "...                                                 ...  \n",
       "1225                                                NaN  \n",
       "1226                                                NaN  \n",
       "1227                                                NaN  \n",
       "1228                                                NaN  \n",
       "1229                                                NaN  \n",
       "\n",
       "[1230 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IMPORT EXCEL MANUAL EDIT #WARNING: CHECK EXCEL FIRST (#NOTE: donte use classes with missing annotations and images)\n",
    "df=pd.read_excel(excelpath)\n",
    "classtomix_df=df.loc[:,'classtomix_l']\n",
    "classtomix_df_catid=df.loc[:,'classtomix_l_catid']\n",
    "new_cat_l=copy.deepcopy(cat_l)\n",
    "new_cat_l_id=copy.deepcopy(cat_l_id)\n",
    "display(df)\n",
    "\n",
    "# PARSE COLUMNS TO FIX\n",
    "classtomix_l=classtomix_df.tolist()\n",
    "classtomix_l_catid=classtomix_df_catid.tolist()\n",
    "#convert strings to lists\n",
    "for icl, cl in enumerate(classtomix_l): \n",
    "    if isinstance(classtomix_l[icl], str): classtomix_l[icl]=convert_unicode(classtomix_l[icl], method='liststr')\n",
    "    if isinstance(classtomix_l_catid[icl], str): classtomix_l_catid[icl]=convert_unicode(classtomix_l_catid[icl], method='listnum')\n",
    "\n",
    "\n",
    "#parse the columns(classtomix_l, classtomix_l_catid) based on the rules\n",
    "#0. if both columns are empty\n",
    "if classtomix_df.isnull().all() or classtomix_df_catid.isnull().all():\n",
    "    raise RuntimeError(\"Go Back to the excel and add something to classtomix_l and classtomix_l_catid\")\n",
    "else:\n",
    "    for ic, classes in enumerate(classtomix_df):\n",
    "        #1. if only classtomix_l_catid empty - get \n",
    "        if not pd.isnull(classtomix_df.iloc[ic]) and pd.isnull(classtomix_df_catid.iloc[ic]):\n",
    "            if classtomix_df.iloc[ic] == 'group_remain_classes': # group the remaining ids \n",
    "                chosed_id=np.array([x for x in classtomix_l_catid if str(x) != 'nan' and str(x) !='[]'][0])\n",
    "                remain_id=np.setdiff1d(np.array(new_cat_l_id), chosed_id)\n",
    "                classtomix_l_catid[ic]=remain_id.tolist()\n",
    "                #classtomix_l[ic]=\"remain_group\" #use this to give another name \n",
    "                break #NOTE : break because this shoul be the last entry\n",
    "            if classtomix_df.iloc[ic] == 'add_remain_classes': # add the remaining \n",
    "                del classtomix_l[ic] #remove \"add_remain_classes\" from classes list\n",
    "                chosed_id=np.array([x for x in classtomix_l_catid if str(x) != 'nan' and str(x) !='[]'][0])\n",
    "                remain_id=np.setdiff1d(np.array(new_cat_l_id), chosed_id)\n",
    "                remain_id_l=remain_id.tolist()\n",
    "                remain_cat_l=[new_cat_l[new_cat_l_id.index(id)] for id in remain_id_l] #id to names\n",
    "                for remain_id in remain_id_l: classtomix_l_catid.append([remain_id])\n",
    "                for remain_cat in remain_cat_l: classtomix_l.append([remain_cat] )\n",
    "                break #NOTE : break because this shoul be the last entry \n",
    "        #2. if only classtomix_l empty - raise\n",
    "        if pd.isnull(classtomix_df.iloc[ic]) and not pd.isnull(classtomix_df_catid.iloc[ic]): \n",
    "            raise RuntimeError('only classtomix_l empty')\n",
    "        #3. if classtomix_l and classtomix_l_catid not empty - mantain\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Make sure everything is correct: \n",
      "1.Drop NaN if exist, but make sure the index is the same for the two! \n",
      "2.Put classtomix_l and classtomix_l_catid as a list of lists\n",
      "3. Change name of classes if you want\n",
      "\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('>> Make sure everything is correct: \\n1.Drop NaN if exist, but make sure the index is the same for the two! \\n2.Put classtomix_l and classtomix_l_catid as a list of lists\\n3. Change name of classes if you want\\n')\n",
    "fixempty=True\n",
    "if fixempty:\n",
    "    classtomix_l=[x for x in classtomix_l if str(x) != 'nan' and str(x) !='[]']\n",
    "    classtomix_l_catid=[x for x in classtomix_l_catid if str(x) != 'nan' and str(x) !='[]']\n",
    "#classtomix_l[1]=['non_aggressive'] #uncomment and change name\n",
    "print(len(classtomix_l))\n",
    "print(len(classtomix_l_catid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['non_aggressive']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 537, 538, 539, 540, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 840, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230]\n"
     ]
    }
   ],
   "source": [
    "print(classtomix_l[-1])\n",
    "print(classtomix_l_catid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mix classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow # newjson=copy.deepcopy(molajson) #do deepcopy to compare\n",
    "# fast\n",
    "newjson={'categories':[],'annotations':[] }\n",
    "newjson['categories']=copy.copy(molajson['categories'])\n",
    "newjson['annotations']=copy.copy(molajson['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "classtomix_l_catidx=[[cat_l_id.index(id) for id in id_l] for id_l in classtomix_l_catid]\n",
    "#print(classtomix_l_catidx) # they should be less one, becacuse it is ordered\n",
    "print(len(classtomix_l_catidx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change molajson['categories']: [{name: , id: }]  \n",
    "=>  1. use first index cat id; 2. change name and change id;  remove the other categories (!!!Without ordering again the category id!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230\n",
      "1228\n",
      "2\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CHANGE NAME  & GET REMOVE List\n",
    "keepidx_l=[]\n",
    "keepid_l=[]\n",
    "firstidx=0 # get first category id\n",
    "for i,id_l in enumerate(tqdm(classtomix_l_catid)): #for each classtomix\n",
    "    firstcatid=id_l[firstidx] # #category id \n",
    "    firstcatidx=classtomix_l_catidx[i][firstidx]# get cat index of first catid\n",
    "    if isinstance(classtomix_l[i], list): newjson['categories'][firstcatidx]['name']=classtomix_l[i][firstidx] #change name of first id \n",
    "    else: newjson['categories'][firstcatidx]['name']=classtomix_l[i]\n",
    "    assert newjson['categories'][firstcatidx]['id']==firstcatid #assert id - it should be the same\n",
    "    keepidx_l.append(firstcatidx) #catidx to keep\n",
    "    keepid_l.append(firstcatid) #catid to keep\n",
    "keepidx_l=list(dict.fromkeys(keepidx_l)) # remove duplicates in the keep list\n",
    "allidx_l=[index for index, value in enumerate(molajson['categories'])] # allidx in categories\n",
    "removeidx_l=[idx for idx in allidx_l if idx not in keepidx_l] # remove idx \n",
    "removeitem_l=[newjson['categories'][removeidx] for removeidx in removeidx_l] #remove items #WARNING NECESSARY BECAUSE THE INDEX WILL CHANGE\n",
    "print(len(allidx_l))\n",
    "print(len(removeidx_l))\n",
    "print(len(allidx_l)-len(removeidx_l))\n",
    "print(keepidx_l in removeidx_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# REMOVE - newjson will be changed\n",
    "for removeitem in removeitem_l: newjson['categories'].remove(removeitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frequency': 'f', 'id': 59, 'synset': 'baseball_cap.n.01', 'image_count': 70, 'instance_count': 248, 'synonyms': ['baseball_cap', 'jockey_cap', 'golf_cap'], 'def': 'a cap with a bill', 'name': 'aggressive'}\n",
      "{'frequency': 'c', 'id': 1230, 'synset': 'zucchini.n.02', 'image_count': 1, 'instance_count': 7, 'synonyms': ['zucchini', 'courgette'], 'def': 'small cucumber-shaped vegetable marrow; typically dark green', 'name': 'zucchini'}\n"
     ]
    }
   ],
   "source": [
    "print(newjson['categories'][-1])\n",
    "print(molajson['categories'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REORDER IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2002.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 1]\n",
      "[1, 0]\n",
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# GET NEW IDs - REORDER IDs - #WARNING after remove\n",
    "ct_l_id=[]\n",
    "for i,c in enumerate(tqdm(newjson['categories'])):\n",
    "    ct_l_id.append(c['id'])\n",
    "newidx_l=[ct_l_id.index(id) for id in keepid_l] # make sure same sequence of keepid_l #SAME ORDER AS EXCEL\n",
    "newid_l=[i+1 for i in range(len(keepid_l))] #reorder keepid_l\n",
    "print(keepid_l)\n",
    "print(newidx_l)\n",
    "print(newid_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SORT IDS - Reorder based on Excel order - newjson will be changed\n",
    "categories_l=copy.copy(newjson['categories'])\n",
    "for i,idx in enumerate(newidx_l):\n",
    "    categories_l[idx]['id']=newid_l[i]\n",
    "for i,idx in enumerate(newidx_l):\n",
    "    newjson['categories'][i]=categories_l[idx] #TODO sort the id in the correct sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1230\n",
      "{'frequency': 'r', 'id': 2, 'synset': 'acorn.n.01', 'image_count': 0, 'instance_count': 0, 'synonyms': ['acorn'], 'def': 'nut from an oak tree', 'name': 'non_aggressive'}\n",
      "{'frequency': 'c', 'id': 1230, 'synset': 'zucchini.n.02', 'image_count': 1, 'instance_count': 7, 'synonyms': ['zucchini', 'courgette'], 'def': 'small cucumber-shaped vegetable marrow; typically dark green', 'name': 'zucchini'}\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(len(categories_l))\n",
    "print(len(newjson['categories']))\n",
    "print(len(molajson['categories']))\n",
    "print(newjson['categories'][-1])\n",
    "print(molajson['categories'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: REMOVE HYPERPARAMETERS? Mantain only id and NAME? OR irrelevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change molajson['annotations']: [{category_id: , }] \n",
    "=> 1.get annotation idx from catid; 2.update annotations id ; 3. update newjson['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aggressive'], ['non_aggressive']]\n",
      "[[59, 137, 177, 263, 312, 360, 407, 460, 476, 534, 541, 552, 574, 596, 626, 628, 672, 731, 826, 829, 839, 841, 861, 889, 900, 943, 986, 1027, 1067, 1176, 1191], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 535, 536, 537, 538, 539, 540, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 827, 828, 830, 831, 832, 833, 834, 835, 836, 837, 838, 840, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230]]\n",
      "[59, 1]\n",
      "[1, 2]\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "# 1.get annotation idx from classtomix_l_catid\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "classtomix_l_ann_catidx=[[np.where(ann_catid_np==id)[0].tolist()  for id in id_l] for id_l in classtomix_l_catid]\n",
    "print(classtomix_l)\n",
    "print(classtomix_l_catid)\n",
    "print(keepid_l)\n",
    "print(newid_l)\n",
    "print(len(classtomix_l_ann_catidx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83875\n",
      "83875\n"
     ]
    }
   ],
   "source": [
    "#2.update annotations ids & 3. update newjson['annotations'] with only the annotations frow classtomix_l_catid\n",
    "newjson['annotations']=copy.copy(molajson['annotations']) #reset annotations\n",
    "copy_ann_l=copy.copy(newjson['annotations'])\n",
    "newjson['annotations']=[] #clear\n",
    "for i, ann_catidx_l in enumerate(classtomix_l_ann_catidx): #only append annotations that \n",
    "    for catidx_l in ann_catidx_l:\n",
    "        for catidx in catidx_l:\n",
    "            copy_ann_l[catidx]['category_id']=newid_l[i] # update catid\n",
    "            newjson['annotations'].append(copy_ann_l[catidx]) #update newjson with only the  (annotations sequence id will be lost\n",
    "print(len(molajson['annotations']))\n",
    "print(len(newjson['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segmentation': [[946, 388, 1121, 388, 1121, 438, 946, 438]], 'bbox': [946, 388, 175, 50], 'area': 8750, 'iscrowd': 0, 'id': 107417, 'image_id': 24033, 'category_id': 2, 'track_id': 3880, '_scale_uuid': '2b951a18-d685-4b44-a43e-7b834eaaade6', 'scale_category': 'moving object', 'video_id': 612}\n",
      "{'segmentation': [[621, 234, 813, 234, 813, 379, 621, 379]], 'bbox': [621, 234, 192, 145], 'area': 27840, 'iscrowd': 0, 'id': 331425, 'image_id': 89466, 'category_id': 2, 'track_id': 14355, '_scale_uuid': 'e9194b27-7a6c-48b0-baee-4e1a3988b270', 'scale_category': 'pet', 'video_id': 2362}\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(molajson['annotations'][-1])\n",
    "print(newjson['annotations'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save mixed json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fast\n",
    "molajson['categories']=copy.copy(newjson['categories'])\n",
    "molajson['annotations']=copy.copy(newjson['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : D:/external_datasets/MOLA/annotations/split_tao_original/train_mix.json \n",
      "\n",
      "info 6\n",
      "images 54649\n",
      "annotations 83875\n",
      "categories 2\n",
      "licenses 1\n",
      "videos 1488\n",
      "tracks 8132\n",
      "['aggressive', 'non_aggressive']\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+'annotations/'+injsonfile+'_mix.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(molajson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))\n",
    "cat_l=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "print(cat_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TEST MIX ANNOTATIONS DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/external_datasets/MOLA/annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-77bb2e66d99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmolajson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/external_datasets/MOLA/annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'"
     ]
    }
   ],
   "source": [
    "molajson = json.load(open(rdir+'annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# annotations category_id\n",
    "ann_ids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_ids.append(an['id'])\n",
    "print(len(ann_ids))\n",
    "\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(cat_l))\n",
    "print(cat_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
