{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix/Fusion of Classes=Categories\n",
    "version: 1\n",
    "\n",
    "info: \n",
    "- mix/fusion: of classes into other classes\n",
    "    0. If not mola.json : Manually add dataset descriptors when importing id, e.g. COCO(see below)\n",
    "- reorder_ids: It also reorders category id\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux-5.11.0-34-generic-x86_64-with-glibc2.10\n",
      "root datasets dir: /home/user/Data/Datasets/External Datasets/\n",
      "root dir: /home/user/Data/Datasets/External Datasets/MOLA/\n"
     ]
    }
   ],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir_dsets='D:/external_datasets/' #WARNING: DATASETS ROOT is OK?\n",
    "rdir='D:/external_datasets/MOLA/' \n",
    "#/home/user/Data/Datasets/External Datasets/MOLA/\n",
    "if str(platform.platform()).find('Linux')>-1:\n",
    "    rdir_dsets=rdir_dsets.replace('D:/external_datasets/','/home/user/Data/Datasets/External Datasets/')\n",
    "    rdir=rdir.replace('D:/external_datasets/','/home/user/Data/Datasets/External Datasets/')\n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root datasets dir: {}'.format(rdir_dsets))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 9\n",
      "categories 373\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 247051\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "#jsonfile\n",
    "injsonfile=\"splitann_mola_fix_equal_reorder_cleanclass_cleanimg/val\" #\"split_mola_fix_equal/test\"\n",
    "molajson =  json.load(open(rdir+'annotations/'+injsonfile+'.json'))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import ids\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COCO', 'TAO'] [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# datasets name and id\n",
    "dset_l=[]\n",
    "dset_l_id=[]\n",
    "try:\n",
    "    for d in molajson['datasets']:\n",
    "        dset_l.append(d['name'])\n",
    "        dset_l_id.append(d['id'])\n",
    "except: #manually add for example for only COCO\n",
    "    dset_l=['TAO']\n",
    "    dset_l_id=[1]\n",
    "print(dset_l, dset_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "cat_l_id=[]\n",
    "cat_l_dset=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "    cat_l_id.append(c['id'])\n",
    "    try:\n",
    "        cat_l_dset.append(dset_l[c['dataset']-1]) # dset_l index is same as id-1\n",
    "    except:\n",
    "        cat_l_dset.append(dset_l[0])\n",
    "#print(cat_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "img_l=[]\n",
    "img_l_id=[]\n",
    "for c in molajson['images']:\n",
    "    img_l.append(c['file_name'])\n",
    "    img_l_id.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247051/247051 [00:00<00:00, 1383888.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "ann_dset=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "    try:\n",
    "        ann_dset.append(an['dataset'])\n",
    "    except:\n",
    "        ann_dset.append(dset_l_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find mixers cat_ids\n",
    "mixers example\n",
    "categories= [{name:cow, id:1, dataset:1},...,{name:cow, id:200, dataset:2},...,{name:cow, id:101, dataset:3}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane']\n",
      "[[1], [2], [3], [4], [5]]\n",
      "[['COCO'], ['COCO'], ['COCO'], ['COCO'], ['COCO']]\n",
      "373\n",
      "373\n",
      "373\n"
     ]
    }
   ],
   "source": [
    "#mixers #TODO: SORT alphabetically\n",
    "mixers_l=[]\n",
    "mixers_l_catid=[]\n",
    "mixers_l_catdset=[]\n",
    "mixer_method=\"all_cats\"\n",
    "if mixer_method==\"all_cats\": #Do for all category names, even with equal \n",
    "    mixers_l=cat_l\n",
    "    mixers_l_catid=[[id] for id in cat_l_id]\n",
    "    mixers_l_catdset=[[dset] for dset in cat_l_dset]\n",
    "    \n",
    "\n",
    "print(mixers_l[0:5])\n",
    "print(mixers_l_catid[0:5])\n",
    "print(mixers_l_catdset[0:5])\n",
    "print(len(mixers_l))\n",
    "print(len(mixers_l_catid))\n",
    "print(len(mixers_l_catdset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 373/373 [00:00<00:00, 1844.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# get annotations mixers\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "ann_imgid_np=np.array(ann_imgid)\n",
    "ann_bbox_np=np.array(ann_bbox)\n",
    "ann_dset_np=np.array(ann_dset)\n",
    "mixers_l_imgid=[]\n",
    "mixers_l_bbox=[]\n",
    "mixers_l_dset=[]\n",
    "for catids in tqdm(mixers_l_catid):\n",
    "    l_imgid=[]\n",
    "    l_bbox=[]\n",
    "    l_dset=[]\n",
    "    for catid in catids:\n",
    "        ann_idx = np.where(ann_catid_np==catid)[0].tolist() #annotation index of ids\n",
    "        l_imgid.append(ann_imgid_np[ann_idx].tolist())\n",
    "        l_bbox.append(ann_bbox_np[ann_idx].tolist())\n",
    "        l_dset.append(ann_dset_np[ann_idx].tolist())\n",
    "    mixers_l_imgid.append(l_imgid)\n",
    "    mixers_l_bbox.append(l_bbox)\n",
    "    mixers_l_dset.append(l_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classes|categories to mix w/ EXCEL report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INIT VARS\n",
    "classtomix_l=[]\n",
    "classtomix_l_catid=[]\n",
    "method=\"\" #\"save_images\": to save new images and create excel report for manual inspection and build classtomix_l; \"\": use a saved excel report, uncomment excelpath\n",
    "datadir=\"mixers/\"+injsonfile+\"/\" #root folder to save mixer method . #WARNING mixers/original json that was used to save images and excel\n",
    "folder=mixer_method+'/' #folder to save images and exel \n",
    "showimage=False #show images\n",
    "startidx=0 # start index of image to save from each dataset\n",
    "imgnr=1 # total number of images to save from each dataset\n",
    "imgstep='random' # step between images: int | 'random' - int steps between images; 'rand' gets random list\n",
    "#paths\n",
    "path=os.path.join(rdir,datadir,folder) #path to folder\n",
    "assure_path_exists(path)\n",
    "excelpath=path+mixer_method+\"_v1.xlsx\"#path+mixer_method+\"_classtomix_report.xlsx\"#path to excel\n",
    "#fixed path - if method=\"\"\n",
    "if not method: excelpath=rdir+\"mixers/mola_fix_equal_reorder_cleanclass_cleanimg/mix_coco_and_tao_aggressive_2c.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#METHODS\n",
    "if method==\"save_images\": # save images and excel report to folder for manual edit the classtomix_l\n",
    "    df=pd.DataFrame({'mixers_l': mixers_l,'mixers_l_catid': mixers_l_catid, 'mixers_l_catdset': mixers_l_catdset, 'classtomix_l': np.nan, 'classtomix_l_catid':np.nan, 'rules':np.nan })\n",
    "    df.loc[0, 'rules']=\"To fix classes: 1) You need to fill the column classtomix_l and/or classtomix_l_catid with the information from the respective mixer columns; 2) When copy/pasting or changing, make sure the same structure maintains:  ['car', 'carrot'], [3, 52], beware of the spaces ['car', '  and always maintain the first class in the list;  3) You have 3 possibilities of filling the columns : 1-the 2 columns empty, meaning the row will not be used for classtomix; 2-only one column empty, e.g. fill the classtotix_l row with the class labels from mixers_l, then during the importing the classtomix_l_catid is filled, and vice-versa; 3-If you want to change the name of the first class in the list,e.g ['car', 'carrot'] for ['automobile', 'carrot'] you need to provide the ids to classtomix_l_catid.\"\n",
    "    df['annotations_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    df['images_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    #save image for each mixer\n",
    "    for i, mixer in enumerate(tqdm(mixers_l)): #run for each mixer category\n",
    "        firstclass=mixer\n",
    "        if isinstance(firstclass, list): firstclass=firstclass[0] #first class\n",
    "        print('\\n>> '+firstclass+'...') #class\n",
    "        classpath=os.path.join(path, firstclass) # path to folder for images of  firstclass\n",
    "        classpath=parse_path(classpath)+'/' #make it a folder\n",
    "        assure_path_exists(classpath)\n",
    "        df=save_imgs(df, rdir_dsets, classpath, i, dset_l, mixers_l, mixers_l_catid, mixers_l_bbox, mixers_l_dset,\n",
    "              mixers_l_imgid, img_l, img_l_id, startidx=startidx, imgnr=imgnr, imgstep=imgstep, showimage=showimage)    \n",
    "    df.to_excel(excelpath, index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mixers_l</th>\n",
       "      <th>mixers_l_catid</th>\n",
       "      <th>mixers_l_catdset</th>\n",
       "      <th>classtomix_l</th>\n",
       "      <th>classtomix_l_catid</th>\n",
       "      <th>rules</th>\n",
       "      <th>annotations_missing</th>\n",
       "      <th>images_missing</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>aggressive_keywords</th>\n",
       "      <th>class</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>person</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['COCO']</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>[35, 43, 44, 45, 105, 113, 131, 165, 190, 192,...</td>\n",
       "      <td>To fix classes: 1) You need to fill the column...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>knife</td>\n",
       "      <td>knife(44), butcher_knife(113)</td>\n",
       "      <td>Só adicionei ids com annotations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>[2]</td>\n",
       "      <td>['COCO']</td>\n",
       "      <td>group_remain_classes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>weapon</td>\n",
       "      <td>bow_(weapon)(105)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>car</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['COCO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gun</td>\n",
       "      <td>gun(190)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>[4]</td>\n",
       "      <td>['COCO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bat</td>\n",
       "      <td>baseball bat(35)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airplane</td>\n",
       "      <td>[5]</td>\n",
       "      <td>['COCO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fork</td>\n",
       "      <td>fork(43)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>water_ski</td>\n",
       "      <td>[369]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>wig</td>\n",
       "      <td>[370]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>windshield_wiper</td>\n",
       "      <td>[371]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>wineglass</td>\n",
       "      <td>[372]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>wooden_spoon</td>\n",
       "      <td>[373]</td>\n",
       "      <td>['TAO']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             mixers_l mixers_l_catid mixers_l_catdset          classtomix_l  \\\n",
       "0              person            [1]         ['COCO']            aggressive   \n",
       "1             bicycle            [2]         ['COCO']  group_remain_classes   \n",
       "2                 car            [3]         ['COCO']                   NaN   \n",
       "3          motorcycle            [4]         ['COCO']                   NaN   \n",
       "4            airplane            [5]         ['COCO']                   NaN   \n",
       "..                ...            ...              ...                   ...   \n",
       "368         water_ski          [369]          ['TAO']                   NaN   \n",
       "369               wig          [370]          ['TAO']                   NaN   \n",
       "370  windshield_wiper          [371]          ['TAO']                   NaN   \n",
       "371         wineglass          [372]          ['TAO']                   NaN   \n",
       "372      wooden_spoon          [373]          ['TAO']                   NaN   \n",
       "\n",
       "                                    classtomix_l_catid  \\\n",
       "0    [35, 43, 44, 45, 105, 113, 131, 165, 190, 192,...   \n",
       "1                                                  NaN   \n",
       "2                                                  NaN   \n",
       "3                                                  NaN   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "368                                                NaN   \n",
       "369                                                NaN   \n",
       "370                                                NaN   \n",
       "371                                                NaN   \n",
       "372                                                NaN   \n",
       "\n",
       "                                                 rules annotations_missing  \\\n",
       "0    To fix classes: 1) You need to fill the column...                 [0]   \n",
       "1                                                  NaN                 [0]   \n",
       "2                                                  NaN                 [0]   \n",
       "3                                                  NaN                 [0]   \n",
       "4                                                  NaN                 [0]   \n",
       "..                                                 ...                 ...   \n",
       "368                                                NaN                 [0]   \n",
       "369                                                NaN                 [0]   \n",
       "370                                                NaN                 [0]   \n",
       "371                                                NaN                 [0]   \n",
       "372                                                NaN                 [0]   \n",
       "\n",
       "    images_missing  Unnamed: 8 aggressive_keywords  \\\n",
       "0              [0]         NaN               knife   \n",
       "1              [0]         NaN              weapon   \n",
       "2              [0]         NaN                 gun   \n",
       "3              [0]         NaN                 bat   \n",
       "4              [0]         NaN                fork   \n",
       "..             ...         ...                 ...   \n",
       "368            [0]         NaN                 NaN   \n",
       "369            [0]         NaN                 NaN   \n",
       "370            [0]         NaN                 NaN   \n",
       "371            [0]         NaN                 NaN   \n",
       "372            [0]         NaN                 NaN   \n",
       "\n",
       "                             class                             notes  \n",
       "0    knife(44), butcher_knife(113)  Só adicionei ids com annotations  \n",
       "1                bow_(weapon)(105)                               NaN  \n",
       "2                         gun(190)                               NaN  \n",
       "3                 baseball bat(35)                               NaN  \n",
       "4                         fork(43)                               NaN  \n",
       "..                             ...                               ...  \n",
       "368                            NaN                               NaN  \n",
       "369                            NaN                               NaN  \n",
       "370                            NaN                               NaN  \n",
       "371                            NaN                               NaN  \n",
       "372                            NaN                               NaN  \n",
       "\n",
       "[373 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IMPORT EXCEL MANUAL EDIT #WARNING: CHECK EXCEL FIRST (#NOTE: donte use classes with missing annotations and images)\n",
    "df=pd.read_excel(excelpath)\n",
    "classtomix_df=df.loc[:,'classtomix_l']\n",
    "classtomix_df_catid=df.loc[:,'classtomix_l_catid']\n",
    "new_cat_l=copy.deepcopy(cat_l)\n",
    "new_cat_l_id=copy.deepcopy(cat_l_id)\n",
    "display(df)\n",
    "\n",
    "# PARSE COLUMNS TO FIX\n",
    "classtomix_l=classtomix_df.tolist()\n",
    "classtomix_l_catid=classtomix_df_catid.tolist()\n",
    "#convert strings to lists\n",
    "for icl, cl in enumerate(classtomix_l): \n",
    "    if isinstance(classtomix_l[icl], str): classtomix_l[icl]=convert_unicode(classtomix_l[icl], method='liststr')\n",
    "    if isinstance(classtomix_l_catid[icl], str): classtomix_l_catid[icl]=convert_unicode(classtomix_l_catid[icl], method='listnum')\n",
    "\n",
    "\n",
    "#parse the columns(classtomix_l, classtomix_l_catid) based on the rules\n",
    "#0. if both columns are empty\n",
    "if classtomix_df.isnull().all() or classtomix_df_catid.isnull().all():\n",
    "    raise RuntimeError(\"Go Back to the excel and add something to classtomix_l and classtomix_l_catid\")\n",
    "else:\n",
    "    for ic, classes in enumerate(classtomix_df):\n",
    "        #1. if only classtomix_l_catid empty - get \n",
    "        if not pd.isnull(classtomix_df.iloc[ic]) and pd.isnull(classtomix_df_catid.iloc[ic]):\n",
    "            if classtomix_df.iloc[ic] == 'group_remain_classes': # group the remaining ids \n",
    "                chosed_id=np.array([x for x in classtomix_l_catid if str(x) != 'nan' and str(x) !='[]'][0])\n",
    "                remain_id=np.setdiff1d(np.array(new_cat_l_id), chosed_id)\n",
    "                classtomix_l_catid[ic]=remain_id.tolist()\n",
    "                classtomix_l[ic]=\"non_aggressive\" #use this to give another name \n",
    "                break #NOTE : break because this shoul be the last entry\n",
    "            if classtomix_df.iloc[ic] == 'add_remain_classes': # add the remaining \n",
    "                del classtomix_l[ic] #remove \"add_remain_classes\" from classes list\n",
    "                chosed_id=np.array([x for x in classtomix_l_catid if str(x) != 'nan' and str(x) !='[]'][0])\n",
    "                remain_id=np.setdiff1d(np.array(new_cat_l_id), chosed_id)\n",
    "                remain_id_l=remain_id.tolist()\n",
    "                remain_cat_l=[new_cat_l[new_cat_l_id.index(id)] for id in remain_id_l] #id to names\n",
    "                for remain_id in remain_id_l: classtomix_l_catid.append([remain_id])\n",
    "                for remain_cat in remain_cat_l: classtomix_l.append([remain_cat] )\n",
    "                break #NOTE : break because this shoul be the last entry \n",
    "        #2. if only classtomix_l empty - raise\n",
    "        if pd.isnull(classtomix_df.iloc[ic]) and not pd.isnull(classtomix_df_catid.iloc[ic]): \n",
    "            raise RuntimeError('only classtomix_l empty')\n",
    "        #3. if classtomix_l and classtomix_l_catid not empty - mantain\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Make sure everything is correct: \n",
      "1.Drop NaN if exist, but make sure the index is the same for the two! \n",
      "2.Put classtomix_l and classtomix_l_catid as a list of lists\n",
      "3. Change name of classes if you want\n",
      "\n",
      "2\n",
      "2\n",
      "non_aggressive\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n"
     ]
    }
   ],
   "source": [
    "print('>> Make sure everything is correct: \\n1.Drop NaN if exist, but make sure the index is the same for the two! \\n2.Put classtomix_l and classtomix_l_catid as a list of lists\\n3. Change name of classes if you want\\n')\n",
    "fixempty=True\n",
    "if fixempty:\n",
    "    classtomix_l=[x for x in classtomix_l if str(x) != 'nan' and str(x) !='[]']\n",
    "    classtomix_l_catid=[x for x in classtomix_l_catid if str(x) != 'nan' and str(x) !='[]']\n",
    "#classtomix_l[1]=['non_aggressive'] #uncomment and change name\n",
    "print(len(classtomix_l))\n",
    "print(len(classtomix_l_catid))\n",
    "print(classtomix_l[-1])\n",
    "print(classtomix_l_catid[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mix classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# slow # newjson=copy.deepcopy(molajson) #do deepcopy to compare\n",
    "# fast\n",
    "newjson={'categories':[],'annotations':[] }\n",
    "newjson['categories']=copy.copy(molajson['categories'])\n",
    "newjson['annotations']=copy.copy(molajson['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "classtomix_l_catidx=[[cat_l_id.index(id) for id in id_l] for id_l in classtomix_l_catid]\n",
    "#print(classtomix_l_catidx) # they should be less one, becacuse it is ordered\n",
    "print(len(classtomix_l_catidx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change molajson['categories']: [{name: , id: }]  \n",
    "=>  1. use first index cat id; 2. change name and change id;  remove the other categories (!!!Without ordering again the category id!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 25040.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n",
      "371\n",
      "2\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CHANGE NAME  & GET REMOVE List\n",
    "keepidx_l=[]\n",
    "keepid_l=[]\n",
    "firstidx=0 # get first category id\n",
    "for i,id_l in enumerate(tqdm(classtomix_l_catid)): #for each classtomix\n",
    "    firstcatid=id_l[firstidx] # #category id \n",
    "    firstcatidx=classtomix_l_catidx[i][firstidx]# get cat index of first catid\n",
    "    if isinstance(classtomix_l[i], list): newjson['categories'][firstcatidx]['name']=classtomix_l[i][firstidx] #change name of first id \n",
    "    else: newjson['categories'][firstcatidx]['name']=classtomix_l[i]\n",
    "    assert newjson['categories'][firstcatidx]['id']==firstcatid #assert id - it should be the same\n",
    "    keepidx_l.append(firstcatidx) #catidx to keep\n",
    "    keepid_l.append(firstcatid) #catid to keep\n",
    "keepidx_l=list(dict.fromkeys(keepidx_l)) # remove duplicates in the keep list\n",
    "allidx_l=[index for index, value in enumerate(molajson['categories'])] # allidx in categories\n",
    "removeidx_l=[idx for idx in allidx_l if idx not in keepidx_l] # remove idx \n",
    "removeitem_l=[newjson['categories'][removeidx] for removeidx in removeidx_l] #remove items #WARNING NECESSARY BECAUSE THE INDEX WILL CHANGE\n",
    "print(len(allidx_l))\n",
    "print(len(removeidx_l))\n",
    "print(len(allidx_l)-len(removeidx_l))\n",
    "print(keepidx_l in removeidx_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# REMOVE - newjson will be changed\n",
    "for removeitem in removeitem_l: newjson['categories'].remove(removeitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supercategory': 'sports', 'id': 35, 'name': 'aggressive', 'dataset': 1}\n",
      "{'frequency': 'c', 'id': 373, 'synset': 'wooden_spoon.n.02', 'image_count': 3, 'instance_count': 4, 'synonyms': ['wooden_spoon'], 'def': 'a spoon made of wood', 'name': 'wooden_spoon', 'dataset': 2}\n"
     ]
    }
   ],
   "source": [
    "print(newjson['categories'][-1])\n",
    "print(molajson['categories'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REORDER IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 41323.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 1]\n",
      "[1, 0]\n",
      "[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# GET NEW IDs - REORDER IDs - #WARNING after remove\n",
    "ct_l_id=[]\n",
    "for i,c in enumerate(tqdm(newjson['categories'])):\n",
    "    ct_l_id.append(c['id'])\n",
    "newidx_l=[ct_l_id.index(id) for id in keepid_l] # make sure same sequence of keepid_l #SAME ORDER AS EXCEL\n",
    "newid_l=[i+1 for i in range(len(keepid_l))] #reorder keepid_l\n",
    "print(keepid_l)\n",
    "print(newidx_l)\n",
    "print(newid_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SORT IDS - Reorder based on Excel order - newjson will be changed\n",
    "categories_l=copy.copy(newjson['categories'])\n",
    "for i,idx in enumerate(newidx_l):\n",
    "    categories_l[idx]['id']=newid_l[i]\n",
    "for i,idx in enumerate(newidx_l):\n",
    "    newjson['categories'][i]=categories_l[idx] #TODO sort the id in the correct sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "373\n",
      "{'supercategory': 'person', 'id': 2, 'name': 'non_aggressive', 'keypoints': ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle'], 'skeleton': [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12], [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3], [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]], 'dataset': 1}\n",
      "{'frequency': 'c', 'id': 373, 'synset': 'wooden_spoon.n.02', 'image_count': 3, 'instance_count': 4, 'synonyms': ['wooden_spoon'], 'def': 'a spoon made of wood', 'name': 'wooden_spoon', 'dataset': 2}\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(len(categories_l))\n",
    "print(len(newjson['categories']))\n",
    "print(len(molajson['categories']))\n",
    "print(newjson['categories'][-1])\n",
    "print(molajson['categories'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: REMOVE HYPERPARAMETERS? Mantain only id and NAME? OR irrelevant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### change molajson['annotations']: [{category_id: , }] \n",
    "=> 1.get annotation idx from catid; 2.update annotations id ; 3. update newjson['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aggressive'], 'non_aggressive']\n",
      "[[35, 43, 44, 45, 105, 113, 131, 165, 190, 192, 202, 207, 213, 270, 274, 288, 293, 309, 330, 361, 373], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 191, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]]\n",
      "[35, 1]\n",
      "[1, 2]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# 1.get annotation idx from classtomix_l_catid\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "classtomix_l_ann_catidx=[[np.where(ann_catid_np==id)[0].tolist()  for id in id_l] for id_l in classtomix_l_catid]\n",
    "print(classtomix_l)\n",
    "print(classtomix_l_catid)\n",
    "print(keepid_l)\n",
    "print(newid_l)\n",
    "print(len(classtomix_l_ann_catidx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247051\n",
      "247051\n"
     ]
    }
   ],
   "source": [
    "#2.update annotations ids & 3. update newjson['annotations'] with only the annotations frow classtomix_l_catid\n",
    "newjson['annotations']=copy.copy(molajson['annotations']) #reset annotations\n",
    "copy_ann_l=copy.copy(newjson['annotations'])\n",
    "newjson['annotations']=[] #clear\n",
    "for i, ann_catidx_l in enumerate(classtomix_l_ann_catidx): #only append annotations that \n",
    "    for catidx_l in ann_catidx_l:\n",
    "        for catidx in catidx_l:\n",
    "            copy_ann_l[catidx]['category_id']=newid_l[i] # update catid\n",
    "            newjson['annotations'].append(copy_ann_l[catidx]) #update newjson with only the  (annotations sequence id will be lost\n",
    "print(len(molajson['annotations']))\n",
    "print(len(newjson['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segmentation': [[774, 551, 801, 551, 801, 618, 774, 618]], 'bbox': [774, 551, 27, 67], 'area': 1809, 'iscrowd': 0, 'id': 1337238, 'image_id': 177630, 'category_id': 2, 'track_id': 8097, '_scale_uuid': '1743830b-3d91-4b76-84a2-fad35db6fe53', 'scale_category': 'object_moved_by_person', 'video_id': 1479, 'dataset': 2}\n",
      "{'segmentation': [[774, 551, 801, 551, 801, 618, 774, 618]], 'bbox': [774, 551, 27, 67], 'area': 1809, 'iscrowd': 0, 'id': 1337238, 'image_id': 177630, 'category_id': 2, 'track_id': 8097, '_scale_uuid': '1743830b-3d91-4b76-84a2-fad35db6fe53', 'scale_category': 'object_moved_by_person', 'video_id': 1479, 'dataset': 2}\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(molajson['annotations'][-1])\n",
    "print(newjson['annotations'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save mixed json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fast\n",
    "molajson['categories']=copy.copy(newjson['categories'])\n",
    "molajson['annotations']=copy.copy(newjson['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : /home/user/Data/Datasets/External Datasets/MOLA/annotations/splitann_mola_fix_equal_reorder_cleanclass_cleanimg/val_mix.json \n",
      "\n",
      "info 5\n",
      "licenses 9\n",
      "categories 2\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 247051\n",
      "datasets 2\n",
      "['aggressive', 'non_aggressive']\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+'annotations/'+injsonfile+'_mix.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(molajson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))\n",
    "cat_l=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "print(cat_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TEST MIX ANNOTATIONS DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/external_datasets/MOLA/annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-77bb2e66d99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmolajson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/external_datasets/MOLA/annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'"
     ]
    }
   ],
   "source": [
    "molajson = json.load(open(rdir+'annotations/split_mola_fix_equal_reorder_nomissings/mix_aggressive_addremainclasses/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# annotations category_id\n",
    "ann_ids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_ids.append(an['id'])\n",
    "print(len(ann_ids))\n",
    "\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "for c in molajson['categories']:\n",
    "    cat_l.append(c['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(cat_l))\n",
    "print(cat_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
