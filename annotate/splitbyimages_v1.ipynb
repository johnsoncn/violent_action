{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split datasets\n",
    "version: 1\n",
    "\n",
    "info:\n",
    "- split json into train.json, val.json and test.json \n",
    "\n",
    "### WARNING: splitbyimages is not ideal (use splitbyannotations) -> because you can fail to have all the classes in train (or val,or test). This was done, because some datasets like tao are missing annotations and images\n",
    "\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.21292-SP0\n",
      "root dir: D:/external_datasets/MOLA/annotations/\n"
     ]
    }
   ],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/MOLA/annotations/' \n",
    "if str(platform.platform()).find('linux')>-1: rdir=rdir.replace('D:/','/mnt/d/')\n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=70\n",
    "val=20\n",
    "test=100-(train+val)\n",
    "injsonfile='coco2017_reorder_cleanclass.json'\n",
    "infilename=injsonfile.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 1170251\n",
      "categories 80\n"
     ]
    }
   ],
   "source": [
    "# init json\n",
    "molajson =  json.load(open(rdir+injsonfile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import ids\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories id\n",
    "cats=[]\n",
    "catids=[]\n",
    "for c in molajson['categories']:\n",
    "    catids.append(c['id'])\n",
    "    cats.append(c['name'])\n",
    "#print(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "imgs=[]\n",
    "imgids=[]\n",
    "for c in molajson['images']:\n",
    "    imgs.append(c['file_name'])\n",
    "    imgids.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1170251/1170251 [00:01<00:00, 1079964.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id\n",
    "ann_catids=[]\n",
    "ann_ids=[]\n",
    "ann_imgids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_catids.append(an['category_id'])\n",
    "    ann_ids.append(an['id'])\n",
    "    ann_imgids.append(an['image_id'])\n",
    "print(len(ann_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273469\n"
     ]
    }
   ],
   "source": [
    "#TEST dupplicates v1 - slow\n",
    "# duplicates_l=list(set([x for x in ann_ids if ann_ids.count(x) > 1])) # duplicates l \n",
    "#TEST dupplicates v2 - fast\n",
    "#from collections import Counter\n",
    "#duplicates_l=[item for item, count in Counter(ann_ids).items() if count > 1]\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. split by images\n",
    "#QUESTION Seeded random or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.99926999602553\n",
      "19.99805332273476\n",
      "9.998621103603785\n"
     ]
    }
   ],
   "source": [
    "#init\n",
    "train_imgids=[]\n",
    "val_imgids=[]\n",
    "test_imgids=[]\n",
    "\n",
    "#size\n",
    "train_size=len(imgids) * train // 100 #floor division\n",
    "val_size=len(imgids) * val // 100\n",
    "test_size=len(imgids) * test // 100\n",
    "\n",
    "#select images\n",
    "random.shuffle(imgids) \n",
    "train_imgids.extend(imgids[:train_size])\n",
    "val_imgids.extend(imgids[train_size+1:train_size+val_size-1])\n",
    "test_imgids.extend(imgids[train_size+val_size+1:train_size+val_size+test_size])\n",
    "\n",
    "\n",
    "print((len(train_imgids)/len(imgids))*100)\n",
    "print((len(val_imgids)/len(imgids))*100)\n",
    "print((len(test_imgids)/len(imgids))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 86300/86300 [02:17<00:00, 627.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 24655/24655 [00:40<00:00, 614.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 12327/12327 [00:19<00:00, 628.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.601017217673816\n",
      "0.6805377649752061\n",
      "0.4258915395073365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ann_catids_np=np.array(ann_catids)\n",
    "train_ann_catidx=[]\n",
    "val_ann_catidx=[]\n",
    "test_ann_catidx=[]\n",
    "for imgid in tqdm(train_imgids):\n",
    "    ann_idx_np = np.where(ann_catids_np==imgid)[0] #annotation index of ids\n",
    "    if not ann_idx_np.any(): continue    \n",
    "    train_ann_catidx.extend(ann_idx_np.tolist())\n",
    "for imgid in tqdm(val_imgids):\n",
    "    ann_idx_np = np.where(ann_catids_np==imgid)[0] #annotation index of ids\n",
    "    if not ann_idx_np.any(): continue    \n",
    "    val_ann_catidx.extend(ann_idx_np.tolist())\n",
    "for imgid in tqdm(test_imgids):\n",
    "    ann_idx_np = np.where(ann_catids_np==imgid)[0] #annotation index of ids\n",
    "    if not ann_idx_np.any(): continue    \n",
    "    test_ann_catidx.extend(ann_idx_np.tolist())\n",
    "\n",
    "print((len(train_ann_catidx)/len(ann_catids))*100)\n",
    "print((len(val_ann_catidx)/len(ann_catids))*100)\n",
    "print((len(test_ann_catidx)/len(ann_catids))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  112356\n",
      "duplicate:  0\n",
      "original:  7964\n",
      "duplicate:  0\n",
      "original:  4984\n",
      "duplicate:  0\n"
     ]
    }
   ],
   "source": [
    "l_dup=[train_ann_catidx, val_ann_catidx,test_ann_catidx ]\n",
    "for i in l_dup:\n",
    "    print('original: ', len(i))\n",
    "    u, c = np.unique(np.array(i), return_counts=True)\n",
    "    duplicates_l= u[c > 1].tolist()\n",
    "    print('duplicate: ',len(duplicates_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save splited jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_idx=[train_ann_catidx,val_ann_catidx, test_ann_catidx]\n",
    "percent_names=['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "newjson=copy.copy(molajson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▎                                                      | 1/3 [00:15<00:31, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/MOLA/annotations/splitimg_coco2017_reorder_cleanclass/train.json \n",
      "\n",
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 112356\n",
      "categories 80\n",
      "\n",
      " >> SAVING val...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████▋                           | 2/3 [00:20<00:12, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/MOLA/annotations/splitimg_coco2017_reorder_cleanclass/val.json \n",
      "\n",
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 7964\n",
      "categories 80\n",
      "\n",
      " >> SAVING test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:25<00:00,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/MOLA/annotations/splitimg_coco2017_reorder_cleanclass/test.json \n",
      "\n",
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 4984\n",
      "categories 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "annotations=copy.copy(molajson['annotations']) \n",
    "for i, percent_i in enumerate(tqdm(percent_idx)):\n",
    "    #get new annotations\n",
    "    newjson['annotations']=[annotations[index] for index in percent_i]\n",
    "    # save\n",
    "    print('\\n >> SAVING {}...'.format(percent_names[i]))\n",
    "    outpath=rdir+'splitimg_{}/'.format(infilename)\n",
    "    assure_path_exists(outpath)\n",
    "    outjsonfile=outpath+'{}.json'.format(percent_names[i]) #rdir+'{}_{}.json'.format(percent_names[i],infilename)\n",
    "    with open(outjsonfile, 'w') as f:\n",
    "        json.dump(newjson, f)\n",
    "    print(\"JSON SAVED : {} \\n\".format(outjsonfile))\n",
    "    for k in molajson:\n",
    "        print(k, len(newjson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TEST SPLIT ANNOTATIONS DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 9\n",
      "categories 1261\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 133266\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "injsonfile='mola_mix_aggressive.json'\n",
    "outjsonfile=rdir+'split_{}/'.format(infilename)+'test.json'\n",
    "# init json\n",
    "molajson =  json.load(open(outjsonfile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 133266/133266 [00:00<00:00, 1497403.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133266\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id\n",
    "ann_ids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_ids.append(an['id'])\n",
    "print(len(ann_ids))\n",
    "\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
