{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge datasets\n",
    "version: 1\n",
    "\n",
    "info:\n",
    "- Merge different datasets annotations json\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## motionLAB Annotations Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to combine multiple datasets, it is often useful to convert them into a unified data format. \n",
    "\n",
    "Objective: This script will allow you to merge the annotations into motionLab format (COCO & TAO-style annotation file) containing Image IDs in your data.json (general) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE: Check at the end of this script for the formats\n",
    "\n",
    "MOLA format : motionLab annotations format\n",
    "\n",
    "COCO format : https://cocodataset.org/#format-data ; https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch\n",
    "\n",
    "TAO format : https://github.com/TAO-Dataset/tao/blob/master/tao/toolkit/tao/tao.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux-5.4.0-65-generic-x86_64-with-glibc2.10\n",
      "root dir: /home/administrator/Z/Datasets/External Datasets/\n"
     ]
    }
   ],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/' #WARNING needs to be root datasets \n",
    "print('OS: {}'.format(platform.platform()))\n",
    "if str(platform.platform()).upper().find('linux'.upper())>-1: rdir='/home/administrator/Z/Datasets/External Datasets/' #'/mnt/d/external_datasets/'\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INIT motionLAB JSON\n",
    "- uses annotate.init_json() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON INITIATED : D:/external_datasets/mlab.json\n"
     ]
    }
   ],
   "source": [
    "molafile=rdir+'mola.json'\n",
    "init_json(file=molafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LOAD & ORGANIZE original datasets JSONs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize original COCO & save fullcoco\n",
    "- without changing ids - necessary if you gonna mix different types of annotations\n",
    "- #NOTE the only divergent hyperparameter between instances, captions and person_keypoints is the \"annotations\"\n",
    "- #WARNING COCO captions annotations are different from instances and person_keypoints -> #SOLUTION move caption to \"images\" hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 591753/591753 [00:00<00:00, 1586466.52it/s]\n",
      "add: images: 100%|█████████████████████████████████████████████████████████| 118287/118287 [10:35<00:00, 186.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 25014/25014 [00:00<00:00, 1567857.50it/s]\n",
      "add: images: 100%|████████████████████████████████████████████████████████████| 5000/5000 [00:01<00:00, 4784.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : D:/external_datasets/COCO/2017/annotations/fullcoco2017.json \n",
      "\n",
      "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])\n",
      "{'description': 'COCO 2017 Dataset', 'url': 'http://cocodataset.org', 'version': '1.0', 'year': 2017, 'contributor': 'COCO Consortium', 'date_created': '2017/09/01'}\n",
      "8\n",
      "123287\n",
      "1170251\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# merge train\n",
    "\n",
    "### 1.Captions -> #WARNING move caption annotations to images as new \"caption\" subkey ->below\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/captions_train2017.json'))\n",
    "ann_caption=[]\n",
    "ann_imgid=[]\n",
    "for an in tqdm(newjson['annotations']):\n",
    "    ann_caption.append(an['caption'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "### 2.Instances\n",
    "newjson =  json.load(open(rdir+'COCO/2017/annotations/instances_train2017.json'))\n",
    "key='images' # add images\n",
    "root_dir='COCO/2017/images/train2017/' \n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='add: {}'.format(key))):\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name'] # change images: file_name\n",
    "    imgid=newjson[key][ik]['id']\n",
    "    try:\n",
    "        imgidx=ann_imgid.index(imgid) #assuming one caption per imgid\n",
    "        newjson[key][ik]['caption'] = ann_caption[imgidx] # add captions\n",
    "    except:\n",
    "        newjson[key][ik]['caption'] = 'missing caption!'         \n",
    "fulljson = newjson # init fulljson\n",
    "### 3. Person Keypoints\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/person_keypoints_train2017.json'))\n",
    "key='annotations' # add annotations\n",
    "fulljson[key] = fulljson[key] + newjson[key]        \n",
    "fulljson['categories'][0]=newjson['categories'][0] # update person category based on person_keypoints\n",
    "\n",
    "\n",
    "# merge val\n",
    "\n",
    "### 1.Captions -> #WARNING move caption annotations to images as new \"caption\" subkey ->below\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/captions_val2017.json'))\n",
    "ann_caption=[]\n",
    "ann_imgid=[]\n",
    "for an in tqdm(newjson['annotations']):\n",
    "    ann_caption.append(an['caption'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "### 2.Instances\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/instances_val2017.json'))\n",
    "key='images' # add images\n",
    "root_dir='COCO/2017/images/val2017/' \n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='add: {}'.format(key))):\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name'] # change images: file_name\n",
    "    imgid=newjson[key][ik]['id']\n",
    "    try:\n",
    "        imgidx=ann_imgid.index(imgid) #assuming one caption per imgid\n",
    "        newjson[key][ik]['caption'] = ann_caption[imgidx] # add captions\n",
    "    except:\n",
    "        newjson[key][ik]['caption'] = 'missing caption!'    \n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='annotations' # add annotations\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "### 3.Person Keypoints\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/person_keypoints_val2017.json'))\n",
    "key='annotations' # add annotations\n",
    "fulljson[key] = fulljson[key] + newjson[key]   \n",
    "\n",
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+'COCO/2017/annotations/fullcoco2017.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(fulljson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "\n",
    "print(fulljson.keys())\n",
    "print(fulljson['info'])\n",
    "print(len(fulljson['licenses']))\n",
    "print(len(fulljson['images']))\n",
    "print(len(fulljson['annotations']))\n",
    "print(len(fulljson['categories']))\n",
    "print(fulljson['images'][10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Organize original TAO & save fulltao\n",
    "- #WARNING TAO dataset has no annotations for some categories -> #SOLVED this was on purpose (see below on the section ANNOTATIONS FORMAT)\n",
    "- #WARNING TAO dataset has no images for some categories - #SOLVE ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rename file_name: images: 100%|██████████| 18274/18274 [00:00<00:00, 1065692.16it/s]\n",
      "rename file_name: videos: 100%|██████████| 500/500 [00:00<00:00, 1088863.97it/s]\n",
      "rename file_name: images: 100%|██████████| 36375/36375 [00:00<00:00, 977603.97it/s]\n",
      "rename file_name: videos: 100%|██████████| 988/988 [00:00<00:00, 1013196.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : /home/administrator/Z/Datasets/External Datasets/TAO/TAO_DIR/annotations/fulltao.json \n",
      "\n",
      "dict_keys(['videos', 'annotations', 'tracks', 'images', 'info', 'categories', 'licenses'])\n",
      "{'year': 2020, 'version': '0.1.20200120', 'description': 'Annotations imported from Scale', 'contributor': '', 'url': '', 'date_created': '2020-01-20 15:49:53.519740'}\n",
      "1\n",
      "54649\n",
      "167751\n",
      "1230\n"
     ]
    }
   ],
   "source": [
    "TAO_ROOT=\"TAO/TAO_DIR/\"\n",
    "# merge train\n",
    "newjson =  json.load(open(rdir+TAO_ROOT+'annotations/train.json'))\n",
    "key='images' #alter paths to datasets root\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    root_dir=TAO_ROOT+'frames/' # change images: file_name\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name']\n",
    "    root_dir=TAO_ROOT+'videos/' # change images: video\n",
    "    newjson[key][ik]['video'] = root_dir + newjson[key][ik]['video']\n",
    "key='videos' #alter paths to datasets root\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    root_dir=TAO_ROOT+'videos/' # change images: video\n",
    "    newjson[key][ik]['name'] = root_dir + newjson[key][ik]['name']\n",
    "fulljson = newjson\n",
    "# merge val\n",
    "newjson =  json.load(open(rdir+TAO_ROOT+'annotations/validation.json'))\n",
    "key='images' #alter paths to datasets root\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    root_dir=TAO_ROOT+'frames/' # change images: file_name\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name']\n",
    "    root_dir=TAO_ROOT+'videos/' # change images: video\n",
    "    newjson[key][ik]['video'] = root_dir + newjson[key][ik]['video']\n",
    "fulljson[key] = fulljson[key] + newjson[key]\n",
    "key='videos' #alter paths to datasets root\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    root_dir=TAO_ROOT+'videos/' # change images: video\n",
    "    newjson[key][ik]['name'] = root_dir + newjson[key][ik]['name']\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='tracks'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "\n",
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+TAO_ROOT+'annotations/fulltao.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(fulljson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "\n",
    "print(fulljson.keys())\n",
    "print(fulljson['info'])\n",
    "print(len(fulljson['licenses']))\n",
    "print(len(fulljson['images']))\n",
    "print(len(fulljson['annotations']))\n",
    "print(len(fulljson['categories']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MERGE datasets\n",
    "- #WARNING merge is slow -> #TODO #SOLUTION use same approach as fixclasses and mixclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molafile=rdir+'mola.json'\n",
    "mergecoco=rdir+'COCO/2017/annotations/fullcoco2017.json'\n",
    "mergetao=rdir+TAO_ROOT+'annotations/fulltao.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING if memory error go to a terminal ipython shell and paste this comands\n",
    "!python annotate_v5.py --molafile $molafile --mergefile $mergecoco --dataset_id 1\n",
    "!python annotate_v5.py --molafile $molafile --mergefile $mergetao --dataset_id 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TEST MERGED JSON ANNOTATIONS DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "molajson = json.load(open(rdir+'MOLA/annotations/mola.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 9\n",
      "categories 1310\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 1338002\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1338002/1338002 [00:00<00:00, 1387926.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1338002\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id\n",
    "ann_ids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_ids.append(an['id'])\n",
    "print(len(ann_ids))\n",
    "\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNOTATIONS FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOLA\n",
    "Format in annotate_v5.init_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "        \"info\": None,\n",
    "        \"licenses\": [],\n",
    "        \"categories\": [],\n",
    "        \"videos\": [],\n",
    "        \"images\": [],\n",
    "        \"tracks\": [],\n",
    "        \"segment_info\": [],\n",
    "        \"annotations\": [],\n",
    "        \"datasets\": [{'name': 'COCO', 'id': 1}, {'name': 'TAO', 'id': 2}]\n",
    "    }\n",
    "    \n",
    "output['info'] = {\n",
    "        \"description\": \"Mixed Dataset\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"1\",\n",
    "        \"year\": 2020,\n",
    "        \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation file format: https://cocodataset.org/#format-data ; https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"info\": {info},\n",
    "    \"licenses\": [license],\n",
    "    \"images\": [image],\n",
    "    \"annotations\": [annotation],\n",
    "    \"categories\": [category], <-- Not in Captions annotations\n",
    "    \"segment_info\": [segment] <-- Only in Panoptic annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info{\n",
    "    \"year\": int, \n",
    "    \"version\": str, \n",
    "    \"description\": str, \n",
    "    \"contributor\": str, \n",
    "    \"url\": str, \n",
    "    \"date_created\": datetime,\n",
    "}\n",
    "license{\n",
    "    \"id\": int, \n",
    "    \"name\": str, \n",
    "    \"url\": str,\n",
    "}\n",
    "image{\n",
    "    \"id\": int, \n",
    "    \"width\": int, \n",
    "    \"height\": int, \n",
    "    \"file_name\": str, \n",
    "    \"license\": int, \"flickr_url\": str, \n",
    "    \"coco_url\": str, \"date_captured\": datetime,\n",
    "}\n",
    "annotation{\n",
    "    \"id\": int, \n",
    "    \"image_id\": int, \n",
    "    \"category_id\": int, \n",
    "    \"segmentation\": RLE or [polygon], \n",
    "    \"area\": float, \n",
    "    \"bbox\": [x,y,width,height], \n",
    "    \"iscrowd\": 0 or 1,\n",
    "}\n",
    "\n",
    "category{\n",
    "    \"id\": int, \n",
    "    \"name\": str, \n",
    "    \"supercategory\": str,\n",
    "}\n",
    "segment{\n",
    "    \"id\": int, \n",
    "    \"category_id\": int, \n",
    "    \"area\": int, \n",
    "    \"bbox\": [x,y,width,height], \n",
    "    \"iscrowd\": 0 or 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation file format: https://github.com/TAO-Dataset/tao/blob/master/tao/toolkit/tao/tao.py\n",
    "\n",
    "\n",
    "#NOTE: https://github.com/TAO-Dataset/tao/blob/master/docs/faqs.md . Why does the training set only contain 216 LVIS categories?\n",
    "- TAO contains a total of 482 LVIS categories. However, not all categories are present in the train, val, and test sets. Instead, we encourage researchers to train detectors on the LVIS v0.5 dataset, which contains a superset of the 482 categories, and trackers on existing single-object tracking datasets. TAO is primarily a benchmark dataset, but we provide a small set of training videos for tuning trackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"info\" : info,\n",
    "    \"images\" : [image],\n",
    "    \"videos\": [video],\n",
    "    \"tracks\": [track],\n",
    "    \"annotations\" : [annotation],\n",
    "    \"categories\": [category],\n",
    "    \"licenses\" : [license],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info: \"like MS COCO\"\n",
    "\n",
    "license: {\n",
    "    \"id\" : int,\n",
    "    \"name\" : str,\n",
    "    \"url\" : str,\n",
    "}\n",
    "category: {\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"synset\": str,  # For non-LVIS objects, this is \"unknown\"\n",
    "    ... [other fields copied from LVIS v0.5 and unused]\n",
    "}\n",
    "\n",
    "video: {\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"width\" : int,\n",
    "    \"height\" : int,\n",
    "    \"neg_category_ids\": [int],\n",
    "    \"not_exhaustive_category_ids\": [int],\n",
    "    \"metadata\": dict,  # Metadata about the video\n",
    "}\n",
    "image: {\n",
    "    \"id\" : int,\n",
    "    \"video_id\": int,\n",
    "    \"file_name\" : str,\n",
    "    \"license\" : int,\n",
    "    # Redundant fields for COCO-compatibility\n",
    "    \"width\": int,\n",
    "    \"height\": int,\n",
    "    \"frame_index\": int\n",
    "}    \n",
    "track: {\n",
    "    \"id\": int,\n",
    "    \"category_id\": int,\n",
    "    \"video_id\": int\n",
    "}\n",
    "annotation: {\n",
    "    \"image_id\": int,\n",
    "    \"track_id\": int,\n",
    "    \"bbox\": [x,y,width,height],\n",
    "    \"area\": float,\n",
    "    # Redundant field for compatibility with COCO scripts\n",
    "    \"category_id\": int\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
