{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter datasets\n",
    "version: 1\n",
    "\n",
    "info:\n",
    "- filter json into train.json, val.json and test.json \n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.20241-SP0\n",
      "root dir: D:/external_datasets/\n"
     ]
    }
   ],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "\n",
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/' \n",
    "if str(platform.platform()).find('linux')>-1: rdir='/mnt/d/external_datasets/' \n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=70\n",
    "val=20\n",
    "test=100-(train+val)\n",
    "injsonfile='mlab_fix_equal.json'\n",
    "infilename=injsonfile.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 9\n",
      "categories 1261\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 1338002\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "# init json\n",
    "mlabjson =  json.load(open(rdir+injsonfile))\n",
    "for k in mlabjson:\n",
    "    print(k, len(mlabjson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import ids\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories id\n",
    "catids=[]\n",
    "for c in mlabjson['categories']:\n",
    "    catids.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1338002/1338002 [00:00<00:00, 1737663.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id\n",
    "ann_catids=[]\n",
    "for an in tqdm(mlabjson['annotations']):\n",
    "    ann_catids.append(an['category_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter annotations\n",
    "#QUESTION Seeded random or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1261/1261 [00:02<00:00, 444.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.98823619097729\n",
      "19.989730957053876\n",
      "9.9881016620304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ann_catids_np=np.array(ann_catids)\n",
    "train_ann_catidx=[]\n",
    "val_ann_catidx=[]\n",
    "test_ann_catidx=[]\n",
    "for catid in tqdm(catids):\n",
    "    ann_idx_np = np.where(ann_catids_np==catid)[0] #annotation index of ids\n",
    "    train_size=len(ann_idx_np) * train // 100 #floor division\n",
    "    val_size=len(ann_idx_np) * val // 100\n",
    "    test_size=len(ann_idx_np) * test // 100\n",
    "    remain_idx_np=ann_idx_np #start 100%\n",
    "    #train\n",
    "    train_idx_np = np.random.choice(remain_idx_np, train_size)\n",
    "    train_ann_catidx.extend(train_idx_np.tolist())\n",
    "    remain_idx_np=remain_idx_np[~np.in1d(remain_idx_np,train_idx_np)]\n",
    "    #val\n",
    "    val_idx_np = np.random.choice(remain_idx_np, val_size)\n",
    "    val_ann_catidx.extend(val_idx_np.tolist())\n",
    "    remain_idx_np=remain_idx_np[~np.in1d(remain_idx_np,val_idx_np)]\n",
    "    #test\n",
    "    test_idx_np = np.random.choice(remain_idx_np, test_size)\n",
    "    test_ann_catidx.extend(test_idx_np.tolist())\n",
    "    remain_idx_np=remain_idx_np[~np.in1d(remain_idx_np,test_idx_np)]\n",
    "\n",
    "print((len(train_ann_catidx)/len(ann_catids))*100)\n",
    "print((len(val_ann_catidx)/len(ann_catids))*100)\n",
    "print((len(test_ann_catidx)/len(ann_catids))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save filtered jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_idx=[train_ann_catidx,val_ann_catidx, test_ann_catidx]\n",
    "percent_names=['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████                                                      | 1/3 [02:34<05:09, 154.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/train_mlab_fix_equal.json \n",
      "\n",
      "info 5\n",
      "licenses 9\n",
      "categories 1261\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 936444\n",
      "datasets 2\n",
      "\n",
      " >> SAVING val...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████                           | 2/3 [03:21<02:02, 122.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/val_mlab_fix_equal.json \n",
      "\n",
      "info 5\n",
      "licenses 9\n",
      "categories 1261\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 267463\n",
      "datasets 2\n",
      "\n",
      " >> SAVING test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [03:48<00:00, 76.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/test_mlab_fix_equal.json \n",
      "\n",
      "info 5\n",
      "licenses 9\n",
      "categories 1261\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 133641\n",
      "datasets 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "annotations=copy.copy(mlabjson['annotations']) #reset annotations\n",
    "for i, percent_i in enumerate(tqdm(percent_idx)):\n",
    "    #get new annotations\n",
    "    mlabjson['annotations']=[annotations[index] for index in percent_i]\n",
    "    # save\n",
    "    print('\\n >> SAVING {}...'.format(percent_names[i]))\n",
    "    outjsonfile=rdir+'{}_{}.json'.format(percent_names[i],infilename)\n",
    "    with open(outjsonfile, 'w') as f:\n",
    "        json.dump(mlabjson, f)\n",
    "    print(\"JSON SAVED : {} \\n\".format(outjsonfile))\n",
    "    for k in mlabjson:\n",
    "        print(k, len(mlabjson[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
