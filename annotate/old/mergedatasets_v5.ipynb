{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# motionLAB Annotations Data Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to combine multiple datasets, it is often useful to convert them into a unified data format. \n",
    "\n",
    "Objective: This script will allow you to merge the annotations into motionLab format (COCO & TAO-style annotation file) containing Image IDs in your data.json (general) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COCO format : https://cocodataset.org/#format-data ; https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch\n",
    "\n",
    "TAO format : https://github.com/TAO-Dataset/tao/blob/master/tao/toolkit/tao/tao.py\n",
    "\n",
    "##### NOTE: Check at the end of this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.20215-SP0\n",
      "root dir: D:/external_datasets/\n"
     ]
    }
   ],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "\n",
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/' \n",
    "print('OS: {}'.format(platform.platform()))\n",
    "if str(platform.platform()).find('linux')>-1: rdir='/mnt/d/external_datasets/' \n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INIT motionLAB JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON INITIATED : D:/external_datasets/mlab.json\n"
     ]
    }
   ],
   "source": [
    "mlabfile=rdir+'mlab.json'\n",
    "init_json(file=mlabfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load and Merge JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Organize COCO original (without changing ids - necessary if you gonna mix different types of annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rename file_name: images: 100%|██████████| 118287/118287 [00:00<00:00, 1550774.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supercategory': 'person', 'id': 1, 'name': 'person', 'keypoints': ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle'], 'skeleton': [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12], [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3], [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rename file_name: images: 100%|██████████| 5000/5000 [00:00<00:00, 1368005.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : /mnt/d/external_datasets/COCO/2017/annotations/fullcoco2017.json \n",
      "\n",
      "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])\n",
      "{'description': 'COCO 2017 Dataset', 'url': 'http://cocodataset.org', 'version': '1.0', 'year': 2017, 'contributor': 'COCO Consortium', 'date_created': '2017/09/01'}\n",
      "8\n",
      "123287\n",
      "1787018\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# merge train\n",
    "### 1.Instances\n",
    "newjson =  json.load(open(rdir+'COCO/2017/annotations/instances_train2017.json'))\n",
    "key='images'\n",
    "root_dir='COCO/2017/images/train2017/' # change images: file_name\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name']\n",
    "fulljson = newjson\n",
    "### 2.Captions\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/captions_train2017.json'))\n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "### 3. Person Keypoints\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/person_keypoints_train2017.json'))\n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key]        \n",
    "### update person category\n",
    "fulljson['categories'][0]=newjson['categories'][0]\n",
    "#print(fulljson['categories'][0])\n",
    "\n",
    "\n",
    "# merge val\n",
    "### 1.Instances\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/instances_val2017.json'))\n",
    "key='images'\n",
    "root_dir='COCO/2017/images/val2017/' # change images: file_name\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name']\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "### 2.Captions\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/captions_val2017.json'))\n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "### 3.Person Keypoints\n",
    "newjson = json.load(open(rdir+'COCO/2017/annotations/person_keypoints_val2017.json'))\n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key]   \n",
    "\n",
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+'COCO/2017/annotations/fullcoco2017.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(fulljson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "\n",
    "print(fulljson.keys())\n",
    "print(fulljson['info'])\n",
    "print(len(fulljson['licenses']))\n",
    "print(len(fulljson['images']))\n",
    "print(len(fulljson['annotations']))\n",
    "print(len(fulljson['categories']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Merge in mlabjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python annotate_v4.py --mlabfile /mnt/d/external_datasets/mlab.json --mergefile /mnt/d/external_datasets/COCO/2017/annotations/fullcoco2017.json --dataset_id 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rename file_name: images: 100%|███████████████████████████████████████████| 18274/18274 [00:00<00:00, 676804.11it/s]\n",
      "rename file_name: images: 100%|███████████████████████████████████████████| 36375/36375 [00:00<00:00, 773811.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : D:/external_datasets/TAO/TAO_DIR/annotations/fulltao.json \n",
      "\n",
      "dict_keys(['info', 'images', 'annotations', 'categories', 'licenses', 'videos', 'tracks'])\n",
      "{'year': 2020, 'version': '0.1.20200120', 'description': 'Annotations imported from Scale', 'contributor': '', 'url': '', 'date_created': '2020-01-20 15:49:53.519740'}\n",
      "1\n",
      "54649\n",
      "167751\n",
      "1230\n"
     ]
    }
   ],
   "source": [
    "# merge train\n",
    "newjson =  json.load(open(rdir+'TAO/TAO_DIR/annotations/train.json'))\n",
    "key='images'\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    root_dir='TAO/TAO_DIR/frames/' # change images: file_name\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name']\n",
    "    root_dir='TAO/TAO_DIR/videos/' # change images: video\n",
    "    newjson[key][ik]['video'] = root_dir + newjson[key][ik]['video']\n",
    "fulljson = newjson\n",
    "# merge val\n",
    "newjson =  json.load(open(rdir+'TAO/TAO_DIR/annotations/val.json'))\n",
    "key='images'\n",
    "for ik, k in enumerate(tqdm(newjson[key], desc='rename file_name: {}'.format(key))):\n",
    "    root_dir='TAO/TAO_DIR/frames/' # change images: file_name\n",
    "    newjson[key][ik]['file_name'] = root_dir + newjson[key][ik]['file_name']\n",
    "    root_dir='TAO/TAO_DIR/videos/' # change images: video\n",
    "    newjson[key][ik]['video'] = root_dir + newjson[key][ik]['video']\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='videos'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='tracks'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "key='annotations'\n",
    "fulljson[key] = fulljson[key] + newjson[key] \n",
    "\n",
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+'TAO/TAO_DIR/annotations/fulltao.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(fulljson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))\n",
    "\n",
    "print(fulljson.keys())\n",
    "print(fulljson['info'])\n",
    "print(len(fulljson['licenses']))\n",
    "print(len(fulljson['images']))\n",
    "print(len(fulljson['annotations']))\n",
    "print(len(fulljson['categories']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlabfile=rdir+'mlab.json'\n",
    "mergefile=rdir+'TAO/TAO_DIR/annotations/fulltao.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python annotate_v4.py --mlabfile $mlabfile --mergefile $mergefile --dataset_id 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE ALL (Option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING if memory error go to the terminal shell\n",
    "!python annotate_v4.py --mlabfile /mnt/d/external_datasets/mlab.json --mergefile /mnt/d/external_datasets/COCO/2017/annotations/fullcoco2017.json --dataset_id 1\n",
    "!python annotate_v4.py --mlabfile /mnt/d/external_datasets/mlab.json --mergefile /mnt/d/external_datasets/TAO/TAO_DIR/annotations/fulltao.json --dataset_id 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlabjson = json.load(open(rdir+'mlab.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 1\n",
      "categories 1230\n",
      "videos 1488\n",
      "images 54649\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 167751\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "for k in mlabjson:\n",
    "    print(k, len(mlabjson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNOTATIONS FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation file format: \n",
    "\n",
    "https://cocodataset.org/#format-data ; https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"info\": {info},\n",
    "    \"licenses\": [license],\n",
    "    \"images\": [image],\n",
    "    \"annotations\": [annotation],\n",
    "    \"categories\": [category], <-- Not in Captions annotations\n",
    "    \"segment_info\": [segment] <-- Only in Panoptic annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info{\n",
    "    \"year\": int, \n",
    "    \"version\": str, \n",
    "    \"description\": str, \n",
    "    \"contributor\": str, \n",
    "    \"url\": str, \n",
    "    \"date_created\": datetime,\n",
    "}\n",
    "license{\n",
    "    \"id\": int, \n",
    "    \"name\": str, \n",
    "    \"url\": str,\n",
    "}\n",
    "image{\n",
    "    \"id\": int, \n",
    "    \"width\": int, \n",
    "    \"height\": int, \n",
    "    \"file_name\": str, \n",
    "    \"license\": int, \"flickr_url\": str, \n",
    "    \"coco_url\": str, \"date_captured\": datetime,\n",
    "}\n",
    "annotation{\n",
    "    \"id\": int, \n",
    "    \"image_id\": int, \n",
    "    \"category_id\": int, \n",
    "    \"segmentation\": RLE or [polygon], \n",
    "    \"area\": float, \n",
    "    \"bbox\": [x,y,width,height], \n",
    "    \"iscrowd\": 0 or 1,\n",
    "}\n",
    "\n",
    "category{\n",
    "    \"id\": int, \n",
    "    \"name\": str, \n",
    "    \"supercategory\": str,\n",
    "}\n",
    "segment{\n",
    "    \"id\": int, \n",
    "    \"category_id\": int, \n",
    "    \"area\": int, \n",
    "    \"bbox\": [x,y,width,height], \n",
    "    \"iscrowd\": 0 or 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation file format:\n",
    "\n",
    "https://github.com/TAO-Dataset/tao/blob/master/tao/toolkit/tao/tao.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"info\" : info,\n",
    "    \"images\" : [image],\n",
    "    \"videos\": [video],\n",
    "    \"tracks\": [track],\n",
    "    \"annotations\" : [annotation],\n",
    "    \"categories\": [category],\n",
    "    \"licenses\" : [license],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info: \"like MS COCO\"\n",
    "\n",
    "license: {\n",
    "    \"id\" : int,\n",
    "    \"name\" : str,\n",
    "    \"url\" : str,\n",
    "}\n",
    "category: {\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"synset\": str,  # For non-LVIS objects, this is \"unknown\"\n",
    "    ... [other fields copied from LVIS v0.5 and unused]\n",
    "}\n",
    "\n",
    "video: {\n",
    "    \"id\": int,\n",
    "    \"name\": str,\n",
    "    \"width\" : int,\n",
    "    \"height\" : int,\n",
    "    \"neg_category_ids\": [int],\n",
    "    \"not_exhaustive_category_ids\": [int],\n",
    "    \"metadata\": dict,  # Metadata about the video\n",
    "}\n",
    "image: {\n",
    "    \"id\" : int,\n",
    "    \"video_id\": int,\n",
    "    \"file_name\" : str,\n",
    "    \"license\" : int,\n",
    "    # Redundant fields for COCO-compatibility\n",
    "    \"width\": int,\n",
    "    \"height\": int,\n",
    "    \"frame_index\": int\n",
    "}    \n",
    "track: {\n",
    "    \"id\": int,\n",
    "    \"category_id\": int,\n",
    "    \"video_id\": int\n",
    "}\n",
    "annotation: {\n",
    "    \"image_id\": int,\n",
    "    \"track_id\": int,\n",
    "    \"bbox\": [x,y,width,height],\n",
    "    \"area\": float,\n",
    "    # Redundant field for compatibility with COCO scripts\n",
    "    \"category_id\": int\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
