{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Classes=Categories\n",
    "version: 3\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.20241-SP0\n",
      "root dir: D:/external_datasets/\n"
     ]
    }
   ],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "\n",
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/' \n",
    "if str(platform.platform()).find('linux')>-1: rdir='/mnt/d/external_datasets/' \n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlabjson =  json.load(open(rdir+'mlab_cocotao.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 9\n",
      "categories 1310\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 1954769\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "for k in mlabjson:\n",
    "    print(k, len(mlabjson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import ids\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations\n",
    "#### #WARNING don't use try: except: pass when importing - go back to mergedatasets and find the BUG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COCO', 'TAO'] [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# datasets name and id\n",
    "dset_l=[]\n",
    "dset_l_id=[]\n",
    "for d in mlabjson['datasets']:\n",
    "    dset_l.append(d['name'])\n",
    "    dset_l_id.append(d['id'])\n",
    "print(dset_l, dset_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "cat_l_id=[]\n",
    "cat_l_dset=[]\n",
    "for c in mlabjson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "    cat_l_id.append(c['id'])\n",
    "    cat_l_dset.append(dset_l[c['dataset']-1]) # dset_l index is same as id-1\n",
    "#print(cat_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "img_l=[]\n",
    "img_l_id=[]\n",
    "for c in mlabjson['images']:\n",
    "    img_l.append(c['file_name'])\n",
    "    img_l_id.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1954769/1954769 [00:01<00:00, 1201465.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "ann_dset=[]\n",
    "for an in tqdm(mlabjson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "    ann_dset.append(an['dataset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find duplicates cat_ids\n",
    "Duplicates example\n",
    "categories= [{name:cow, id:1, dataset:1},...,{name:cow, id:200, dataset:2},...,{name:cow, id:101, dataset:3}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 1042.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fork', 'chair', 'clock', 'bird', 'toaster', 'horse', 'umbrella', 'bench', 'skateboard', 'zebra', 'elephant', 'sheep', 'carrot', 'handbag', 'bottle', 'toothbrush', 'pizza', 'knife', 'boat', 'dog', 'apple', 'bed', 'vase', 'scissors', 'cake', 'book', 'bear', 'toilet', 'giraffe', 'suitcase', 'kite', 'spoon', 'bicycle', 'broccoli', 'surfboard', 'motorcycle', 'frisbee', 'backpack', 'cup', 'sink', 'sandwich', 'snowboard', 'cow', 'banana', 'truck', 'cat', 'airplane', 'refrigerator', 'bowl']\n",
      "[[43, 555], [57, 317], [75, 356], [15, 179], [71, 1195], [18, 659], [26, 1235], [14, 171], [37, 1060], [23, 1309], [21, 509], [19, 1041], [52, 301], [27, 115], [40, 213], [80, 1202], [54, 909], [44, 705], [9, 198], [17, 462], [48, 93], [60, 159], [76, 1242], [77, 1017], [56, 265], [74, 206], [22, 158], [62, 1197], [24, 582], [29, 116], [34, 701], [45, 1098], [2, 175], [51, 234], [38, 1137], [4, 794], [30, 560], [25, 114], [42, 427], [72, 1059], [49, 1006], [32, 1073], [20, 161], [47, 125], [8, 1224], [16, 309], [5, 84], [73, 508], [46, 219]]\n",
      "[['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO'], ['COCO', 'TAO']]\n",
      "49\n",
      "49\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#duplicates #TODO: SORT alphabetically\n",
    "duplicates_l=[]\n",
    "duplicates_l_catid=[]\n",
    "duplicates_l_catdset=[]\n",
    "duplicate_method=\"equal_names\"\n",
    "if duplicate_method==\"equal_names\": #FIX REPETITIONS\n",
    "    duplicates_l=list(set([x for x in cat_l if cat_l.count(x) > 1])) # duplicates l \n",
    "    for duplicate in tqdm(duplicates_l):\n",
    "        idx_mask = [name == duplicate for name in cat_l] #mask of index of duplicate\n",
    "        catids = np.array(cat_l_id)[idx_mask] #duplicate catids\n",
    "        catdsets = np.array(cat_l_dset)[idx_mask] #duplicate catdset\n",
    "        duplicates_l_catid.append(catids.tolist())\n",
    "        duplicates_l_catdset.append(catdsets.tolist())\n",
    "if duplicate_method==\"similar_names\": #FIX SIMILAR NAMES\n",
    "    #WARNING: fix equal_names first - if not, it will not be fixed in this case\n",
    "    import difflib\n",
    "    for cat in cat_l: \n",
    "        match_l=[]\n",
    "        match_l_temp=[c for c in cat_l if (c).find(cat)>-1] #only substring inside string - catagory with big name is not found\n",
    "        if not len(match_l_temp)>1: continue #more than one\n",
    "        #refine search #ADD or REMOVE refine options\n",
    "        match_l.append(cat) #make category to be the first item\n",
    "        match_l.extend([c for c in match_l_temp if ((c+' ').find(cat)>-1 or (c+' ').find(cat)>-1 or (' '+c).find(cat)>-1 or (c+'_').find(cat)>-1 or ('_'+c).find(cat)>-1 )]) #mantain optins: c+'_';'_'+c \n",
    "        match_l.extend(difflib.get_close_matches(cat, match_l_temp, n=5, cutoff=0.9)) #get similar words\n",
    "        #remove equal names\n",
    "        match_l=list(dict.fromkeys(match_l))#match_l=list(set(match_l))\n",
    "        if not len(match_l)>1: continue #more than one\n",
    "        #add to duplicates\n",
    "        duplicates_l.append(match_l)\n",
    "    for duplicates in tqdm(duplicates_l):\n",
    "        catids=[]\n",
    "        catdsets=[]\n",
    "        for duplicate in duplicates:\n",
    "            idx=cat_l.index(duplicate) #first duplicate ()\n",
    "            catids.append(cat_l_id[idx]) #duplicate catids\n",
    "            catdsets.append(cat_l_dset[idx]) #duplicate cat dsets\n",
    "        duplicates_l_catid.append(catids)\n",
    "        duplicates_l_catdset.append(catdsets)\n",
    "if duplicate_method==\"all_names\": #Do for all category names, even with equal \n",
    "    duplicates_l=cat_l #NORMALIZE: same list format ?? not needed\n",
    "    duplicates_l_catid=[[id] for id in cat_l_id]\n",
    "    duplicates_l_catdset=[[dset] for dset in cat_l_dset]\n",
    "    \n",
    "\n",
    "print(duplicates_l)\n",
    "print(duplicates_l_catid)\n",
    "print(duplicates_l_catdset)\n",
    "print(len(duplicates_l))\n",
    "print(len(duplicates_l_catid))\n",
    "print(len(duplicates_l_catdset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 49/49 [00:00<00:00, 95.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# get annotations duplicates\n",
    "ann_catid_np=np.array(ann_catid)\n",
    "ann_imgid_np=np.array(ann_imgid)\n",
    "ann_bbox_np=np.array(ann_bbox)\n",
    "ann_dset_np=np.array(ann_dset)\n",
    "duplicates_l_imgid=[]\n",
    "duplicates_l_bbox=[]\n",
    "duplicates_l_dset=[]\n",
    "for catids in tqdm(duplicates_l_catid):\n",
    "    l_imgid=[]\n",
    "    l_bbox=[]\n",
    "    l_dset=[]\n",
    "    for catid in catids:\n",
    "        ann_idx = np.where(ann_catid_np==catid)[0].tolist() #annotation index of ids\n",
    "        l_imgid.append(ann_imgid_np[ann_idx].tolist())\n",
    "        l_bbox.append(ann_bbox_np[ann_idx].tolist())\n",
    "        l_dset.append(ann_dset_np[ann_idx].tolist())\n",
    "    duplicates_l_imgid.append(l_imgid)\n",
    "    duplicates_l_bbox.append(l_bbox)\n",
    "    duplicates_l_dset.append(l_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classes|categories to fix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> fork...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO fork...:   0%|                                                             | 0/5694 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000084664.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO fork...:   0%|                                                               | 0/167 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_178d5e91768b9c42488ff879c1fa54/frame1111.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Finding TAO fork...:  17%|████████▉                                            | 28/167 [00:00<00:00, 195.80it/s]\n",
      "\n",
      ">>> Finding TAO fork...:  17%|█████████▏                                           | 29/167 [00:00<00:00, 242.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_178d5e91768b9c42488ff879c1fa54/frame0871.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO fork...:  18%|█████████▌                                           | 30/167 [00:00<00:00, 260.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_178d5e91768b9c42488ff879c1fa54/frame1291.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO fork...:  19%|█████████▊                                           | 31/167 [00:00<00:00, 216.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_f98739249efe1830f81eb02e6d756d15/frame0751.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO fork...:  19%|██████████▏                                          | 32/167 [00:00<00:00, 231.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_178d5e91768b9c42488ff879c1fa54/frame0751.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|█▋                                                                               | 1/49 [00:03<02:55,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> chair...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO chair...:   0%|                                                              | 0/510 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Shot_put_v_I7Q-x9MorO0_scene_0_0-1789/frame1021.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO chair...:   0%|                                                      | 1/510 [00:00<00:33, 15.17it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/Charades/0J1AQ/frame0987.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|███▎                                                                             | 2/49 [00:06<02:46,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> clock...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                            | 3/49 [00:07<02:08,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING clock is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> bird...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO bird...:   0%|                                                               | 0/672 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_5184aeb820dfcb8aa8f4c56c79107373/frame0451.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO bird...:   0%|                                                       | 1/672 [00:00<00:54, 12.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_c4254cd81215eab0ab8f1722fce00f/frame1501.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO bird...:   0%|▏                                                      | 2/672 [00:00<00:24, 27.65it/s]\u001b[A\n",
      "  8%|██████▌                                                                          | 4/49 [00:10<02:07,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_5184aeb820dfcb8aa8f4c56c79107373/frame0251.jpeg'\n",
      "\n",
      ">> toaster...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                        | 5/49 [00:11<01:40,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING toaster is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> horse...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO horse...:   0%|                                                             | 0/1225 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_399611735518de04d63ddcead9b8994/frame0391.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO horse...:   0%|                                                     | 1/1225 [00:00<00:20, 58.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Grooming_horse_v_ANnFXWVJ_x0_scene_0_0-5143/frame1141.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO horse...:   0%|                                                     | 2/1225 [00:00<00:37, 32.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_399611735518de04d63ddcead9b8994/frame0151.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO horse...:   0%|▏                                                   | 3/1225 [00:00<00:07, 166.69it/s]\u001b[A\n",
      " 12%|█████████▉                                                                       | 6/49 [00:14<01:47,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Horseback_riding_v_kM1naurrexk_scene_0_0-3876/frame1111.jpg'\n",
      "\n",
      ">> umbrella...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO umbrella...:   0%|                                                        | 0/11844 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000210789.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▌                                                                     | 7/49 [00:17<01:46,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> bench...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO bench...:   0%|                                                           | 0/10251 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000234757.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▏                                                                   | 8/49 [00:20<01:45,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> skateboard...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▉                                                                  | 9/49 [00:22<01:45,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> zebra...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▎                                                               | 10/49 [00:25<01:43,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> elephant...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO elephant...:   0%|                                                         | 0/5768 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000107851.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████▉                                                              | 11/49 [00:28<01:42,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> sheep...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO sheep...:   0%|                                                             | 0/1388 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_b85bf1321a40f6cee0c6537fdf7d51d3/frame1171.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|███████████████████▌                                                            | 12/49 [00:34<02:19,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> carrot...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▏                                                          | 13/49 [00:37<02:01,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> handbag...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██████████████████████▊                                                         | 14/49 [00:40<01:58,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> bottle...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO bottle...:   0%|                                                            | 0/1821 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/Charades/5ACD3/frame1141.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|████████████████████████▍                                                       | 15/49 [00:43<01:50,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> toothbrush...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO toothbrush...:   0%|                                                         | 0/172 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Brushing_teeth_v_ghzmn2V-SDE/frame1153.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO toothbrush...:   1%|▎                                                | 1/172 [00:00<00:02, 66.67it/s]\u001b[A\n",
      " 33%|██████████████████████████                                                      | 16/49 [00:46<01:41,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Brushing_teeth_v_ghzmn2V-SDE/frame1609.jpg'\n",
      "\n",
      ">> pizza...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO pizza...:   0%|                                                            | 0/6106 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000357903.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████▊                                                    | 17/49 [00:48<01:34,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> knife...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO knife...:   0%|                                                              | 0/294 [00:00<?, ?it/s]\u001b[A\n",
      ">>> Finding TAO knife...:   5%|██▌                                                  | 14/294 [00:00<00:03, 79.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/AVA/XOe9GeojzCs_scene_13_62523-64711/frame1171.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO knife...:   5%|██▋                                                 | 15/294 [00:00<00:01, 163.07it/s]\u001b[A\n",
      " 37%|█████████████████████████████▍                                                  | 18/49 [00:51<01:33,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_23584c2660351f12cffe1399c47ce870/frame1831.jpeg'\n",
      "\n",
      ">> boat...\n",
      "COCO\n",
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Sailing_v_JMzNLlatrys_scene_0_3138-4738/frame1111.jpg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO boat...:   0%|                                                               | 0/287 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO boat...:   0%|▏                                                      | 1/287 [00:00<00:18, 15.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Bungee_jumping_v_wfU6kQCtqPQ_scene_0_0-5494/frame1051.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███████████████████████████████                                                 | 19/49 [00:54<01:27,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> dog...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO dog...:   0%|                                                               | 0/2541 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_d58b6fdb1975c540e531ef6eae855e9e/frame0649.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Finding TAO dog...:   0%|                                                               | 0/2541 [00:00<?, ?it/s]\n",
      "\n",
      ">>> Finding TAO dog...:   0%|                                                       | 1/2541 [00:00<02:27, 17.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_6f26504bb5244ddd4469376ecc9d29d/frame1081.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████████████████████████████████▋                                               | 20/49 [00:57<01:24,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> apple...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████▎                                             | 21/49 [00:58<01:05,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING apple is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> bed...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO bed...:   0%|                                                                 | 0/71 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/AVA/XOe9GeojzCs_scene_10_51401-53477/frame1561.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO bed...:   1%|▊                                                        | 1/71 [00:00<00:04, 15.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/AVA/XOe9GeojzCs_scene_10_51401-53477/frame1531.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|███████████████████████████████████▉                                            | 22/49 [01:01<01:06,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> vase...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO vase...:   0%|                                                             | 0/6890 [00:00<?, ?it/s]\u001b[A\n",
      " 47%|█████████████████████████████████████▌                                          | 23/49 [01:02<00:51,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000429530.jpg'\n",
      ">>>> #WARNING vase is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> scissors...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO scissors...:   0%|                                                            | 0/95 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Throwing_darts_v_tS8_PFJtWOU/frame2881.jpg'\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Throwing_darts_v_tS8_PFJtWOU/frame2731.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO scissors...:   1%|▌                                                   | 1/95 [00:00<00:06, 15.39it/s]\u001b[A\n",
      "\n",
      ">>> Finding TAO scissors...:   3%|█▋                                                  | 3/95 [00:00<00:01, 48.02it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/AVA/4Y5qi1gD2Sw_scene_1_28435-31083/frame1171.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO scissors...:   4%|██▏                                                 | 4/95 [00:00<00:01, 60.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/AVA/4Y5qi1gD2Sw_scene_1_28435-31083/frame1051.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|███████████████████████████████████████▏                                        | 24/49 [01:05<00:56,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> cake...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████▊                                       | 25/49 [01:06<00:45,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING cake is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> book...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|██████████████████████████████████████████▍                                     | 26/49 [01:09<00:51,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> bear...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO bear...:   0%|                                                             | 0/1365 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000132622.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████                                    | 27/49 [01:12<00:54,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> toilet...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO toilet...:   0%|                                                           | 0/4336 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000348045.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████████████████████████████████████████████▋                                  | 28/49 [01:13<00:42,  2.05s/it]\n",
      ">>> Finding COCO giraffe...:   0%|                                                          | 0/5363 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING toilet is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> giraffe...\n",
      "COCO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000333069.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████▎                                | 29/49 [01:16<00:46,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> suitcase...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████▉                               | 30/49 [01:19<00:52,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> kite...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO kite...:   0%|                                                               | 0/116 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Kite_flying_v_Oz3pnUluJR8_scene_0_470-4389/frame1141.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Finding TAO kite...:   0%|                                                               | 0/116 [00:00<?, ?it/s]\n",
      " 63%|██████████████████████████████████████████████████▌                             | 31/49 [01:23<00:54,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> spoon...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO spoon...:   0%|                                                              | 0/257 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Making_a_lemonade_v_LWbt2xGpkJA_scene_0_0-1542/frame1081.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO spoon...:   0%|▏                                                     | 1/257 [00:00<00:17, 14.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Preparing_salad_v_AjH8TFfZIGY/frame3661.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|████████████████████████████████████████████████████▏                           | 32/49 [01:41<02:06,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> bicycle...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO bicycle...:   0%|                                                            | 0/921 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Horseback_riding_v_prQDcmyY04s/frame1951.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO bicycle...:   0%|                                                   | 1/921 [00:00<00:08, 110.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Horseback_riding_v_prQDcmyY04s/frame1711.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|█████████████████████████████████████████████████████▉                          | 33/49 [01:44<01:37,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> broccoli...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▌                        | 34/49 [01:45<01:09,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING broccoli is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> surfboard...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████▏                      | 35/49 [01:48<00:57,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> motorcycle...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▊                     | 36/49 [01:52<00:51,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> frisbee...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO frisbee...:   0%|                                                             | 0/23 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Discus_throw_v_uf1qMhzjHAc/frame4081.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO frisbee...:   9%|████▌                                                | 2/23 [00:00<00:00, 28.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Discus_throw_v_uf1qMhzjHAc/frame4051.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO frisbee...:  22%|███████████▌                                         | 5/23 [00:00<00:00, 70.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Discus_throw_v_uf1qMhzjHAc/frame3991.jpg'\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Discus_throw_v_uf1qMhzjHAc/frame4111.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO frisbee...:  26%|█████████████▊                                       | 6/23 [00:00<00:00, 89.57it/s]\u001b[A\n",
      " 76%|████████████████████████████████████████████████████████████▍                   | 37/49 [01:55<00:44,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> backpack...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████                  | 38/49 [01:59<00:42,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> cup...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████▋                | 39/49 [02:03<00:38,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> sink...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO sink...:   0%|                                                             | 0/5835 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000239627.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|█████████████████████████████████████████████████████████████████▎              | 40/49 [02:04<00:27,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING sink is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> sandwich...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO sandwich...:   0%|                                                         | 0/4550 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000438226.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/Charades/3YVPG/frame1081.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO sandwich...:   0%|                                                           | 0/387 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      ">>> Finding TAO sandwich...:   0%|▏                                                 | 1/387 [00:00<00:03, 110.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/YFCC100M/v_5b8014f2ebc4628f33a9dcc2d1fbc3b/frame1021.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████████████████████████████████████████████████▉             | 41/49 [02:07<00:23,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> snowboard...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▌           | 42/49 [02:08<00:16,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> #WARNING snowboard is missing from json annotations\n",
      "annotations datasets:  []\n",
      "annotations imgids:  []\n",
      "annotations bbox:  []\n",
      "\n",
      ">> cow...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO cow...:   0%|                                                              | 0/8527 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000526706.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████████▏         | 43/49 [02:11<00:15,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> banana...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO banana...:   0%|                                                           | 0/9837 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000581781.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding COCO banana...:   0%|                                                   | 1/9837 [00:00<17:22,  9.43it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000581781.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO banana...:   7%|███▊                                                  | 3/43 [00:00<00:00, 44.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_5168dc89995a4af63aae3b482eb7f73d/frame0031.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|███████████████████████████████████████████████████████████████████████▊        | 44/49 [02:14<00:13,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> truck...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO truck...:   0%|                                                           | 0/10388 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000260261.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO truck...:   0%|                                                             | 0/1671 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/BDD/b2dbb793-9f0b2bec/frame2101.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO truck...:   0%|                                                     | 1/1671 [00:00<01:51, 14.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/ArgoVerse/649750f3-0163-34eb-a102-7aaf5384eaec/ring_front_center_315969569701921136.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO truck...:   0%|                                                     | 2/1671 [00:00<01:03, 26.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/ArgoVerse/9da4ca63-f524-3b38-8c8b-624f17518574/ring_front_center_315966380318156424.jpg'\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/ArgoVerse/9da4ca63-f524-3b38-8c8b-624f17518574/ring_front_center_315966381317157464.jpg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO truck...:   0%|                                                     | 3/1671 [00:00<00:40, 41.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/ArgoVerse/rear_right_7dd530ed-80d9-30b7-80a6-57e7d334f302/ring_rear_right_315968751089187712.jpg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO truck...:   0%|▏                                                    | 4/1671 [00:00<00:54, 30.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████████████████████████████████████████████████████████████████████▍      | 45/49 [02:18<00:12,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> cat...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO cat...:   0%|                                                              | 0/4970 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000063552.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO cat...:   0%|                                                               | 0/1004 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_8d62fe522547e0c841c61d3dcfb5a63b/frame1411.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO cat...:   0%|                                                       | 1/1004 [00:00<00:38, 26.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/train/HACS/Wrapping_presents_v_sRd38UFfp6c_scene_0_810-1950/frame1051.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|███████████████████████████████████████████████████████████████████████████     | 46/49 [02:21<00:09,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> airplane...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████████████████████████▋   | 47/49 [02:24<00:06,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> refrigerator...\n",
      "COCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding COCO refrigerator...:   0%|                                                     | 0/2763 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000000802.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding COCO refrigerator...:   0%|                                             | 1/2763 [00:00<02:51, 16.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/COCO/2017/images/val2017/000000159791.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████████████████████████████████████████▎ | 48/49 [02:27<00:03,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> bowl...\n",
      "COCO\n",
      "TAO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO bowl...:   0%|                                                               | 0/505 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_b4fbb0da6968177ee3d7f31aa3f6648/frame1321.jpg'\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/HACS/Making_a_sandwich_v_6RjriKVIkR4_scene_0_0-4638/frame0991.jpg'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      ">>> Finding TAO bowl...:   0%|                                                       | 1/505 [00:00<00:30, 16.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Finding TAO bowl...:   0%|▏                                                      | 2/505 [00:00<00:14, 33.88it/s]\u001b[A\n",
      "\n",
      ">>> Finding TAO bowl...:   0%|                                                               | 0/505 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_b4fbb0da6968177ee3d7f31aa3f6648/frame1201.jpg'\n",
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/Charades/OEIR9/frame1016.jpg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>> Finding TAO bowl...:   1%|▎                                                      | 3/505 [00:00<00:10, 50.01it/s]\n",
      "\n",
      ">>> Finding TAO bowl...:   1%|▍                                                      | 4/505 [00:00<00:07, 70.14it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 49/49 [02:31<00:00,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'D:/external_datasets/TAO/TAO_DIR/frames/val/YFCC100M/v_460a1314da9bd32cbd14a2b3414f30/frame0649.jpeg'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classtofix_l=[]\n",
    "classtofix_l_catid=[]\n",
    "method=\"all\"\n",
    "if method==\"all\": #fix all duplicates\n",
    "    classtofix_l=duplicates_l\n",
    "    classtofix_l_catid=duplicates_l_catid\n",
    "if method==\"view_images\": # view images and select class to fix (INCEPTION =>>>Pufff!!!!)\n",
    "    img_l_id_np=np.array(img_l_id)      \n",
    "    for i, duplicate in enumerate(tqdm(duplicates_l)): #run for each duplicate\n",
    "        print(duplicate+'...') #class\n",
    "        display_imgs(rdir, i, dset_l, duplicates_l_catid, duplicates_l_dset, duplicates_l_imgid, img_l, img_l_id, imgidx=0)\n",
    "        classtofix_l, classtofix_l_catid=save_classtofix(i, classtofix_l, classtofix_l_catid, duplicates_l, duplicates_l_catid, duplicates_l_dset, duplicates_l_imgid, img_l, img_l_id, imgidx=0)\n",
    "if method==\"save_images\": # save images to folder for manual check\n",
    "    datadir=\"duplicates\"\n",
    "    folder=duplicate_method+'/'\n",
    "    showimage=False #show images\n",
    "    startidx=0 # start index of image to save from each dataset\n",
    "    imgnr=10 # total number of images to save from each dataset\n",
    "    imgstep='random' # step between images: int | 'random' - int steps between images; 'rand' gets random list\n",
    "    path=os.path.join(rdir,datadir,folder)\n",
    "    assure_path_exists(path)\n",
    "    #TODO\n",
    "    #save excel # TODO Send duplicates_l, duplicates_L_catid, duplicates_l_catdset: user should make column  classtofix_l and classtofix_L_catid - user should create  \n",
    "    df=pd.DataFrame({'duplicates_l': duplicates_l,'duplicates_l_catid': duplicates_l_catid, 'duplicates_l_catdset': duplicates_l_catdset, 'classtofix_l': np.nan, 'classtofix_l_catid':np.nan, 'rules':np.nan })\n",
    "    df.loc[0, 'rules']=\"To fix classes: 1) You need to fill the column classtofix_l and/or classtofix_l_catid with the information from the respective duplicate columns; 2) When copy/pasting or changing, make sure the same structure maintains:  ['car', 'carrot'], [3, 52], beware of the spaces ['car', '  and always maintain the first class in the list;  3) You have 3 possibilities of filling the columns : 1-the 2 columns empty, meaning the row will not be used for classtofix; 2-only one column empty, e.g. fill the classtotix_l row with the class labels from duplicates_l, then during the importing the classtofix_l_catid is filled, and vice-versa; 3-If you want to change the name of the first class in the list,e.g ['car', 'carrot'] for ['automobile', 'carrot'] you need to provide the ids to classtofix_l_catid.\"\n",
    "    excelpath=path+duplicate_method+\"_classtofix_report.xlsx\"\n",
    "    df['annotations_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    df['images_missing'] = np.empty((len(df), 0)).tolist()\n",
    "    #save image for each duplicate\n",
    "    for i, duplicate in enumerate(tqdm(duplicates_l)): #run for each duplicate category\n",
    "        minclass=duplicate\n",
    "        if isinstance(minclass, list): minclass=minclass[0]\n",
    "        print('\\n>> '+minclass+'...') #class\n",
    "        classpath=os.path.join(path, minclass) # folder for images of this class\n",
    "        classpath=parse_path(classpath)+'/' #make it a folder\n",
    "        assure_path_exists(classpath)\n",
    "        df=save_imgs(df, rdir, classpath, i, dset_l, duplicates_l, duplicates_l_catid, duplicates_l_bbox, duplicates_l_dset,\n",
    "              duplicates_l_imgid, img_l, img_l_id, startidx=startidx, imgnr=imgnr, imgstep=imgstep, showimage=showimage)\n",
    "    df.to_excel(excelpath, index=False)   \n",
    "if method==\"view_duplicate\":\n",
    "    i=-1 #duplicate_l index : last category\n",
    "    ii=1 #dset_l index : TAO\n",
    "    step=10 #step images\n",
    "    dpi=80\n",
    "    dataset=dset_l[ii]\n",
    "    category=duplicates_l[i]\n",
    "    view_duplicate(rdir, i, ii, dataset, category, duplicates_l_imgid, duplicates_l_bbox, img_l, img_l_id, step=step,\n",
    "                   dpi=dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: CHECK EXCEL FIRST\n",
    "if method==\"save_images\": # reading classtofix from excel\n",
    "    classtofix_l=[]\n",
    "    classtofix_l_catid=[]\n",
    "    df=pd.read_excel(excelpath)\n",
    "    classtofix_df=df.loc[:,'classtofix_l']\n",
    "    classtofix_df_catid=df.loc[:,'classtofix_l_catid']\n",
    "    display(df)\n",
    "    # PARSE COLUMNS TO FIX\n",
    "    classtofix_l=classtofix_df.tolist()\n",
    "    classtofix_l_catid=classtofix_df_catid.tolist()\n",
    "    print(classtofix_l_catid)\n",
    "    #convert strings to lists\n",
    "    for icl, cl in enumerate(classtofix_l): \n",
    "        if isinstance(classtofix_l[icl], str): classtofix_l[icl]=convert_unicode(classtofix_l[icl], method='liststr')\n",
    "        if isinstance(classtofix_l_catid[icl], str): classtofix_l_catid[icl]=convert_unicode(classtofix_l_catid[icl], method='listnum')\n",
    "    print(classtofix_l_catid)\n",
    "    #parse the columns based on the rules    \n",
    "    for ic, classes in enumerate(classtofix_df):\n",
    "        #1. Two columns empty - do nothing, maintain\n",
    "        if  pd.isnull(classtofix_df.iloc[ic]) and pd.isnull(classtofix_df_catid.iloc[ic]): continue\n",
    "        #2. if only classtofix_l_catid empty - get \n",
    "        if not pd.isnull(classtofix_df.iloc[ic]) and pd.isnull(classtofix_df_catid.iloc[ic]):\n",
    "            classes=convert_unicode(classes, method='liststr')\n",
    "            cids=[]\n",
    "            for c in classes:\n",
    "                cidx=duplicates_l[ic].index(c)\n",
    "                cid=duplicates_l_catid[ic][cidx]\n",
    "                cids.append(cid)\n",
    "            classtofix_l_catid[ic]=cids\n",
    "            print(classtofix_l_catid)\n",
    "        #2. if only classtofix_l empty - get\n",
    "        if pd.isnull(classtofix_df.iloc[ic]) and not pd.isnull(classtofix_df_catid.iloc[ic]): \n",
    "            classes=[]\n",
    "            cids=classtofix_l_catid[ic]\n",
    "            for c in cids:\n",
    "                cidx=duplicates_l_catid[ic].index(c)\n",
    "                clas=duplicates_l[ic][cidx]\n",
    "                classes.append(clas)\n",
    "            classtofix_l[ic]=classes\n",
    "        #3. if both columns not empty - do nothing\n",
    "        if not pd.isnull(classtofix_df.iloc[ic]) and not pd.isnull(classtofix_df_catid.iloc[ic]): continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Make sure everything is correct: 1.Drop NaN if exist, but make sure the index is the same for the two! \n",
      "\n",
      "['fork', 'chair', 'clock', 'bird', 'toaster', 'horse', 'umbrella', 'bench', 'skateboard', 'zebra', 'elephant', 'sheep', 'carrot', 'handbag', 'bottle', 'toothbrush', 'pizza', 'knife', 'boat', 'dog', 'apple', 'bed', 'vase', 'scissors', 'cake', 'book', 'bear', 'toilet', 'giraffe', 'suitcase', 'kite', 'spoon', 'bicycle', 'broccoli', 'surfboard', 'motorcycle', 'frisbee', 'backpack', 'cup', 'sink', 'sandwich', 'snowboard', 'cow', 'banana', 'truck', 'cat', 'airplane', 'refrigerator', 'bowl']\n",
      "[[43, 555], [57, 317], [75, 356], [15, 179], [71, 1195], [18, 659], [26, 1235], [14, 171], [37, 1060], [23, 1309], [21, 509], [19, 1041], [52, 301], [27, 115], [40, 213], [80, 1202], [54, 909], [44, 705], [9, 198], [17, 462], [48, 93], [60, 159], [76, 1242], [77, 1017], [56, 265], [74, 206], [22, 158], [62, 1197], [24, 582], [29, 116], [34, 701], [45, 1098], [2, 175], [51, 234], [38, 1137], [4, 794], [30, 560], [25, 114], [42, 427], [72, 1059], [49, 1006], [32, 1073], [20, 161], [47, 125], [8, 1224], [16, 309], [5, 84], [73, 508], [46, 219]]\n"
     ]
    }
   ],
   "source": [
    "print('>> Make sure everything is correct: 1.Drop NaN if exist, but make sure the index is the same for the two! \\n')\n",
    "fixempty=True\n",
    "if fixempty:\n",
    "    classtofix_l=[x for x in classtofix_l if str(x) != 'nan' and str(x) !='[]']\n",
    "    classtofix_l_catid=[x for x in classtofix_l_catid if str(x) != 'nan' and str(x) !='[]']\n",
    "print(classtofix_l)\n",
    "print(classtofix_l_catid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fix classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow # newjson=copy.deepcopy(mlabjson) #do deepcopy to compare\n",
    "# fast\n",
    "newjson={'categories':[],'annotations':[] }\n",
    "newjson['categories']=copy.copy(mlabjson['categories'])\n",
    "newjson['annotations']=copy.copy(mlabjson['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "classtofix_l_catidx=[[cat_l_id.index(id) for id in id_l] for id_l in classtofix_l_catid]\n",
    "#print(classtofix_l_catidx) # they should be less one, becacuse it is ordered\n",
    "print(len(classtofix_l_catidx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change mlabjson['categories']: [{name: , id: }]  \n",
    "=>  use min cat id and remove the other categories (!!!Without ordering again the category id!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "removeidx_l=[]\n",
    "minidx=0 # get first cat: minimum in equal names and the category used to search in similar_names\n",
    "for i,id_l in enumerate(tqdm(classtofix_l_catid)): #for each classtofix\n",
    "    minid=id_l[minidx] # #category id \n",
    "    catidx=classtofix_l_catidx[i][minidx]# get cat index of min catid\n",
    "    if isinstance(classtomix_l[i], list): newjson['categories'][firstcatidx]['name']=classtomix_l[i][minidx] #change name of first id \n",
    "    else: newjson['categories'][catidx]['name']=classtofix_l[i] #change name of min id (if changed)\n",
    "    assert newjson['categories'][catidx]['id']==id_l[minidx] #assert id - it should be the same\n",
    "    otheridx_l=copy.copy(classtofix_l_catidx[i]) #the idx to remove\n",
    "    otheridx_l.remove(catidx)\n",
    "    removeidx_l.extend(otheridx_l) #remove index\n",
    "removeidx_l=list(dict.fromkeys(removeidx_l)) # no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE - Newjson will be changed\n",
    "removeitem_l=[newjson['categories'][removeidx] for removeidx in removeidx_l] #items to remove\n",
    "for removeitem in removeitem_l: newjson['categories'].remove(removeitem) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "if not True: print(True)\n",
    "else: print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supercategory': 'outdoor', 'id': 14, 'name': 'bench', 'dataset': 1}\n",
      "{'supercategory': 'outdoor', 'id': 14, 'name': 'bench', 'dataset': 1}\n",
      "{'frequency': 'f', 'id': 171, 'synset': 'bench.n.01', 'image_count': 93, 'instance_count': 160, 'synonyms': ['bench'], 'def': 'a long seat for more than one person', 'name': 'bench', 'dataset': 2}\n",
      "{'frequency': 'f', 'id': 171, 'synset': 'bench.n.01', 'image_count': 93, 'instance_count': 160, 'synonyms': ['bench'], 'def': 'a long seat for more than one person', 'name': 'bench', 'dataset': 2}\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(mlabjson['categories'][13])\n",
    "print(newjson['categories'][13])\n",
    "print(mlabjson['categories'][170])\n",
    "print(newjson['categories'][170])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change mlabjson['annotations']: [{category_id: , }] \n",
    "=> remove_catid_l to annidx_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "17\n",
      "6860\n",
      "681\n",
      "1172463\n"
     ]
    }
   ],
   "source": [
    "ann_catid_np=np.array(ann_catid)\n",
    "classtofix_l_ann_catidx=[[np.where(ann_catid_np==id)[0].tolist()  for id in id_l] for id_l in classtofix_l_catid]\n",
    "print(len(classtofix_l_ann_catidx))\n",
    "print(classtofix_l_catidx[0][0])\n",
    "print(len(classtofix_l_ann_catidx[0][0]))\n",
    "print((classtofix_l_ann_catidx[0][0][0]))#to maintain same id\n",
    "print((classtofix_l_ann_catidx[0][1][0]))#to change same id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,id_l in enumerate(classtofix_l_catid): #for each classtofix\n",
    "    minidx=0 # get first catid min\n",
    "    minid=id_l[minidx]\n",
    "    ann_catidx= classtofix_l_ann_catidx[i][minidx]# get annotation cat index of min catid\n",
    "    ann_otheridx_l=copy.copy(classtofix_l_ann_catidx[i])\n",
    "    ann_otheridx_l.remove(ann_catidx) #the idx to change\n",
    "    for ann_otheridx in ann_otheridx_l[0]: newjson['annotations'][ann_otheridx]['category_id']=minid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segmentation': [[20.95, 105.11, 20.95, 87.58, 8.43, 80.69, 8.43, 75.06, 38.48, 74.43, 40.35, 66.92, 32.22, 63.79, 39.1, 35.62, 135.51, 37.5, 130.5, 65.04, 128.0, 70.05, 124.87, 108.86, 119.86, 102.6, 119.23, 86.95, 111.72, 86.95, 106.08, 107.61, 104.83, 107.61, 98.57, 90.71, 77.91, 86.33, 64.77, 86.33, 55.38, 90.08, 45.99, 100.73, 45.36, 109.49, 41.61, 110.12, 40.35, 97.6, 35.97, 89.46, 29.71, 86.95, 24.7, 93.84, 24.7, 105.73]], 'area': 5697.957150000001, 'iscrowd': 0, 'image_id': 26929, 'bbox': [8.43, 35.62, 127.08, 74.5], 'category_id': 14, 'id': 8876, 'dataset': 1}\n",
      "{'segmentation': [[20.95, 105.11, 20.95, 87.58, 8.43, 80.69, 8.43, 75.06, 38.48, 74.43, 40.35, 66.92, 32.22, 63.79, 39.1, 35.62, 135.51, 37.5, 130.5, 65.04, 128.0, 70.05, 124.87, 108.86, 119.86, 102.6, 119.23, 86.95, 111.72, 86.95, 106.08, 107.61, 104.83, 107.61, 98.57, 90.71, 77.91, 86.33, 64.77, 86.33, 55.38, 90.08, 45.99, 100.73, 45.36, 109.49, 41.61, 110.12, 40.35, 97.6, 35.97, 89.46, 29.71, 86.95, 24.7, 93.84, 24.7, 105.73]], 'area': 5697.957150000001, 'iscrowd': 0, 'image_id': 26929, 'bbox': [8.43, 35.62, 127.08, 74.5], 'category_id': 14, 'id': 8876, 'dataset': 1}\n",
      "{'image_id': 77836, 'id': 1174301, 'caption': 'There is a lawnmower loaded into a pickup truck', 'dataset': 1}\n",
      "{'image_id': 77836, 'id': 1174301, 'caption': 'There is a lawnmower loaded into a pickup truck', 'dataset': 1, 'category_id': 14}\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(mlabjson['annotations'][8875])\n",
    "print(newjson['annotations'][8875])\n",
    "print(mlabjson['annotations'][1174300])\n",
    "print(newjson['annotations'][1174300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save fixed json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast\n",
    "mlabjson['categories']=copy.copy(newjson['categories'])\n",
    "mlabjson['annotations']=copy.copy(newjson['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING...\n",
      "JSON SAVED : D:/external_datasets/mlabequal.json \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "print('\\n >> SAVING...')\n",
    "jsonfile=rdir+'mlab_fix_equal.json'\n",
    "with open(jsonfile, 'w') as f:\n",
    "    json.dump(newjson, f)\n",
    "print(\"JSON SAVED : {} \\n\".format(jsonfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #DEBUG 'mlab_fix_equal.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlabjson =  json.load(open(rdir+'mlab_fix_equal.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 5\n",
      "licenses 9\n",
      "categories 1261\n",
      "videos 1488\n",
      "images 177936\n",
      "tracks 8132\n",
      "segment_info 0\n",
      "annotations 1954769\n",
      "datasets 2\n"
     ]
    }
   ],
   "source": [
    "for k in mlabjson:\n",
    "    print(k, len(mlabjson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COCO', 'TAO'] [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# datasets name and id\n",
    "dset_l=[]\n",
    "dset_l_id=[]\n",
    "for d in mlabjson['datasets']:\n",
    "    dset_l.append(d['name'])\n",
    "    dset_l_id.append(d['id'])\n",
    "print(dset_l, dset_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories name and id\n",
    "cat_l=[]\n",
    "cat_l_id=[]\n",
    "cat_l_dset=[]\n",
    "for c in mlabjson['categories']:\n",
    "    cat_l.append(c['name'])\n",
    "    cat_l_id.append(c['id'])\n",
    "    cat_l_dset.append(dset_l[c['dataset']-1]) # dset_l index is same as id-1\n",
    "#print(cat_l_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images filepath and id\n",
    "img_l=[]\n",
    "img_l_id=[]\n",
    "for c in mlabjson['images']:\n",
    "    img_l.append(c['file_name'])\n",
    "    img_l_id.append(c['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████                                     | 860001/1954769 [00:00<00:01, 899572.23it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'category_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cad5cb95cd71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mann_dset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0man\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlabjson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annotations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mann_catid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mann_imgid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mann_bbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bbox'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'category_id'"
     ]
    }
   ],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "ann_dset=[]\n",
    "for an in tqdm(mlabjson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "    ann_dset.append(an['dataset'])\n",
    "#NOTE: \"TRY is NOT a good idea!!!: if something fails you should not use that annotation\n",
    "print(len(ann_catid), len(ann_imgid), len(ann_bbox), len(ann_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-14-cad5cb95cd71>\u001b[0m(7)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      5 \u001b[1;33m\u001b[0mann_dset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6 \u001b[1;33m\u001b[1;32mfor\u001b[0m \u001b[0man\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlabjson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annotations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 7 \u001b[1;33m    \u001b[0mann_catid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      8 \u001b[1;33m    \u001b[0mann_imgid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m    \u001b[0mann_bbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0man\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bbox'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  an\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 26942, 'id': 860002, 'caption': 'A bicycle replica with a clock as the front wheel.', 'dataset': 1}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocojson =  json.load(open(rdir+'COCO/2017/annotations/instances_val2017.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 36781/36781 [00:00<00:00, 994197.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36781 36781 36781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id, image_id, bbox, and dataset\n",
    "ann_catid=[]\n",
    "ann_imgid=[]\n",
    "ann_bbox=[]\n",
    "for an in tqdm(cocojson['annotations']):\n",
    "    ann_catid.append(an['category_id'])\n",
    "    ann_imgid.append(an['image_id'])\n",
    "    ann_bbox.append(an['bbox'])\n",
    "#NOTE: \"TRY is NOT a good idea!!!: if something fails you should not use that annotation\n",
    "print(len(ann_catid), len(ann_imgid), len(ann_bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[267.03,\n",
       "   243.78,\n",
       "   314.59,\n",
       "   154.05,\n",
       "   357.84,\n",
       "   136.76,\n",
       "   374.05,\n",
       "   104.32,\n",
       "   410.81,\n",
       "   110.81,\n",
       "   429.19,\n",
       "   131.35,\n",
       "   420.54,\n",
       "   165.95,\n",
       "   451.89,\n",
       "   209.19,\n",
       "   464.86,\n",
       "   240.54,\n",
       "   480,\n",
       "   253.51,\n",
       "   484.32,\n",
       "   263.24,\n",
       "   496.22,\n",
       "   271.89,\n",
       "   484.32,\n",
       "   278.38,\n",
       "   438.92,\n",
       "   257.84,\n",
       "   401.08,\n",
       "   216.76,\n",
       "   370.81,\n",
       "   247.03,\n",
       "   414.05,\n",
       "   277.3,\n",
       "   433.51,\n",
       "   304.32,\n",
       "   443.24,\n",
       "   323.78,\n",
       "   400,\n",
       "   362.7,\n",
       "   376.22,\n",
       "   375.68,\n",
       "   400,\n",
       "   418.92,\n",
       "   394.59,\n",
       "   424.32,\n",
       "   337.3,\n",
       "   382.16,\n",
       "   337.3,\n",
       "   371.35,\n",
       "   388.11,\n",
       "   327.03,\n",
       "   341.62,\n",
       "   301.08,\n",
       "   311.35,\n",
       "   276.22,\n",
       "   304.86,\n",
       "   263.24,\n",
       "   294.05,\n",
       "   249.19]],\n",
       " 'num_keypoints': 8,\n",
       " 'area': 28292.08625,\n",
       " 'iscrowd': 0,\n",
       " 'keypoints': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  325,\n",
       "  160,\n",
       "  2,\n",
       "  398,\n",
       "  177,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  437,\n",
       "  238,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  477,\n",
       "  270,\n",
       "  2,\n",
       "  287,\n",
       "  255,\n",
       "  1,\n",
       "  339,\n",
       "  267,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  423,\n",
       "  314,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  355,\n",
       "  367,\n",
       "  2],\n",
       " 'image_id': 537548,\n",
       " 'bbox': [267.03, 104.32, 229.19, 320],\n",
       " 'category_id': 1,\n",
       " 'id': 183020}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocojson['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
