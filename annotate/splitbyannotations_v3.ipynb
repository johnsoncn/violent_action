{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split datasets\n",
    "version: 3\n",
    "\n",
    "info:\n",
    "- split json into train.json, val.json and test.json \n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotate_v5 import *\n",
    "import platform \n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import copy\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from matplotlib.patches import Rectangle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.21292-SP0\n",
      "root dir: D:/external_datasets/MOLA/annotations/\n"
     ]
    }
   ],
   "source": [
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/MOLA/annotations/' \n",
    "if str(platform.platform()).find('linux')>-1: rdir=rdir.replace('D:/','/mnt/d/')\n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root dir: {}'.format(rdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=70\n",
    "val=20\n",
    "test=100-(train+val)\n",
    "injsonfile='coco2017_reorder_cleanclass.json'\n",
    "infilename=injsonfile.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 1170251\n",
      "categories 80\n"
     ]
    }
   ],
   "source": [
    "# init json\n",
    "molajson =  json.load(open(rdir+injsonfile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import ids\n",
    "#### #NOTE: work with ids and index so you can use numpy for faster operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories id\n",
    "catids=[]\n",
    "cats=[]\n",
    "for c in molajson['categories']:\n",
    "    catids.append(c['id'])\n",
    "    cats.append(c['name'])\n",
    "#print(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1170251/1170251 [00:00<00:00, 1215215.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id\n",
    "ann_catids=[]\n",
    "ann_ids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_catids.append(an['category_id'])\n",
    "    ann_ids.append(an['id'])\n",
    "print(len(ann_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273469\n"
     ]
    }
   ],
   "source": [
    "#TEST dupplicates v1 - slow\n",
    "# duplicates_l=list(set([x for x in ann_ids if ann_ids.count(x) > 1])) # duplicates l \n",
    "#TEST dupplicates v2 - fast\n",
    "#from collections import Counter\n",
    "#duplicates_l=[item for item, count in Counter(ann_ids).items() if count > 1]\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. split by annotations\n",
    "#QUESTION Seeded random or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 80/80 [00:01<00:00, 55.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.99677846889257\n",
      "19.983832528235396\n",
      "9.989993599663661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ann_catids_np=np.array(ann_catids)\n",
    "train_ann_catidx=[]\n",
    "val_ann_catidx=[]\n",
    "test_ann_catidx=[]\n",
    "for catid in tqdm(catids):\n",
    "    ann_idx_np = np.where(ann_catids_np==catid)[0] #annotation index of ids\n",
    "    if not ann_idx_np.any(): continue\n",
    "    #print(\"\\n>> \", catid)\n",
    "    \n",
    "    #assert ann_idx_np\n",
    "    u, c = np.unique(ann_idx_np, return_counts=True)\n",
    "    duplicates_l= u[c > 1].tolist()\n",
    "    assert len(duplicates_l)==0 #assert duplicates (above is already)\n",
    "    assert all([True if ann_catids[i]==catid else False for i in ann_idx_np] ) #assert index belongs to catid\n",
    "    \n",
    "    #parameters\n",
    "    train_size=len(ann_idx_np) * train // 100 #floor division\n",
    "    val_size=len(ann_idx_np) * val // 100\n",
    "    test_size=len(ann_idx_np) * test // 100\n",
    "    \n",
    "    #select data\n",
    "    random.shuffle(ann_idx_np) \n",
    "    train_ann_catidx.extend(ann_idx_np[:train_size].tolist())\n",
    "    val_ann_catidx.extend(ann_idx_np[train_size+1:train_size+val_size-1].tolist())\n",
    "    test_ann_catidx.extend(ann_idx_np[train_size+val_size+1:train_size+val_size+test_size].tolist())\n",
    "\n",
    "\n",
    "print((len(train_ann_catidx)/len(ann_catids))*100)\n",
    "print((len(val_ann_catidx)/len(ann_catids))*100)\n",
    "print((len(test_ann_catidx)/len(ann_catids))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:  819138\n",
      "duplicate:  0\n",
      "original:  233861\n",
      "duplicate:  0\n",
      "original:  116908\n",
      "duplicate:  0\n"
     ]
    }
   ],
   "source": [
    "l_dup=[train_ann_catidx, val_ann_catidx,test_ann_catidx ]\n",
    "for i in l_dup:\n",
    "    print('original: ', len(i))\n",
    "    u, c = np.unique(np.array(i), return_counts=True)\n",
    "    duplicates_l= u[c > 1].tolist()\n",
    "    print('duplicate: ',len(duplicates_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save splited jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_idx=[train_ann_catidx,val_ann_catidx, test_ann_catidx]\n",
    "percent_names=['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "newjson=copy.copy(molajson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> SAVING train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████                                                      | 1/3 [02:09<04:19, 129.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/MOLA/annotations/splitann_coco2017_reorder_cleanclass/train.json \n",
      "\n",
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 819138\n",
      "categories 80\n",
      "\n",
      " >> SAVING val...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████                           | 2/3 [02:48<01:42, 102.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/MOLA/annotations/splitann_coco2017_reorder_cleanclass/val.json \n",
      "\n",
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 233861\n",
      "categories 80\n",
      "\n",
      " >> SAVING test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [03:09<00:00, 63.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON SAVED : D:/external_datasets/MOLA/annotations/splitann_coco2017_reorder_cleanclass/test.json \n",
      "\n",
      "info 6\n",
      "licenses 8\n",
      "images 123287\n",
      "annotations 116908\n",
      "categories 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "annotations=copy.copy(molajson['annotations']) \n",
    "for i, percent_i in enumerate(tqdm(percent_idx)):\n",
    "    #get new annotations\n",
    "    newjson['annotations']=[annotations[index] for index in percent_i]\n",
    "    # save\n",
    "    print('\\n >> SAVING {}...'.format(percent_names[i]))\n",
    "    outpath=rdir+'splitann_{}/'.format(infilename)\n",
    "    assure_path_exists(outpath)\n",
    "    outjsonfile=outpath+'{}.json'.format(percent_names[i]) #rdir+'{}_{}.json'.format(percent_names[i],infilename)\n",
    "    with open(outjsonfile, 'w') as f:\n",
    "        json.dump(newjson, f)\n",
    "    print(\"JSON SAVED : {} \\n\".format(outjsonfile))\n",
    "    for k in molajson:\n",
    "        print(k, len(newjson[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TEST SPLIT ANNOTATIONS DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/external_datasets/MOLA/annotations/split_coco2017_reorder_cleanclass/test.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aea0f019f101>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutjsonfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrdir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'split_{}/'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'test.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# init json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmolajson\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutjsonfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmolajson\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmolajson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/external_datasets/MOLA/annotations/split_coco2017_reorder_cleanclass/test.json'"
     ]
    }
   ],
   "source": [
    "injsonfile='mola_mix_aggressive.json'\n",
    "outjsonfile=rdir+'split_{}/'.format(infilename)+'test.json'\n",
    "# init json\n",
    "molajson =  json.load(open(outjsonfile))\n",
    "for k in molajson:\n",
    "    print(k, len(molajson[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 133266/133266 [00:00<00:00, 1497403.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133266\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# annotations category_id\n",
    "ann_ids=[]\n",
    "for an in tqdm(molajson['annotations']):\n",
    "    ann_ids.append(an['id'])\n",
    "print(len(ann_ids))\n",
    "\n",
    "#TEST duplicates v3 -faster\n",
    "u, c = np.unique(np.array(ann_ids), return_counts=True)\n",
    "duplicates_l= u[c > 1].tolist()\n",
    "print(len(duplicates_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
