{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL \n",
    "\n",
    "author: nmc-costa\n",
    "\n",
    "info: \n",
    "- violent_action tutorial: setup and testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git https://github.com/nmc-costa/violent_action.git  # clone repo\n",
    "!conda env create -f violent_action/conda/win_env.yml #current windows build (there is also anyOS_env.yml, but for windows may not work)\n",
    "#!pip install -qr violent_action/requirements.txt  # install dependencies using pip instead of conda (ignore errors)\n",
    "#TODO setup.py installation with all dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. [DEMO] yolov5 aggressive and non aggresive\n",
    "- 9.1. annotate mlabjson into agressive and nonaggressive  \n",
    "    - 9.1.1. mergedatasets: Merge different datasets annotations into mlabjson \n",
    "    - 9.1.2. fixclasses: find and fix duplicates (equal names and similar names)\n",
    "    - 9.1.3. mixclasses: mix/fusion of classes into other classes (example: aggressive|nonaggressive)\n",
    "    - 9.1.4. filterdatasets: train, val and test json\n",
    "- 9.2. json2yolo Annotations:  json2yolo/json2yolo.py\n",
    "- 9.3. Inference using yolov5 to track objects in video\n",
    "    - 9.3.1. Test retrain models from checkpoint (run yolo/yolov5_v2.ipynb)\n",
    "    - 9.3.2. Test retrain models from scratch (run yolo/yolov5_v2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# COMPLETED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. datasets for object tracking: \n",
    "test datasets/datasets_objecttracking_v2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. datasets for human action traking: \n",
    "test datasets/datasets_actiontracking_v4.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create sharable project in Github\n",
    "Link: https://github.com/nmc-costa/violent_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resolve yolov5 faulty installation: \n",
    "#WARNING yolov5 developed in linux\n",
    "\n",
    "#NOTE check requirements.txt for solutions or see below the FAQs\n",
    "- Below the requirements.txt FAQs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQs\n",
    "#------\n",
    "\n",
    "# #WARNING windows : pycocotools fails - use pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
    "# #WARNING windows : gives pip errors ; #SOLUTION installing individually with conda \n",
    "# #WARNING windows : has path problems - see below\n",
    "# #WARNING (WSL-windows subsystem for linux) : pytorch problems \n",
    "# #WARNING WSL : gives pip errors ; #SOLUTION installing with conda \n",
    "# #WARNING WSL : CUDA LIMITATIONS ; #SOLUTION 1) update wsl to wsl 2 kernel: https://docs.microsoft.com/en-us/windows/wsl/install-win10#update-to-wsl-2  ; 2) install windows dev insider build >20150, install cuda-toolkit by following: https://docs.nvidia.com/cuda/wsl-user-guide/index.html #NOTE if ubuntu 2004, just change 1804 in paths; check using torch: import torch torch.cuda.is_available(); #NOTE Performance on GTX 1070: https://developer.nvidia.com/blog/announcing-cuda-on-windows-subsystem-for-linux-2/\n",
    "# #WARNING WSL : spyder needs GUI to work: #SOLUTION https://medium.com/@macasaetjohn/setting-up-a-spyder-environment-with-wsl-bb83716a44f3\n",
    "# #WARNING yolov5: runs are saved inside yolov5/runs/\n",
    "\n",
    "\n",
    "# #BUG WINDOWS yolov5 1 : yolov5.utils.increment_dir function error in windows path ; #SOLVED use (try: except: pass)\n",
    "# #BUG yolov5 2 : zip(*[cache[x] for x in self.img_files]) in yolov5.utils.datasets gives keyerror; #SOLUTION delete cache in dataset, e.g. if img_files='/mnt/d/external_datasets/coco128/images/train2017/000000000073.jpg' and cache key = '/Volumes/Seagate/p19/external_datasets/coco128/images/train2017/000000000073.jpg' you will have a keyerror\n",
    "# #BUG CODE yolov5 : they use 'opt' var declared in if __name__ == '__main__': as a global var : #WARNING can only debug inside script, or you need to recreate the opt as global in your script; pip install -e will be the last resort\n",
    "# #BUG yolov5 pytorch: needs torch==1.5.1 and torchvisio==0.6.1: #SOLVED WSL with cuda: pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. yolov5 validation test: test yolo/yolov5_v2_coco128test.ipynb\n",
    "    - train, test and inference(detect) working in Windows and WSL2\n",
    "    - #TODO #BUG WINDOWS jupyter don't print in realtime to console; macOS and WSL works in real time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5.1 Check yolo/coco128_external.yaml paths\n",
    "- 5.2 Check yolo/yolov5/models/yolov5s.yaml 'nc:80' number of class parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run yolo/yolov5_v2_coco128test.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. yolov5 validation Test: TAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6.1. (json2yolo) Annotations=> YOLO FORMAT : test json2yolo/json2yolo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo.json2yolo.json2yolo import convert_tao_json\n",
    "\n",
    "#CREATE LABELS and IMAGES FOLDER (D:/ or /mnt/d/ WSL)\n",
    "convert_tao_json(json_dir='/mnt/d/external_datasets/TAO/TAO_DIR/annotations/', \n",
    "                 outdir=\"/mnt/d/external_datasets/yoloformat/tao8/\", img_number=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### #BUG MISSING TAO FILES - Download problems; or TAO staff removed images that are in the annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6.2. TAO yolov5 validation test: test yolo/yolov5_v2_tao128test.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        6.2.1 Check yolo/tao128_external.yaml paths\n",
    "        6.2.2 Check yolo/yolov5/models/yolov5s.yaml 'nc:1230' number of class parameter\n",
    "        6.2.3 Delete yolo/yolov5/runs/exp0 ->in windows exp0 doens't increment, so it is implemented !rm -rfv runs/exp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run yolo/yolov5_v2_tao128test.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [DEMO] Inference : yolov5 tracking objects in video \n",
    "\n",
    "- 7.1. Default Inference with pretrained yolov5 models\n",
    "    - Don't forget to fix source and output for your case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run yolo/yolov5_defaultdetect_v1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 7.2. Inference with retrained models with new data\n",
    "    - Two options: 1) Retrain models from scratch 2) Retrain models from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.: \n",
    "run yolo/yolov5_v2_coco128test.ipynb\n",
    "# or \n",
    "run yolo/yolov5_v2_tao128test.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Annotate method (mlabjson):\n",
    "1. mergedatasets: Merge different datasets annotations json \n",
    "2. fixclasses: find and fix duplicates (equal names and similar names)\n",
    "3. mixclasses: mix/fusion of classes into other classes (example: aggressive|nonaggressive)\n",
    "4. filterdatasets: train, val and test json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. mergedatasets\n",
    "run annotate/mergedatasets_v6.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. fixclasses\n",
    "run annotate/fixclasses_v3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. mixclasses\n",
    "run annotate/mixclasses_v1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. filterdatasets\n",
    "run annotate/filterdatasets_v1.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
