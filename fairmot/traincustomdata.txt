#WARNING: one-class multi-object tracking

-------
SCRIPT:
-------
-Use json2fairmot.py to create dataset dir with images and labels.
-If already have images, use gen_fairmot_labels.

--------
DETAILED:
--------
Dataset preparation:
Dataset
   |——————images
   |        └——————train
   |        └——————val
   └——————labels_with_ids
   |         └——————train(empty)
   |         └——————val(empty)

Train on custom dataset:
You can train FairMOT on custom dataset by following several steps bellow:

	1.Generate one txt label file for one image. Each line of the txt label file represents one object. The format of the line is: "class id x_center/img_width y_center/img_height w/img_width h/img_height". You can modify src/gen_labels_16.py to generate label files for your custom dataset.
	2.Generate files containing image paths. The example files are in src/data/. Some similar code can be found in src/gen_labels_crowd.py
	3.Create a json file for your custom dataset in src/lib/cfg/. You need to specify the "root" and "train" keys in the json file. You can find some examples in src/lib/cfg/.
	4.Add --data_cfg '../src/lib/cfg/your_dataset.json' when training.


Labels: 
src.gen_labels
label_str = '0 {:d} {:.6f} {:.6f} {:.6f} {:.6f}\n'.format(
                tid_curr, x / img_width, y / img_height, w / img_width, h / img_height) 
0 -> class id
tid_curr - track_id -> cada bbox tem um id unico, para o caso de uma anotação ter mais do que uma bbox.("gtboxes" - ground truth boxes?)

