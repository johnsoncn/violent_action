{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yolov5\n",
    "version 2 \n",
    "\n",
    "author: nmc-costa\n",
    "\n",
    "info: testing version 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "Go to tutorial_yolov5.ipnb for full setup (like cloning the yolov5 repo, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-10-10.0.20251-SP0\n",
      "root dir: D:/external_datasets/\n",
      "Python: 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]\n",
      "Setup complete. Using torch 1.5.1 _CudaDeviceProperties(name='GeForce GTX 1070', major=6, minor=1, total_memory=8192MB, multi_processor_count=16)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#Define root dir dependent on OS\n",
    "rdir='D:/external_datasets/' \n",
    "if str(platform.platform()).find('linux')>-1: rdir='/mnt/d/external_datasets/' \n",
    "print('OS: {}'.format(platform.platform()))\n",
    "print('root dir: {}'.format(rdir))\n",
    "print(\"Python: \" + sys.version)\n",
    "\n",
    "#cuda \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" #force CPU\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\n",
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\json2yolo\n"
     ]
    }
   ],
   "source": [
    "# DIRs [needed if you use %cd command multiple times ]\n",
    "#script dir \n",
    "scriptdir=sys.path[0] #os.getcwd()\n",
    "#yolov5 Dir\n",
    "yolov5_dir=os.path.join(scriptdir, 'yolov5')\n",
    "print(yolov5_dir)\n",
    "#json2yolo Dir\n",
    "json2yolo_dir=os.path.join(scriptdir, 'json2yolo')\n",
    "print(json2yolo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. input data\n",
    "#### Prepare the dataset for yolo format (CHECK OUT https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data ; https://medium.com/towards-artificial-intelligence/yolo-v5-is-here-custom-object-detection-tutorial-with-yolo-v5-12666ee1774e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Create labels and organize dataset in YOLO format (USE $JSON2YOLO$ folder)\n",
    "\n",
    "Dataset Directory structure:\n",
    "- dataset:\n",
    "    - annotations:\n",
    "        - samefoldername.json (WARNING: use 'train', 'val', 'test')\n",
    "    - images:\n",
    "        - samefoldername\n",
    "    - labels:\n",
    "        - samefoldername\n",
    "\n",
    "Example :\n",
    "\n",
    "dataset/images/train/000000109622.jpg  # image\n",
    "\n",
    "dataset/labels/train/000000109622.txt  # label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "source=\"mola\"\n",
    "datasets_root_dir='D:/external_datasets/'\n",
    "json_dir='D:/external_datasets/MOLA/annotations/train_mola_mix_aggressive/'\n",
    "outdir=\"D:/external_datasets/MOLA/yoloformat/mola128/\"\n",
    "img_number=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $json2yolo_dir\n",
    "!python json2yolo.py --source $source --datasets_root_dir $datasets_root_dir --json_dir $json_dir --outdir $outdir --img_number $img_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. create dataset .yaml file (like coco_external)\n",
    "\n",
    "Yolov5 algorithm parses yaml information: path to dataset(train, validation and test) in YOLO (darknet) format (see below); number of classes and classes names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YAML Paths\n",
    "datasetyaml=os.path.join(scriptdir, 'coco128_external.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Select a Model(yolov5s, yolov5x, ...) and update the number of classes to match the dataset\n",
    "\n",
    "Go to $./models$ folder and copy model .yaml file tho this directory and change the $nc: $ parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YAML Paths\n",
    "modelyaml=os.path.join(scriptdir, 'yolov5s.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train\n",
    "Run the training command below to train for X epochs. \n",
    "\n",
    "EXAMPLE: You can train YOLOv5s from scratch by passing `--cfg yolov5s.yaml --weights ''`, or train from a pretrained checkpoint by passing a matching weights file: `--cfg yolov5s.yaml --weights yolov5s.pt`.\n",
    "\n",
    "Train function retrains the model with the new 'train' data and tests the model against the 'val' data\n",
    "\n",
    "All training results are saved to runs/exp0 for the first experiment, then runs/exp1, runs/exp2 etc. for subsequent experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "#BUG WINDOWS runs/exp0 don't iterates to exp1,exp2,...\n",
    "logdir=os.path.join(yolov5_dir, 'runs/exp0')\n",
    "!rm -rfv $logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 16248."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard (optional)\n",
    "#BUG WINDOWS are not able to log information\n",
    "%cd $yolov5_dir\n",
    "\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\n",
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "Namespace(batch_size=8, bucket='', cache_images=False, cfg='./models/yolov5s.yaml', data='C:\\\\Users\\\\nmc_costa\\\\google_drive\\\\projects\\\\bosch_P19\\\\research\\\\python_ws\\\\violent_action\\\\yolo\\\\mola8_external.yaml', device='', epochs=3, evolve=False, hyp='', img_size=[640], multi_scale=False, name='', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights=\"''\")\n",
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce GTX 1070', total_memory=8192MB)\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "Hyperparameters {'optimizer': 'SGD', 'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n",
      "Overriding ./models/yolov5s.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning images:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "Scanning images: 100%|##########| 8/8 [00:00<00:00, 800.00it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 404, in <module>\n",
      "    train(hyp)\n",
      "  File \"train.py\", line 164, in train\n",
      "    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\utils\\datasets.py\", line 50, in create_dataloader\n",
      "    dataset = LoadImagesAndLabels(path, imgsz, batch_size,\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\utils\\datasets.py\", line 335, in __init__\n",
      "    cache = self.cache_labels(cache_path)  # cache\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\utils\\datasets.py\", line 455, in cache_labels\n",
      "    torch.save(x, path)  # save for next time\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py\", line 369, in save\n",
      "    with _open_file_like(f, 'wb') as opened_file:\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py\", line 234, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py\", line 215, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\external_datasets\\\\COCO\\\\2017\\\\labels\\\\train2017.cache'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1      2709  torch.nn.modules.conv.Conv2d            [128, 21, 1, 1]               \n",
      " 19                -2  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 22                -1  1      5397  torch.nn.modules.conv.Conv2d            [256, 21, 1, 1]               \n",
      " 23                -2  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 26                -1  1     10773  torch.nn.modules.conv.Conv2d            [512, 21, 1, 1]               \n",
      " 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [2, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\n",
      "Model Summary: 191 layers, 7.25779e+06 parameters, 7.25779e+06 gradients\n",
      "\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n"
     ]
    }
   ],
   "source": [
    "# Train Models from scractch \n",
    "#(#WARNING: if using --cache parameter you need to be careful: in yolov5.utils.datasets gives keyerror; #SOLUTION delete cache in dataset folder or don't use --cache)\n",
    "%cd $yolov5_dir\n",
    "#!pwd\n",
    "# !ls\n",
    "!python train.py --img 640 --batch 8 --epochs 3 --data $datasetyaml --cfg $modelyaml --weights ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Output data (Visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View runs/exp0/train*.jpg images to see training images, labels and augmentation effects. A Mosaic Dataloader is used for training (shown below), a new concept developed by Ultralytics and first featured in YOLOv4. If your labels are not correct in these images then you have incorrectly labelled your data, and should revisit 2. Create Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=os.path.join(yolov5_dir,'runs/exp0/train_batch0.jpg'), width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference (detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $yolov5_dir\n",
    "!python detect.py --source D:/external_datasets/mola_samples/VIDEOS --output  D:/external_datasets/mola_samples/inference/yolov5/yolov5s_coco128test_augment --weights runs/exp0/weights/best.pt --conf 0.4 --augment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (Re-) Test/validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Re-) Test a model on dataset to determine trained accuracy (WARNING : Train already does this). Models are auto-downloaded from Google Drive. To show results by class use the --verbose flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHELL Ipython: Run YOLOv5x on COCO validation images\n",
    "%cd $yolov5_dir\n",
    "#!pwd\n",
    "#!ls\n",
    "!python test.py --weights runs/exp0/weights/best.pt --data $yaml --task 'val' --img 672 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
