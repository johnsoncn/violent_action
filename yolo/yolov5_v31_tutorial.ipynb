{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvhYZrIZCEyo"
   },
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/26833433/98702494-b71c4e80-237a-11eb-87ed-17fcd6b3f066.jpg\">\n",
    "\n",
    "This notebook was written by Ultralytics LLC, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
    "For more information please visit https://github.com/ultralytics/yolov5 and https://www.ultralytics.com.\n",
    "\n",
    "\n",
    "\n",
    "ADAPTED TO PROBLEMATIC by Nuno Costa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Clone repo, install dependencies and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "7e5e09a2-892e-4999-9e6c-567ea329eb38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.7.0+cu101 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16130MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install dependencies - #BUG matplotlib in pip install\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\n",
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\json2yolo\n"
     ]
    }
   ],
   "source": [
    "# DIRs [needed if you use %cd command multiple times ]\n",
    "import sys\n",
    "import os\n",
    "#script dir \n",
    "scriptdir=sys.path[0] #os.getcwd()\n",
    "#yolov5 Dir\n",
    "yolov5_dir=os.path.join(scriptdir, 'yolov5')\n",
    "print(yolov5_dir)\n",
    "#json2yolo Dir\n",
    "json2yolo_dir=os.path.join(scriptdir, 'json2yolo')\n",
    "print(json2yolo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.7.0 _CudaDeviceProperties(name='GeForce GTX 1070', major=6, minor=1, total_memory=8192MB, multi_processor_count=16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 1. Inference\n",
    "\n",
    "`detect.py` runs inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "zR9ZbuQCH7FX",
    "outputId": "c9a308f7-2216-4805-8003-eca8dd0dc30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='0', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', project='runs/detect', save_conf=False, save_txt=False, source='data/images/', update=False, view_img=False, weights=['yolov5x.pt'])\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 1.7.0 CUDA:0 (GeForce GTX 1070, 8192MB)\n",
      "\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.common.Conv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Detect' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Model Summary: 483 layers, 88922205 parameters, 4390525 gradients\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 172, in <module>\n",
      "    detect()\n",
      "  File \"detect.py\", line 61, in detect\n",
      "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 121, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 137, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 48, in forward\n",
      "    x[i] = self.m[i](x[i])  # conv\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 778, in __getattr__\n",
      "    raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "torch.nn.modules.module.ModuleAttributeError: 'Detect' object has no attribute 'm'\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights yolov5x.pt --img 640 --conf 0.25 --source data/images/ --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/exp/zidane.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a548615854de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'runs/detect/exp/zidane.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[0;32m   1225\u001b[0m                 metadata=metadata)\n\u001b[0;32m   1226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1257\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/exp/zidane.jpg'"
     ]
    }
   ],
   "source": [
    "Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qbaa3iEcrcE"
   },
   "source": [
    "Results are saved to `runs/detect`. A full list of available inference sources:\n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/98274798-2b7a7a80-1f94-11eb-91a4-70c73593e26b.jpg\" width=\"900\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 2. Test\n",
    "Test a model on [COCO](https://cocodataset.org/#home) val or test-dev dataset to evaluate trained accuracy. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be 1-2% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyTZYGgRjnMc"
   },
   "source": [
    "## COCO val2017\n",
    "Download [COCO val 2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L14) dataset (1GB - 5000 images), and test model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "9cb5be61e41144ef9dbc9339c2f46eb1",
      "a6ba87512fd04622b9948571d330d9c0",
      "ed1a514c303b49c0a23745f4ff17344b",
      "79edc4bba71748338f58660262c569a9",
      "cbbf6780f4f048feb2644ed4e3fed9c7",
      "e40fc489500f4e4891025c59b2b1fa8d",
      "191c687c120f4aab9a112697124fe444",
      "6b21efad6db4407eb253f819f279671a"
     ]
    },
    "id": "WQPtK1QYVaD_",
    "outputId": "12268ac4-b9eb-44de-b3a7-2bd3e2fea46f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb5be61e41144ef9dbc9339c2f46eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=819257867.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download COCO val2017\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017val.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YAML Paths # coco  val2017 yaml\n",
    "datasetyaml=os.path.join(scriptdir, 'coco_external.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "30601131-102c-4702-fc13-572cc6087330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment=False, batch_size=32, conf_thres=0.001, data='C:\\\\Users\\\\nmc_costa\\\\google_drive\\\\projects\\\\bosch_P19\\\\research\\\\python_ws\\\\violent_action\\\\yolo\\\\coco128_external.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', project='runs/test', save_conf=False, save_json=False, save_txt=False, single_cls=False, task='val', verbose=False, weights=['yolov5x.pt'])\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 1.7.0 CUDA:0 (GeForce GTX 1070, 8192MB)\n",
      "\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.common.Conv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Detect' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Model Summary: 483 layers, 88922205 parameters, 88922205 gradients\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py:390: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  if param.grad is not None:\n",
      "Traceback (most recent call last):\n",
      "  File \"test.py\", line 302, in <module>\n",
      "    test(opt.data,\n",
      "  File \"test.py\", line 87, in test\n",
      "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 121, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 137, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 48, in forward\n",
      "    x[i] = self.m[i](x[i])  # conv\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 778, in __getattr__\n",
      "    raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "torch.nn.modules.module.ModuleAttributeError: 'Detect' object has no attribute 'm'\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5x on COCO val2017\n",
    "#runing from external: coco_external.yaml\n",
    "!python test.py --weights yolov5x.pt --data $datasetyaml --img 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc_KbFk0juX2"
   },
   "source": [
    "## COCO test-dev2017\n",
    "Download [COCO test2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L15) dataset (7GB - 40,000 images), to test model accuracy on test-dev set (20,000 images). Results are saved to a `*.json` file which can be submitted to the evaluation server at https://competitions.codalab.org/competitions/20794."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0AJnSeCIHyJ"
   },
   "outputs": [],
   "source": [
    "# Download COCO test-dev2017\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip  # unzip labels\n",
    "!f=\"test2017.zip\" && curl http://images.cocodataset.org/zips/$f -o $f && unzip -q $f && rm $f  # 7GB,  41k images\n",
    "%mv ./test2017 ./coco/images && mv ./coco ../  # move images to /coco and move /coco next to /yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "29GJXAP_lPrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment=False, batch_size=32, conf_thres=0.001, data='C:\\\\Users\\\\nmc_costa\\\\google_drive\\\\projects\\\\bosch_P19\\\\research\\\\python_ws\\\\violent_action\\\\yolo\\\\coco128_external.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.65, name='exp', project='runs/test', save_conf=False, save_json=False, save_txt=False, single_cls=False, task='test', verbose=False, weights=['yolov5s.pt'])\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 1.7.0 CUDA:0 (GeForce GTX 1070, 8192MB)\n",
      "\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.common.Conv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Detect' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "Model Summary: 231 layers, 7459581 parameters, 7459581 gradients\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py:390: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  if param.grad is not None:\n",
      "Traceback (most recent call last):\n",
      "  File \"test.py\", line 302, in <module>\n",
      "    test(opt.data,\n",
      "  File \"test.py\", line 87, in test\n",
      "    _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 121, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 137, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 48, in forward\n",
      "    x[i] = self.m[i](x[i])  # conv\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 778, in __getattr__\n",
      "    raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "torch.nn.modules.module.ModuleAttributeError: 'Detect' object has no attribute 'm'\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5s on COCO test-dev2017 using --task test\n",
    "!python test.py --weights yolov5s.pt --data $datasetyaml --task test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# 3. Train\n",
    "\n",
    "Download [COCO128](https://www.kaggle.com/ultralytics/coco128), a small 128-image tutorial dataset, start tensorboard and train YOLOv5s from a pretrained checkpoint for 3 epochs (note actual training is typically much longer, around **300-1000 epochs**, depending on your dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "b434b178be4b41b3881e237e19f49b45",
      "72db749d8e3840238e1ceeec58a2cb4c",
      "4459ef1aa32e422c9f1bc152a2aba7dc",
      "b658312802194c1d86383e444af6ade4",
      "e24e99052e1a4f9ea794081fc6c42d80",
      "a08dda95df7441739105f5b59b8ea882",
      "1abb5618e7134f0eb976857e126fda0d",
      "67e56da5b8574fc7a715422bdfeaeab4"
     ]
    },
    "id": "Knxi2ncxWffW",
    "outputId": "8c237907-6c62-4273-ce27-d5035fc6f5ac"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b434b178be4b41b3881e237e19f49b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22090455.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Download COCO128\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YAML Paths # coco128 yaml\n",
    "datasetyaml=os.path.join(scriptdir, 'coco128_external.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pOkGLv1dMqh"
   },
   "source": [
    "Train a YOLOv5s model on [COCO128](https://www.kaggle.com/ultralytics/coco128) with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.\n",
    "\n",
    "All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5060), started 4 days, 4:07:06 ago. (Use '!kill 5060' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-78ae2bfbdf66f47b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-78ae2bfbdf66f47b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "a98e611d-979b-4e8c-d61c-8e219958ed33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 1.7.0 CUDA:0 (GeForce GTX 1070, 8192MB)\n",
      "\n",
      "Namespace(adam=False, batch_size=16, bucket='', cache_images=True, cfg='', data='C:\\\\Users\\\\nmc_costa\\\\google_drive\\\\projects\\\\bosch_P19\\\\research\\\\python_ws\\\\violent_action\\\\yolo\\\\coco128_external.yaml', device='', epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], local_rank=-1, log_imgs=16, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs\\\\train\\\\exp3', single_cls=False, sync_bn=False, total_batch_size=16, weights='yolov5s.pt', workers=8, world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.common.Conv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'models.yolo.Detect' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1       256  torch.nn.modules.conv.Conv2d            [255, 1, 1]                   \n",
      " 19                -2  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 22                -1  1       256  torch.nn.modules.conv.Conv2d            [255, 1, 1]                   \n",
      " 23                -2  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 26                -1  1       256  torch.nn.modules.conv.Conv2d            [255, 1, 1]                   \n",
      " 27                []  1         0  models.yolo.Detect                      [80, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]], []]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 490, in <module>\n",
      "    train(hyp, opt, device, tb_writer, wandb)\n",
      "  File \"train.py\", line 83, in train\n",
      "    model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc).to(device)  # create\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 91, in __init__\n",
      "    m.stride = torch.tensor([s / x.shape[-2] for x in self.forward(torch.zeros(1, ch, s, s))])  # forward\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 121, in forward\n",
      "    return self.forward_once(x, profile)  # single-scale inference, train\n",
      "  File \"C:\\Users\\nmc_costa\\google_drive\\projects\\bosch_P19\\research\\python_ws\\violent_action\\yolo\\yolov5\\models\\yolo.py\", line 137, in forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 423, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"C:\\Tools\\miniconda3\\envs\\violent_action\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 419, in _conv_forward\n",
      "    return F.conv2d(input, weight, self.bias, self.stride,\n",
      "RuntimeError: Given groups=1, weight of size [1, 255, 1, 1], expected input[1, 128, 16, 16] to have 255 channels, but got 128 channels instead\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data $datasetyaml --weights yolov5s.pt --nosave --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15glLzbQx5u0"
   },
   "source": [
    "# 4. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "## Weights & Biases Logging 🌟 NEW\n",
    "\n",
    "[Weights & Biases](https://www.wandb.com/) (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. To enable W&B logging install `wandb`, and then train normally (you will be guided through setup on first use).\n",
    "```bash\n",
    "$ pip install wandb\n",
    "```\n",
    "\n",
    "During training you will see live updates at [https://www.wandb.com/](https://www.wandb.com/), and you can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. For more information see the [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/98184457-bd3da580-1f0a-11eb-8461-95d908a71893.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WPvRbS5Swl6"
   },
   "source": [
    "## Local Logging\n",
    "\n",
    "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and test jpgs to see mosaics, labels, predictions and augmentation effects. Note a **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "riPdhraOTCO0"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/train/exp/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels\n",
    "Image(filename='runs/train/exp/test_batch0_labels.jpg', width=800)  # test batch 0 labels\n",
    "Image(filename='runs/train/exp/test_batch0_pred.jpg', width=800)  # test batch 0 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYG4WFEnTVrI"
   },
   "source": [
    "> <img src=\"https://user-images.githubusercontent.com/26833433/83667642-90fcb200-a583-11ea-8fa3-338bbf7da194.jpeg\" width=\"750\">  \n",
    "`train_batch0.jpg` shows train batch 0 mosaics and labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/83667626-8c37fe00-a583-11ea-997b-0923fe59b29b.jpeg\" width=\"750\">  \n",
    "`test_batch0_labels.jpg` shows test batch 0 labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/83667635-90641b80-a583-11ea-8075-606316cebb9c.jpeg\" width=\"750\">  \n",
    "`test_batch0_pred.jpg` shows test batch 0 _predictions_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KN5ghjE6ZWh"
   },
   "source": [
    "Training losses and performance metrics are also logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and a custom `results.txt` logfile which is plotted as `results.png` (below) after training completes. Here we show YOLOv5s trained on COCO128 to 300 epochs, starting from scratch (blue), and from pretrained `--weights yolov5s.pt` (orange)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDznIqPF7nk3"
   },
   "outputs": [],
   "source": [
    "from utils.plots import plot_results \n",
    "plot_results(save_dir='runs/train/exp')  # plot all results*.txt as results.png\n",
    "Image(filename='runs/train/exp/results.png', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfrEegCSW3fK"
   },
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/26833433/97808309-8182b180-1c66-11eb-8461-bffe1a79511d.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zelyeqbyt3GD"
   },
   "source": [
    "# Environments\n",
    "\n",
    "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
    "\n",
    "- **Google Colab Notebook** with free GPU: <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "- **Kaggle Notebook** with free GPU: [https://www.kaggle.com/ultralytics/yolov5](https://www.kaggle.com/ultralytics/yolov5)\n",
    "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart) \n",
    "- **Docker Image** https://hub.docker.com/r/ultralytics/yolov5. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) ![Docker Pulls](https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Appendix\n",
    "\n",
    "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gI6NoBev8Ib1"
   },
   "outputs": [],
   "source": [
    "# Re-clone repo\n",
    "%cd ..\n",
    "%rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcKoSIK2WSzj"
   },
   "outputs": [],
   "source": [
    "# Test all models\n",
    "%%shell\n",
    "for x in s m l x\n",
    "do\n",
    "  python test.py --weights yolov5$x.pt --data coco.yaml --img 640\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGH0ZjkGjejy"
   },
   "outputs": [],
   "source": [
    "# Run unit tests\n",
    "%%shell\n",
    "# git clone https://github.com/ultralytics/yolov5\n",
    "# cd yolov5\n",
    "pip install -qr requirements.txt onnx\n",
    "\n",
    "export PYTHONPATH=\"$PWD\" # to run *.py. files in subdirectories\n",
    "for x in yolov5s #yolov5m yolov5l yolov5x # models\n",
    "do\n",
    "  rm -rf runs\n",
    "  python train.py --weights $x.pt --cfg $x.yaml --epochs 3 --img 320 --device 0  # train\n",
    "  for di in 0 cpu # inference devices\n",
    "  do\n",
    "    python detect.py --weights $x.pt --device $di  # detect official\n",
    "    python detect.py --weights runs/train/exp/weights/last.pt --device $di  # detect custom\n",
    "    python test.py --weights $x.pt --device $di # test official\n",
    "    python test.py --weights runs/train/exp/weights/last.pt --device $di # test custom\n",
    "  done\n",
    "  python models/yolo.py --cfg $x.yaml # inspect\n",
    "  python models/export.py --weights $x.pt --img 640 --batch 1 # export\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSgFCAcMbk1R"
   },
   "outputs": [],
   "source": [
    "# VOC\n",
    "for b, m in zip([64, 48, 32, 16], ['yolov5s', 'yolov5m', 'yolov5l', 'yolov5x']):  # zip(batch_size, model)\n",
    "  !python train.py --batch {b} --weights {m}.pt --data voc.yaml --epochs 50 --cache --img 512 --nosave --hyp hyp.finetune.yaml --project VOC --name {m}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "YOLOv5 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "191c687c120f4aab9a112697124fe444": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1abb5618e7134f0eb976857e126fda0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4459ef1aa32e422c9f1bc152a2aba7dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a08dda95df7441739105f5b59b8ea882",
      "max": 22090455,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e24e99052e1a4f9ea794081fc6c42d80",
      "value": 22090455
     }
    },
    "67e56da5b8574fc7a715422bdfeaeab4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b21efad6db4407eb253f819f279671a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72db749d8e3840238e1ceeec58a2cb4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79edc4bba71748338f58660262c569a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b21efad6db4407eb253f819f279671a",
      "placeholder": "​",
      "style": "IPY_MODEL_191c687c120f4aab9a112697124fe444",
      "value": " 781M/781M [05:01&lt;00:00, 2.71MB/s]"
     }
    },
    "9cb5be61e41144ef9dbc9339c2f46eb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed1a514c303b49c0a23745f4ff17344b",
       "IPY_MODEL_79edc4bba71748338f58660262c569a9"
      ],
      "layout": "IPY_MODEL_a6ba87512fd04622b9948571d330d9c0"
     }
    },
    "a08dda95df7441739105f5b59b8ea882": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ba87512fd04622b9948571d330d9c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b434b178be4b41b3881e237e19f49b45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4459ef1aa32e422c9f1bc152a2aba7dc",
       "IPY_MODEL_b658312802194c1d86383e444af6ade4"
      ],
      "layout": "IPY_MODEL_72db749d8e3840238e1ceeec58a2cb4c"
     }
    },
    "b658312802194c1d86383e444af6ade4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67e56da5b8574fc7a715422bdfeaeab4",
      "placeholder": "​",
      "style": "IPY_MODEL_1abb5618e7134f0eb976857e126fda0d",
      "value": " 21.1M/21.1M [22:51&lt;00:00, 16.1kB/s]"
     }
    },
    "cbbf6780f4f048feb2644ed4e3fed9c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e24e99052e1a4f9ea794081fc6c42d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e40fc489500f4e4891025c59b2b1fa8d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed1a514c303b49c0a23745f4ff17344b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e40fc489500f4e4891025c59b2b1fa8d",
      "max": 819257867,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cbbf6780f4f048feb2644ed4e3fed9c7",
      "value": 819257867
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
