{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json2mmaction2\n",
    "version: 1\n",
    "\n",
    "info:\n",
    "- Create standard MOLA JSON\n",
    "\n",
    "author: nuno costa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folders(path='../out/'):\n",
    "    # Create folders\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)  # delete output folder\n",
    "    os.makedirs(path)  # make new output folder\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(src,dst,copy=True):\n",
    "    extracted=True\n",
    "    try:\n",
    "        if copy: \n",
    "            if not os.path.exists(os.path.dirname(dst)): os.makedirs(os.path.dirname(dst)) #make sure dir exists\n",
    "            shutil.copyfile(src, dst)  # raises if missing files\n",
    "        else: #if not copy only extracting filelist from json\n",
    "            if not os.path.exists(src): raise\n",
    "    except:\n",
    "        print(\"\\n>> missing : {}\".format(src))\n",
    "        extracted=False\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SINGLE CASE STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_root_dir='D:/external_datasets/MOLA/'\n",
    "json_dir='D:/external_datasets/MOLA/INCAR/'\n",
    "outdir='D:/external_datasets/MOLA/INCAR_MMA/' #don't forget the last\n",
    "make_folders(path=outdir)  # output directory\n",
    "dataset=\"mola\"\n",
    "json_file = json_dir+'mola.json'\n",
    "img_number=None #STOP CONDITION : None copies all\n",
    "copy_images=True #if false only filelist is extracted from json\n",
    "copy_videos=False\n",
    "level=2 #level: 1- one level; 2-two-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_from_annotation(json_file, data, images, videos, categories, copy_images, copy_videos, outdir_img, outdir_video, img_number=None, level=2):\n",
    "    # WRITE FILES (COPY & GENERATE FILELIST)\n",
    "    # image lists\n",
    "    img_l = []\n",
    "    saved_img_l= []\n",
    "    imglist = []\n",
    "    img_counter = 0 # image counter\n",
    "    # video lists\n",
    "    video_l = []\n",
    "    saved_video_l= []\n",
    "    videolist = []\n",
    "    # write files \n",
    "    method=\"for\" #TODO: parfor method\n",
    "    start=time.time()\n",
    "    if method==\"for\":\n",
    "        #WRITE IMAGES\n",
    "        for x in tqdm(data['annotations'], desc='Annotations %s' % json_file):  \n",
    "            # extract image info from x['image_id']\n",
    "            image_id='%g' % x['image_id']\n",
    "            if image_id in img_l: continue # continue to next loop if repeated image_id \n",
    "            img_l.append(image_id)\n",
    "            img = images[image_id]\n",
    "            h, w, imgf = img['height'], img['width'], img['file_name']\n",
    "            _, img_ext = os.path.splitext(imgf)\n",
    "            img_fn = Path(imgf).stem\n",
    "            img_new_fn = \"img_\"+image_id #img_imgid.jpg (imgid with zeros 00001: image_id.zfill(5) ) Problem is I don't no the maximum of images\n",
    "            # extract video info from img['video_id']\n",
    "            video_id = '%g' % img[\"video_id\"]\n",
    "            video = videos[video_id]\n",
    "            videof= video[\"name\"]\n",
    "            video_fn = Path(videof).stem\n",
    "            video_new_fn = \"video_\"+video_id\n",
    "            # extract label and category\n",
    "            catid = '%g' % x['category_id']\n",
    "            label = catid\n",
    "            category = categories[catid]\n",
    "            # extract total label frames\n",
    "            total_frames = '%g' % x['label_frames']\n",
    "            # extract category\n",
    "            category = categories[label]['name']\n",
    "            # extract bounding box format is [top left x, top left y, width, height] | [x,y,w,h]\n",
    "            box = np.array(x['bbox'], dtype=np.float64) \n",
    "            box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "            box[[0, 2]] /= w  # normalize x & w\n",
    "            box[[1, 3]] /= h  # normalize y & h\n",
    "            if (box[2] > 0.) and (box[3] > 0.):  # if w > 0 and h > 0\n",
    "                # write images - 1st because if copy_images fails the rest should not be done\n",
    "                src = os.path.join(datasets_root_dir, imgf)\n",
    "                dst = os.path.join(outdir_img, video_new_fn, img_new_fn + img_ext)\n",
    "                if level==2: dst = os.path.join(outdir_img, category, video_new_fn, img_new_fn + img_ext)\n",
    "                ext=extract_file(src,dst,copy=copy_images)\n",
    "                if not ext: continue #if image missing from dataset when extracting images dont write nothing more\n",
    "                # img list: \n",
    "                imgline = f'{video_new_fn}/{img_new_fn}\\n' # f'{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                if level==2: imgline = f'{category}/{video_new_fn}/{img_new_fn}\\n' # f'{category}/{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                imglist.append(imgline)\n",
    "                img_counter += 1\n",
    "                # rawframe annotation file list: json to txt [ frame_directory total_frames label  ]\n",
    "                vidline = f'{video_new_fn} {total_frames} {label}\\n'\n",
    "                if level==2: vidline = f'{category}/{video_new_fn} {total_frames} {label}\\n' \n",
    "                videolist.append(vidline)\n",
    "            # STOP conditions\n",
    "            if img_number and img_counter >= img_number: \n",
    "                print(\"STOP CONDITION\")\n",
    "                break\n",
    "        #remove duplicate paths\n",
    "        imglist=list(dict.fromkeys(imglist)) \n",
    "        videolist=list(dict.fromkeys(videolist)) \n",
    "    stop = time.time()\n",
    "    elapsed=stop-start\n",
    "    print(\"time elapsed:\", elapsed)\n",
    "    return imglist, videolist, saved_img_l, saved_video_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations D:/external_datasets/MOLA/INCAR/mola.json: 100%|███████████████████████| 1164/1164 [00:28<00:00, 40.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 28.89821696281433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def mola2mmaction2(datasets_root_dir=None, json_file='mola.json', outdir='out/', copy_images=True, copy_videos=False, img_number=None, level=2):\n",
    "    # MAKE ROOT DIRS\n",
    "    videodir_path = 'videos_%s/' % Path(json_file).stem  # folder name (train, val, test) remove other info\n",
    "    imgdir_path = 'rawframes_%s/' % Path(json_file).stem  # folder name (train, val, test) remove other info\n",
    "    outdir_video = os.path.join (outdir, videodir_path)\n",
    "    outdir_img = os.path.join (outdir, imgdir_path)\n",
    "    if copy_videos: make_folders(path=outdir_video)\n",
    "    if copy_images: make_folders(path=outdir_img)\n",
    "    # PARSE JSON ANNOTATIONS\n",
    "    data=None\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "    if not data: raise\n",
    "    # create image dict {id: image}\n",
    "    images = {'%g' % x['id']: x for x in data['images']}\n",
    "    # create video dict {id: video}\n",
    "    videos = {'%g' % x['id']: x for x in data['videos']}\n",
    "    # create category dict {id: category}\n",
    "    categories = {'%g' % x['id']: x for x in data['categories']}\n",
    "    # WRITE FILES (COPY & GENERATE FILELIST)\n",
    "    method=\"from_annotation\"\n",
    "    if method==\"from_annotation\": imglist, videolist, saved_img_l, saved_video_l=write_from_annotation(json_file, data, images, videos, categories, copy_images, copy_videos, outdir_img, outdir_video, img_number=img_number, level=level)\n",
    "\n",
    "    return imglist, videolist, saved_img_l, saved_video_l\n",
    "imglist, videolist, saved_img_l, saved_video_l = mola2mmaction2(datasets_root_dir=datasets_root_dir, json_file=json_file, outdir=outdir, copy_images=copy_images, copy_videos=copy_videos, img_number=img_number, level=level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE FILELIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE FILELISTS\n",
    "#save imglist : mola_{train,val}_rawframes.txt\n",
    "dataset_type='rawframes'\n",
    "filename=f'{dataset}_{Path(json_file).stem}_{dataset_type}.txt'\n",
    "with open(outdir + filename, 'w') as f:\n",
    "    f.writelines(videolist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIG MMACTION2\n",
    "1. Option (RECOMMENDED): create a customconfig.py file \n",
    "2. Option: modify other config and train from script (see folder MMACTION2/TESTS/mmaction2_tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LjCcmCKOjktc"
   },
   "outputs": [],
   "source": [
    "# 2. Option\n",
    "from mmcv import Config\n",
    "cfg = Config.fromfile('./configs/recognition/tsn/tsn_r50_video_1x1x8_100e_kinetics400_rgb.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc8YhFFGjp3e"
   },
   "source": [
    "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on mola dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root= outdir #default: \"data/\"\n",
    "dataset=\"mola\"\n",
    "dataset_type = 'RawframeDataset'\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = dataset_type\n",
    "cfg.data_root =  root+dataset+imgdir_path\n",
    "cfg.data_root_val = root+dataset+imgdir_path\n",
    "cfg.ann_file_train =  root+dataset+'/'+dataset+'_train_rawframes.txt'\n",
    "cfg.ann_file_val = root+dataset+'/'+dataset+'_val_rawframes.txt'\n",
    "cfg.ann_file_test = root+dataset+'/'+dataset+'_val_rawframes.txt'\n",
    "\n",
    "cfg.data.test.type = dataset_type\n",
    "cfg.data.test.ann_file = root+dataset+'/'+dataset+'_val_rawframes.txt'\n",
    "cfg.data.test.data_prefix = cfg.data_root_val #'data/kinetics400_tiny/val/'\n",
    "\n",
    "cfg.data.train.type = dataset_type\n",
    "cfg.data.train.ann_file = root+dataset+'/'+dataset+'_train_rawframes.txt'\n",
    "cfg.data.train.data_prefix = cfg.data_root #'data/kinetics400_tiny/train/'\n",
    "\n",
    "cfg.data.val.type = dataset_type\n",
    "cfg.data.val.ann_file = root+dataset+'/'+dataset+'_val_rawframes.txt'\n",
    "cfg.data.val.data_prefix = cfg.data_root_val #'data/kinetics400_tiny/val/'\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "cfg.setdefault('omnisource', False)\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 2\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.data.videos_per_gpu = cfg.data.videos_per_gpu // 16\n",
    "cfg.optimizer.lr = cfg.optimizer.lr / 8 / 16\n",
    "cfg.total_epochs = 30\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 10\n",
    "# We can set the log print interval to reduce the the times of printing log\n",
    "cfg.log_config.interval = 5\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tES-qnZ3k38Z"
   },
   "source": [
    "### Train a new recognizer\n",
    "\n",
    "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "outputId": "85a52ef3-7b5c-4c52-8fef-00322a8c65e6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.apis import train_model\n",
    "\n",
    "import mmcv\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the recognizer\n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_model(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryVoSfZVmogw"
   },
   "source": [
    "## Test the trained recognizer\n",
    "\n",
    "After finetuning the recognizer, let's check the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "200e37c7-0da4-421f-98da-41418c3110ca"
   },
   "outputs": [],
   "source": [
    "from mmaction.apis import single_gpu_test\n",
    "from mmaction.datasets import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "# Build a test dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        videos_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "outputs = single_gpu_test(model, data_loader)\n",
    "\n",
    "eval_config = cfg.evaluation\n",
    "eval_config.pop('interval')\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI CASE STUDY (For loop script for each json - train, val , test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mola_json(dataset=\"mola\", datasets_root_dir=None, json_dir='../mola/annotations/', outdir='out/', copy_images=True, copy_videos=False, img_number=None, level=2):\n",
    "    # Convert motionLab JSON file into  labels --------------------------------\n",
    "    make_folders(path=outdir)  # output directory\n",
    "    jsons = glob.glob(json_dir + '*.json')\n",
    "    # Import json\n",
    "    for json_file in sorted(jsons):\n",
    "        imglist, videolist, saved_img_l, saved_video_l = mola2mmaction2(datasets_root_dir=datasets_root_dir, \n",
    "                                                                        json_file=json_file, \n",
    "                                                                        outdir=outdir, \n",
    "                                                                        copy_images=copy_images, \n",
    "                                                                        copy_videos=copy_videos, \n",
    "                                                                        img_number=img_number,\n",
    "                                                                        level=level\n",
    "                                                                       )\n",
    "        # GENERATE FILELISTS\n",
    "        #save videolist : mola_{train,val}_rawframes.txt\n",
    "        dataset_type='rawframes'\n",
    "        filename=f'{dataset}_{Path(json_file).stem}_{dataset_type}.txt'\n",
    "        with open(outdir + filename, 'w') as f:\n",
    "            f.writelines(videolist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations D:/external_datasets/MOLA/INCAR\\mola.json: 100%|███████████████████████| 1164/1164 [00:29<00:00, 39.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 29.156079530715942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets_root_dir='D:/external_datasets/MOLA/'\n",
    "json_dir='D:/external_datasets/MOLA/INCAR/'\n",
    "outdir='D:/external_datasets/MOLA/INCAR_MMA_FORMAT/'\n",
    "img_number=None\n",
    "copy_images=True\n",
    "copy_videos=False\n",
    "level=2\n",
    "convert_mola_json(datasets_root_dir=datasets_root_dir, json_dir=json_dir, outdir=outdir, \n",
    "                  img_number=img_number, copy_images=copy_images, copy_videos=copy_videos, level=level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAILED CODE IDEAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING TO hard to implement when you want to write images\n",
    "#TO ADD IMGID you need to search for imgid on video\n",
    "def write_from_video_annotation(data, images, videos, categories, copy_images, copy_videos, outdir_img, outdir_video):\n",
    "    # WRITE FILES (COPY & GENERATE FILELIST)\n",
    "    # video lists\n",
    "    video_l = []\n",
    "    saved_video_l= []\n",
    "    videolist = []\n",
    "    # write files \n",
    "    method=\"for\" #TODO: parfor method\n",
    "    start=time.time()\n",
    "    if method==\"for\":\n",
    "        #WRITE IMAGES\n",
    "        for x in tqdm(data['video_annotations'], desc='Video Annotations %s' % json_file):  \n",
    "            # extract video info from img['video_id']\n",
    "            video_id = '%g' % x[\"video_id\"]\n",
    "            video = videos[video_id]\n",
    "            videof= video[\"name\"]\n",
    "            video_sensor=video[\"sensor\"]\n",
    "            video_fn = Path(videof).stem\n",
    "            video_new_fn = \"video_\"+video_id\n",
    "            # extract label and category\n",
    "            catid = '%g' % x['category_id']\n",
    "            label = catid\n",
    "            category = categories[catid]\n",
    "            # extract total label frames\n",
    "            total_frames = '%g' % x['label_frames']\n",
    "            # extract category\n",
    "            category = categories[label]['name']\n",
    "            time_start = x['time_start'] #first frame\n",
    "            time_end = x['time_end'] #end frame\n",
    "            # extract image info from x['image_id']\n",
    "            imgdir=os.path.dirname(videof)+'/'+video_sensor+'/'\n",
    "            img_l= sorted( filter( os.path.isfile, glob.glob(imgdir + '*') ) )\n",
    "            # write images - 1st because if copy_images fails the rest should not be done\n",
    "            # image lists\n",
    "            img_l = []\n",
    "            saved_img_l= []\n",
    "            imglist = []\n",
    "            img_counter = 0 # image counter\n",
    "            for imgd in img_l:\n",
    "                src = os.path.join(imgd)\n",
    "                dst = os.path.join(outdir_img, video_new_fn, img_new_fn + img_ext) #TODO: how to add imgid you need to search \n",
    "                if level==2: dst = os.path.join(outdir_img, category, video_new_fn, img_new_fn + img_ext)\n",
    "                ext=extract_file(src,dst,copy=copy_images)\n",
    "                if not ext: continue #if image missing from dataset when extracting images dont write nothing more\n",
    "                # rawframe annotation file list: json to txt [ frame_directory total_frames label  ]\n",
    "                imgline = f'{video_new_fn} {total_frames} {label}\\n' # f'{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                if level==2: imgline = f'{category}/{video_new_fn} {total_frames} {label}\\n' # f'{category}/{video_new_fn}/{img_new_fn} {total_frames} {label}\\n'\n",
    "                imglist.append(imgline)\n",
    "                img_counter += 1\n",
    "        #remove duplicate paths\n",
    "        imglist=list(dict.fromkeys(imglist)) \n",
    "    stop = time.time()\n",
    "    elapsed=stop-start\n",
    "    print(\"time elapsed:\", elapsed)\n",
    "    return imglist, videolist, saved_img_l, saved_video_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
